{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AI Mock Interview Platform","text":"<p>Welcome to the AI Mock Interview Platform documentation! This platform helps you practice system design interviews with an AI-powered interviewer that provides real-time feedback and comprehensive evaluation.</p>"},{"location":"#quick-navigation","title":"\ud83d\ude80 Quick Navigation","text":"<ul> <li> <p> Getting Started</p> <p>Get up and running in minutes with our quick start guide</p> <p> Quick Start Guide</p> </li> <li> <p> Developer Setup</p> <p>Set up your development environment and contribute to the project</p> <p> Developer Setup</p> </li> <li> <p> Architecture</p> <p>Understand the system architecture and component design</p> <p> Architecture Overview</p> </li> <li> <p> API Reference</p> <p>Explore the API documentation and code references</p> <p> API Documentation</p> </li> </ul>"},{"location":"#feature-highlights","title":"\u2728 Feature Highlights","text":""},{"location":"#multi-modal-communication","title":"Multi-modal Communication","text":"<p>Experience realistic interviews with audio, video, whiteboard, and screen sharing capabilities. Practice explaining your designs just like in a real interview.</p>"},{"location":"#ai-powered-interviewer","title":"AI-Powered Interviewer","text":"<p>Powered by OpenAI GPT-4 or Anthropic Claude, the AI interviewer asks relevant follow-up questions, challenges your assumptions, and guides you through the interview process.</p>"},{"location":"#resume-aware-problem-generation","title":"Resume-Aware Problem Generation","text":"<p>Upload your resume and get interview problems tailored to your experience level and background. The AI adapts the difficulty and focus areas based on your profile.</p>"},{"location":"#interactive-whiteboard","title":"Interactive Whiteboard","text":"<p>Draw system architecture diagrams, flowcharts, and data models using the built-in whiteboard. Visualize your designs as you explain them.</p>"},{"location":"#comprehensive-feedback","title":"Comprehensive Feedback","text":"<p>Receive detailed evaluation reports with scores across multiple dimensions, strengths, areas for improvement, and personalized action plans.</p>"},{"location":"#local-first-architecture","title":"Local-First Architecture","text":"<p>All your data stays on your machine. The platform uses local PostgreSQL storage and filesystem for complete privacy and control.</p>"},{"location":"#progress-tracking","title":"Progress Tracking","text":"<p>Review past interview sessions, track your improvement over time, and identify patterns in your performance.</p>"},{"location":"#what-you-can-do","title":"\ud83c\udfaf What You Can Do","text":"<ul> <li>Practice System Design: Work through realistic system design problems</li> <li>Get Real-Time Feedback: Receive immediate feedback on your approach and solutions</li> <li>Track Progress: Monitor your improvement across multiple interview sessions</li> <li>Learn Best Practices: Understand industry-standard system design patterns</li> <li>Build Confidence: Practice in a safe environment before real interviews</li> </ul>"},{"location":"#technology-stack","title":"\ud83c\udfd7\ufe0f Technology Stack","text":"<ul> <li>Frontend: Streamlit for interactive UI</li> <li>Backend: Python with LangChain for AI orchestration</li> <li>Database: PostgreSQL for data persistence</li> <li>AI Models: OpenAI GPT-4, Anthropic Claude</li> <li>Deployment: Docker and Docker Compose</li> <li>Communication: WebRTC for audio/video, Canvas for whiteboard</li> </ul>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<p>This documentation is organized into several sections:</p> <ul> <li>Getting Started: Installation, setup, and first steps</li> <li>Architecture: System design, components, and technical details</li> <li>Features: Detailed feature documentation and usage guides</li> <li>Contributing: Guidelines for contributing to the project</li> <li>Reference: API documentation, changelog, and implementation notes</li> </ul>"},{"location":"#community-and-support","title":"\ud83e\udd1d Community and Support","text":"<ul> <li>GitHub Repository: View on GitHub</li> <li>Issue Tracker: Report bugs and request features</li> <li>Discussions: Ask questions and share ideas</li> </ul>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is open source and available under the MIT License.</p> <p>Ready to get started? Head over to the Quick Start Guide to begin your journey!</p>"},{"location":"AI_INTERVIEWER/","title":"AI Interviewer Agent Documentation","text":""},{"location":"AI_INTERVIEWER/#overview","title":"Overview","text":"<p>The AI Interviewer Agent is a core component of the AI Mock Interview Platform that conducts system design interviews using LangChain and large language models (LLMs). It provides intelligent question generation, response analysis, and adaptive difficulty adjustment.</p>"},{"location":"AI_INTERVIEWER/#architecture","title":"Architecture","text":""},{"location":"AI_INTERVIEWER/#class-aiinterviewer","title":"Class: <code>AIInterviewer</code>","text":"<p>Located in <code>src/ai/ai_interviewer.py</code></p> <p>The AIInterviewer class manages the interview conversation flow, generates questions, analyzes responses, and provides contextual follow-ups.</p>"},{"location":"AI_INTERVIEWER/#key-features","title":"Key Features","text":"<ol> <li>Multi-Provider Support</li> <li>OpenAI GPT-4 and GPT-4 Turbo</li> <li>Anthropic Claude 3 (Opus, Sonnet, Haiku)</li> <li> <p>Easy to extend for additional providers</p> </li> <li> <p>Resume-Aware Problem Generation</p> </li> <li>Tailors problems to candidate's experience level (junior/mid/senior/staff)</li> <li>Considers domain expertise (backend, distributed systems, cloud, etc.)</li> <li> <p>Adjusts difficulty based on years of experience</p> </li> <li> <p>Intelligent Response Processing</p> </li> <li>Analyzes candidate responses for completeness and clarity</li> <li>Generates contextually relevant follow-up questions</li> <li>Asks clarifying questions for ambiguous responses</li> <li> <p>Covers key system design topics (scalability, reliability, trade-offs)</p> </li> <li> <p>Conversation Memory Management</p> </li> <li>Uses LangChain's ConversationBufferMemory</li> <li>Maintains full conversation history</li> <li> <p>Provides context for follow-up questions</p> </li> <li> <p>Token Tracking</p> </li> <li>Tracks all API calls with input/output tokens</li> <li>Calculates estimated costs per operation</li> <li> <p>Integrates with TokenTracker for session-level analytics</p> </li> <li> <p>Retry Logic with Exponential Backoff</p> </li> <li>Automatically retries failed API calls (max 3 attempts)</li> <li>Exponential backoff: 1s, 2s, 4s delays</li> <li> <p>Handles transient API failures gracefully</p> </li> <li> <p>Comprehensive Logging</p> </li> <li>Logs all operations with structured context</li> <li>Includes session_id for traceability</li> <li>Tracks performance metrics (duration, token usage)</li> </ol>"},{"location":"AI_INTERVIEWER/#usage","title":"Usage","text":""},{"location":"AI_INTERVIEWER/#initialization","title":"Initialization","text":"<pre><code>from src.ai.ai_interviewer import AIInterviewer\nfrom src.ai.token_tracker import TokenTracker\nfrom src.log_manager.logging_manager import LoggingManager\n\n# Create dependencies\ntoken_tracker = TokenTracker(data_store=data_store, logger=logger)\nlogger = LoggingManager(config=logging_config, data_store=data_store)\n\n# Initialize interviewer\ninterviewer = AIInterviewer(\n    provider=\"openai\",\n    model=\"gpt-4-turbo-preview\",\n    api_key=\"your-api-key\",\n    token_tracker=token_tracker,\n    temperature=0.7,\n    max_tokens=2000,\n    logger=logger\n)\n</code></pre>"},{"location":"AI_INTERVIEWER/#starting-an-interview","title":"Starting an Interview","text":"<pre><code># Initialize for a session\ninterviewer.initialize(\n    session_id=\"session_123\",\n    resume_data=resume_data  # Optional\n)\n\n# Start the interview\nresponse = interviewer.start_interview()\nprint(response.content)  # Opening question\nprint(f\"Tokens used: {response.token_usage.total_tokens}\")\nprint(f\"Cost: ${response.token_usage.estimated_cost:.4f}\")\n</code></pre>"},{"location":"AI_INTERVIEWER/#processing-candidate-responses","title":"Processing Candidate Responses","text":"<pre><code># Process candidate's response\ncandidate_response = \"I would use a load balancer to distribute traffic...\"\nresponse = interviewer.process_response(candidate_response)\nprint(response.content)  # Follow-up question\n</code></pre>"},{"location":"AI_INTERVIEWER/#resume-aware-problem-generation","title":"Resume-Aware Problem Generation","text":"<pre><code># Generate problem based on resume\nproblem = interviewer.generate_problem(resume_data)\nprint(problem)\n</code></pre>"},{"location":"AI_INTERVIEWER/#asking-clarifying-questions","title":"Asking Clarifying Questions","text":"<pre><code># When response is ambiguous\nambiguous_response = \"I would just handle it.\"\nresponse = interviewer.ask_clarifying_question(ambiguous_response)\nprint(response.content)  # Clarifying question\n</code></pre>"},{"location":"AI_INTERVIEWER/#adapting-difficulty","title":"Adapting Difficulty","text":"<pre><code># Adjust difficulty based on performance\nperformance_indicators = {\n    \"response_quality\": \"high\",\n    \"depth_of_understanding\": \"deep\",\n    \"technical_accuracy\": \"accurate\"\n}\ninterviewer.adapt_difficulty(performance_indicators)\n</code></pre>"},{"location":"AI_INTERVIEWER/#whiteboard-analysis","title":"Whiteboard Analysis","text":"<pre><code># Analyze whiteboard diagram (placeholder implementation)\nwhiteboard_image = load_image_bytes(\"whiteboard.png\")\nanalysis = interviewer.analyze_whiteboard(whiteboard_image)\nprint(f\"Components: {analysis.components_identified}\")\nprint(f\"Relationships: {analysis.relationships}\")\nprint(f\"Missing: {analysis.missing_elements}\")\n</code></pre>"},{"location":"AI_INTERVIEWER/#api-reference","title":"API Reference","text":""},{"location":"AI_INTERVIEWER/#constructor","title":"Constructor","text":"<pre><code>AIInterviewer(\n    provider: str,\n    model: str,\n    api_key: str,\n    token_tracker: TokenTracker,\n    temperature: float = 0.7,\n    max_tokens: int = 2000,\n    logger = None\n)\n</code></pre> <p>Parameters: - <code>provider</code>: AI provider name (\"openai\" or \"anthropic\") - <code>model</code>: Model name (e.g., \"gpt-4-turbo-preview\", \"claude-3-opus-20240229\") - <code>api_key</code>: API key for the provider - <code>token_tracker</code>: TokenTracker instance for usage monitoring - <code>temperature</code>: Sampling temperature (0-2), default 0.7 - <code>max_tokens</code>: Maximum tokens per response, default 2000 - <code>logger</code>: Optional LoggingManager instance</p> <p>Raises: - <code>AIProviderError</code>: If provider initialization fails</p>"},{"location":"AI_INTERVIEWER/#methods","title":"Methods","text":""},{"location":"AI_INTERVIEWER/#initializesession_id-str-resume_data-optionalresumedata-none-none","title":"<code>initialize(session_id: str, resume_data: Optional[ResumeData] = None) -&gt; None</code>","text":"<p>Initialize interviewer for a new session.</p> <p>Parameters: - <code>session_id</code>: Session identifier - <code>resume_data</code>: Optional resume data for context-aware questions</p>"},{"location":"AI_INTERVIEWER/#start_interview-interviewresponse","title":"<code>start_interview() -&gt; InterviewResponse</code>","text":"<p>Start the interview with an opening question.</p> <p>Returns: - <code>InterviewResponse</code> with opening question and token usage</p> <p>Raises: - <code>AIProviderError</code>: If question generation fails</p>"},{"location":"AI_INTERVIEWER/#process_responsecandidate_response-str-whiteboard_image-optionalbytes-none-interviewresponse","title":"<code>process_response(candidate_response: str, whiteboard_image: Optional[bytes] = None) -&gt; InterviewResponse</code>","text":"<p>Process candidate response and generate follow-up question.</p> <p>Parameters: - <code>candidate_response</code>: Candidate's text response - <code>whiteboard_image</code>: Optional whiteboard image for analysis</p> <p>Returns: - <code>InterviewResponse</code> with follow-up question and token usage</p> <p>Raises: - <code>AIProviderError</code>: If response processing fails</p>"},{"location":"AI_INTERVIEWER/#generate_problemresume_data-resumedata-str","title":"<code>generate_problem(resume_data: ResumeData) -&gt; str</code>","text":"<p>Generate a system design problem tailored to candidate's resume.</p> <p>Parameters: - <code>resume_data</code>: Candidate's resume data</p> <p>Returns: - Problem statement string</p> <p>Raises: - <code>AIProviderError</code>: If problem generation fails</p>"},{"location":"AI_INTERVIEWER/#analyze_whiteboardwhiteboard_image-bytes-whiteboardanalysis","title":"<code>analyze_whiteboard(whiteboard_image: bytes) -&gt; WhiteboardAnalysis</code>","text":"<p>Analyze whiteboard diagram using vision-enabled LLM.</p> <p>Parameters: - <code>whiteboard_image</code>: Whiteboard image as bytes</p> <p>Returns: - <code>WhiteboardAnalysis</code> with identified elements</p> <p>Raises: - <code>AIProviderError</code>: If whiteboard analysis fails</p> <p>Note: Currently returns placeholder data. Full implementation requires vision-enabled models.</p>"},{"location":"AI_INTERVIEWER/#ask_clarifying_questionambiguous_response-str-interviewresponse","title":"<code>ask_clarifying_question(ambiguous_response: str) -&gt; InterviewResponse</code>","text":"<p>Generate a clarifying question for an ambiguous response.</p> <p>Parameters: - <code>ambiguous_response</code>: The candidate's ambiguous response</p> <p>Returns: - <code>InterviewResponse</code> with clarifying question and token usage</p> <p>Raises: - <code>AIProviderError</code>: If question generation fails</p>"},{"location":"AI_INTERVIEWER/#adapt_difficultyperformance_indicators-dictstr-any-none","title":"<code>adapt_difficulty(performance_indicators: Dict[str, Any]) -&gt; None</code>","text":"<p>Adapt question difficulty based on candidate performance.</p> <p>Parameters: - <code>performance_indicators</code>: Dictionary with performance metrics   - <code>response_quality</code>: \"high\", \"medium\", \"low\"   - <code>depth_of_understanding</code>: \"deep\", \"moderate\", \"shallow\"   - <code>technical_accuracy</code>: \"accurate\", \"mostly_accurate\", \"inaccurate\"</p>"},{"location":"AI_INTERVIEWER/#generate_followupcontext-conversationcontext-interviewresponse","title":"<code>generate_followup(context: ConversationContext) -&gt; InterviewResponse</code>","text":"<p>Generate a follow-up question based on conversation context.</p> <p>Parameters: - <code>context</code>: Conversation context with messages and metadata</p> <p>Returns: - <code>InterviewResponse</code> with follow-up question and token usage</p> <p>Raises: - <code>AIProviderError</code>: If follow-up generation fails</p>"},{"location":"AI_INTERVIEWER/#get_conversation_history-listmessage","title":"<code>get_conversation_history() -&gt; List[Message]</code>","text":"<p>Get the conversation history from memory.</p> <p>Returns: - List of Message objects representing the conversation</p>"},{"location":"AI_INTERVIEWER/#clear_memory-none","title":"<code>clear_memory() -&gt; None</code>","text":"<p>Clear conversation memory.</p>"},{"location":"AI_INTERVIEWER/#system-prompt","title":"System Prompt","text":"<p>The AI Interviewer uses a carefully crafted system prompt that defines its role and behavior:</p> <pre><code>You are an expert technical interviewer conducting a system design interview. \nYour role is to:\n1. Ask thoughtful, probing questions about system architecture and design\n2. Evaluate the candidate's understanding of scalability, reliability, and trade-offs\n3. Provide constructive follow-up questions based on their responses\n4. Adapt the difficulty based on the candidate's experience level\n5. Focus on real-world scenarios and practical considerations\n\nGuidelines:\n- Be professional and encouraging\n- Ask one question at a time\n- Listen carefully to responses before asking follow-ups\n- Cover key topics: scalability, reliability, data consistency, trade-offs, monitoring\n- Ask clarifying questions when responses are ambiguous\n- Probe deeper into design decisions and their implications\n\nRemember: You are evaluating their thought process, not just the final solution.\n</code></pre>"},{"location":"AI_INTERVIEWER/#resume-aware-problem-generation_1","title":"Resume-Aware Problem Generation","text":"<p>The interviewer generates problems tailored to the candidate's background:</p>"},{"location":"AI_INTERVIEWER/#experience-level-mapping","title":"Experience Level Mapping","text":"<ul> <li>Junior (0-2 years): Focus on basic system components and simple scaling</li> <li>Mid (3-5 years): Include distributed systems concepts and trade-offs</li> <li>Senior (6-10 years): Complex systems with multiple services and data consistency</li> <li>Staff (10+ years): Large-scale systems with organizational and technical challenges</li> </ul>"},{"location":"AI_INTERVIEWER/#domain-expertise-consideration","title":"Domain Expertise Consideration","text":"<p>Problems are tailored to the candidate's domain expertise: - Backend: API design, database optimization, caching strategies - Distributed Systems: Consistency models, partitioning, replication - Cloud: Cloud-native architectures, serverless, container orchestration - Frontend: Client-side architecture, state management, performance optimization</p>"},{"location":"AI_INTERVIEWER/#error-handling","title":"Error Handling","text":"<p>The AI Interviewer implements comprehensive error handling:</p> <ol> <li>Retry Logic: Automatic retry with exponential backoff for transient failures</li> <li>Graceful Degradation: Falls back to default behavior when optional features fail</li> <li>Detailed Logging: All errors logged with full context and stack traces</li> <li>Custom Exceptions: Uses <code>AIProviderError</code> for provider-specific errors</li> </ol>"},{"location":"AI_INTERVIEWER/#token-tracking","title":"Token Tracking","text":"<p>All API calls are tracked for cost monitoring:</p> <pre><code># Token usage is automatically recorded\nresponse = interviewer.process_response(candidate_response)\n\n# Access token usage\nprint(f\"Input tokens: {response.token_usage.input_tokens}\")\nprint(f\"Output tokens: {response.token_usage.output_tokens}\")\nprint(f\"Total tokens: {response.token_usage.total_tokens}\")\nprint(f\"Estimated cost: ${response.token_usage.estimated_cost:.6f}\")\n\n# Get session-level usage\nsession_usage = token_tracker.get_session_usage(session_id)\nprint(f\"Total session cost: ${session_usage.total_cost:.2f}\")\n</code></pre>"},{"location":"AI_INTERVIEWER/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Response Time: Typically 1-3 seconds per API call</li> <li>Token Limits: Configurable max_tokens parameter (default 2000)</li> <li>Memory Management: Conversation history stored in memory (consider truncation for long sessions)</li> <li>Retry Delays: 1s, 2s, 4s exponential backoff (max 3 attempts)</li> </ul>"},{"location":"AI_INTERVIEWER/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Vision API Integration: Full whiteboard analysis using GPT-4 Vision or Claude 3</li> <li>Streaming Responses: Real-time response streaming for better UX</li> <li>Multi-turn Planning: Advanced conversation planning for complex topics</li> <li>Performance Metrics: Real-time performance assessment during interview</li> <li>Custom Prompts: User-configurable system prompts for different interview styles</li> </ol>"},{"location":"AI_INTERVIEWER/#dependencies","title":"Dependencies","text":"<ul> <li><code>langchain</code>: Core LangChain framework</li> <li><code>langchain-openai</code>: OpenAI integration</li> <li><code>langchain-anthropic</code>: Anthropic integration</li> <li><code>openai</code>: OpenAI Python client</li> <li><code>anthropic</code>: Anthropic Python client</li> </ul>"},{"location":"AI_INTERVIEWER/#testing","title":"Testing","text":"<p>See <code>test_ai_interviewer.py</code> for comprehensive unit tests covering: - Initialization with different providers - Session management - Problem generation - Response processing - Clarifying questions - Difficulty adaptation - Whiteboard analysis - Conversation history management</p>"},{"location":"AI_INTERVIEWER/#related-components","title":"Related Components","text":"<ul> <li>TokenTracker (<code>src/ai/token_tracker.py</code>): Token usage tracking and cost estimation</li> <li>LoggingManager (<code>src/log_manager/logging_manager.py</code>): Comprehensive logging</li> <li>ResumeManager (<code>src/resume/resume_manager.py</code>): Resume parsing and analysis</li> <li>Models (<code>src/models.py</code>): Data models for interview components</li> </ul>"},{"location":"AI_INTERVIEWER/#example-complete-interview-flow","title":"Example: Complete Interview Flow","text":"<pre><code># Initialize components\ninterviewer = AIInterviewer(\n    provider=\"openai\",\n    model=\"gpt-4-turbo-preview\",\n    api_key=api_key,\n    token_tracker=token_tracker,\n    logger=logger\n)\n\n# Start session\ninterviewer.initialize(session_id, resume_data)\nopening = interviewer.start_interview()\nprint(f\"Interviewer: {opening.content}\")\n\n# Interview loop\nwhile not session_ended:\n    # Get candidate response\n    candidate_response = get_user_input()\n\n    # Process response\n    response = interviewer.process_response(candidate_response)\n    print(f\"Interviewer: {response.content}\")\n\n    # Track tokens\n    print(f\"Tokens: {response.token_usage.total_tokens}, Cost: ${response.token_usage.estimated_cost:.4f}\")\n\n    # Optionally adapt difficulty\n    if should_adapt_difficulty():\n        performance = assess_performance(candidate_response)\n        interviewer.adapt_difficulty(performance)\n\n# Get conversation history\nhistory = interviewer.get_conversation_history()\nsave_conversation(history)\n</code></pre>"},{"location":"AI_INTERVIEWER/#troubleshooting","title":"Troubleshooting","text":""},{"location":"AI_INTERVIEWER/#issue-api-rate-limits","title":"Issue: API Rate Limits","text":"<p>Solution: The retry logic handles rate limits automatically. If persistent, consider: - Reducing request frequency - Using a different model tier - Implementing request queuing</p>"},{"location":"AI_INTERVIEWER/#issue-high-token-usage","title":"Issue: High Token Usage","text":"<p>Solution: - Reduce <code>max_tokens</code> parameter - Truncate conversation history for long sessions - Use cheaper models for non-critical operations</p>"},{"location":"AI_INTERVIEWER/#issue-slow-response-times","title":"Issue: Slow Response Times","text":"<p>Solution: - Use faster models (e.g., GPT-3.5 Turbo instead of GPT-4) - Reduce <code>max_tokens</code> parameter - Implement response streaming (future enhancement)</p>"},{"location":"AI_INTERVIEWER/#issue-memory-growth","title":"Issue: Memory Growth","text":"<p>Solution: - Call <code>clear_memory()</code> periodically for very long sessions - Implement conversation history truncation - Consider using ConversationSummaryMemory for long sessions</p>"},{"location":"AI_INTERVIEWER/#support","title":"Support","text":"<p>For issues or questions: 1. Check the logs for detailed error messages 2. Review the test suite for usage examples 3. Consult the design document for architecture details 4. Check token usage and costs in the database</p>"},{"location":"ARCHITECTURE/","title":"Architecture Documentation","text":""},{"location":"ARCHITECTURE/#overview","title":"Overview","text":"<p>The AI Mock Interview Platform is a local proof-of-concept system designed to help candidates practice system design interviews with an AI interviewer. The architecture follows SOLID principles, uses dependency injection, and implements the repository pattern for data access.</p>"},{"location":"ARCHITECTURE/#system-architecture","title":"System Architecture","text":""},{"location":"ARCHITECTURE/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         User Interface                           \u2502\n\u2502                      (Streamlit Web App)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Application Layer                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502  \u2502   Session    \u2502  \u2502     AI       \u2502  \u2502  Evaluation  \u2502         \u2502\n\u2502  \u2502   Manager    \u2502  \u2502 Interviewer  \u2502  \u2502   Manager    \u2502         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502  \u2502Communication \u2502  \u2502    Resume    \u2502  \u2502    Token     \u2502         \u2502\n\u2502  \u2502   Manager    \u2502  \u2502   Manager    \u2502  \u2502   Tracker    \u2502         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Infrastructure Layer                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502  \u2502  PostgreSQL  \u2502  \u2502     File     \u2502  \u2502   Logging    \u2502         \u2502\n\u2502  \u2502  Data Store  \u2502  \u2502   Storage    \u2502  \u2502   Manager    \u2502         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#design-principles","title":"Design Principles","text":""},{"location":"ARCHITECTURE/#solid-principles","title":"SOLID Principles","text":"<p>The platform implements all five SOLID principles:</p> <ol> <li>Single Responsibility: Each component has one clear purpose</li> <li>Open-Closed: Extend through inheritance, not modification</li> <li>Liskov Substitution: Interfaces are interchangeable</li> <li>Interface Segregation: Focused, minimal interfaces</li> <li>Dependency Inversion: Depend on abstractions, not concretions</li> </ol>"},{"location":"ARCHITECTURE/#additional-patterns","title":"Additional Patterns","text":"<ul> <li>Repository Pattern: Abstracts data access</li> <li>Factory Pattern: Creates complex objects</li> <li>Strategy Pattern: Selects algorithms at runtime</li> <li>Dependency Injection: All dependencies injected through constructors</li> </ul>"},{"location":"ARCHITECTURE/#key-components","title":"Key Components","text":""},{"location":"ARCHITECTURE/#session-manager","title":"Session Manager","text":"<p>Orchestrates the interview lifecycle and coordinates between components.</p> <p>Responsibilities: - Create and configure interview sessions - Start and end sessions - Manage session state transitions - Coordinate between components</p>"},{"location":"ARCHITECTURE/#ai-interviewer","title":"AI Interviewer","text":"<p>Generates interview questions and analyzes candidate responses using LLMs.</p> <p>Responsibilities: - Generate initial interview problem based on resume - Analyze candidate responses - Generate follow-up questions - Maintain conversation context - Track token usage</p>"},{"location":"ARCHITECTURE/#communication-manager","title":"Communication Manager","text":"<p>Handles multi-modal communication (audio, video, whiteboard, screen share).</p> <p>Responsibilities: - Enable/disable communication modes - Coordinate between mode-specific handlers - Store media files - Manage transcription</p>"},{"location":"ARCHITECTURE/#evaluation-manager","title":"Evaluation Manager","text":"<p>Analyzes interview performance and generates comprehensive feedback.</p> <p>Responsibilities: - Analyze conversation quality - Evaluate system design approach - Generate competency scores - Create improvement plans</p>"},{"location":"ARCHITECTURE/#data-store","title":"Data Store","text":"<p>Manages data persistence using PostgreSQL.</p> <p>Responsibilities: - CRUD operations for all entities - Query optimization - Transaction management - Connection pooling</p>"},{"location":"ARCHITECTURE/#data-flow","title":"Data Flow","text":""},{"location":"ARCHITECTURE/#interview-session-flow","title":"Interview Session Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant UI\n    participant SM as Session Manager\n    participant AI as AI Interviewer\n    participant CM as Communication Manager\n    participant DS as Data Store\n\n    User-&gt;&gt;UI: Upload Resume\n    UI-&gt;&gt;SM: create_session(config)\n    SM-&gt;&gt;DS: save_session()\n    SM-&gt;&gt;AI: generate_initial_problem(resume)\n    AI--&gt;&gt;SM: problem\n    SM--&gt;&gt;UI: session + problem\n\n    User-&gt;&gt;UI: Start Interview\n    UI-&gt;&gt;SM: start_session(session_id)\n    SM-&gt;&gt;CM: enable_modes()\n    SM--&gt;&gt;UI: session started\n\n    loop Interview Interaction\n        User-&gt;&gt;UI: Provide Response\n        UI-&gt;&gt;CM: save_audio/whiteboard()\n        CM-&gt;&gt;DS: save_media_file()\n        UI-&gt;&gt;AI: process_response()\n        AI-&gt;&gt;DS: save_conversation()\n        AI--&gt;&gt;UI: follow_up_question\n    end\n\n    User-&gt;&gt;UI: End Interview\n    UI-&gt;&gt;SM: end_session(session_id)\n    SM-&gt;&gt;CM: disable_modes()\n    SM-&gt;&gt;AI: finalize_conversation()\n    SM-&gt;&gt;DS: update_session(status=COMPLETED)\n    SM--&gt;&gt;UI: session ended</code></pre>"},{"location":"ARCHITECTURE/#architecture-decision-records","title":"Architecture Decision Records","text":""},{"location":"ARCHITECTURE/#adr-001-use-postgresql-for-data-storage","title":"ADR-001: Use PostgreSQL for Data Storage","text":"<p>Status: Accepted</p> <p>Rationale: - ACID compliance ensures data integrity - Relational model fits structured interview data - JSON support for flexible metadata - Easy local deployment in Docker - Clear migration path to cloud PostgreSQL</p>"},{"location":"ARCHITECTURE/#adr-002-use-dependency-injection","title":"ADR-002: Use Dependency Injection","text":"<p>Status: Accepted</p> <p>Rationale: - Highly testable code with easy mocking - Can swap implementations without code changes - Clear, explicit dependencies - No framework overhead</p>"},{"location":"ARCHITECTURE/#adr-003-use-repository-pattern","title":"ADR-003: Use Repository Pattern","text":"<p>Status: Accepted</p> <p>Rationale: - Abstracts data access for future cloud migration - Easy to create in-memory implementations for tests - Separates business logic from data access - Enables swapping PostgreSQL for other databases</p>"},{"location":"ARCHITECTURE/#adr-004-use-langchain-for-llm-orchestration","title":"ADR-004: Use LangChain for LLM Orchestration","text":"<p>Status: Accepted</p> <p>Rationale: - Multi-provider support (OpenAI, Anthropic) - Built-in conversation memory - Structured prompt templates - Token tracking included</p>"},{"location":"ARCHITECTURE/#adr-005-use-streamlit-for-ui","title":"ADR-005: Use Streamlit for UI","text":"<p>Status: Accepted</p> <p>Rationale: - Rapid development with pure Python - Built-in interactive components - WebRTC and canvas support - Perfect for proof-of-concept</p>"},{"location":"ARCHITECTURE/#future-considerations","title":"Future Considerations","text":""},{"location":"ARCHITECTURE/#scalability","title":"Scalability","text":"<ul> <li>Multi-user support with authentication</li> <li>Cloud deployment (AWS/GCP/Azure)</li> <li>Horizontal scaling with load balancing</li> <li>Redis caching for session state</li> <li>CDN for media file delivery</li> </ul>"},{"location":"ARCHITECTURE/#performance","title":"Performance","text":"<ul> <li>Async processing for I/O operations</li> <li>Background jobs for evaluation generation</li> <li>Streaming LLM responses</li> <li>Database query optimization</li> </ul>"},{"location":"ARCHITECTURE/#features","title":"Features","text":"<ul> <li>Multiple interview types (coding, behavioral)</li> <li>Real-time collaboration</li> <li>Analytics dashboard</li> <li>Mobile support</li> <li>Integration with job boards</li> </ul> <p>For detailed component documentation, see the Components section.</p>"},{"location":"COMMUNICATION_MANAGER/","title":"Communication Manager Documentation","text":""},{"location":"COMMUNICATION_MANAGER/#overview","title":"Overview","text":"<p>The Communication Manager module provides comprehensive support for multiple communication modes during interview sessions, including audio, video, whiteboard, screen sharing, and transcript management.</p>"},{"location":"COMMUNICATION_MANAGER/#architecture","title":"Architecture","text":"<p>The Communication Manager follows a modular architecture with specialized handlers for each communication mode:</p> <pre><code>CommunicationManager (Coordinator)\n\u251c\u2500\u2500 AudioHandler (Audio capture &amp; transcription)\n\u251c\u2500\u2500 VideoHandler (Video recording)\n\u251c\u2500\u2500 WhiteboardHandler (Canvas snapshots)\n\u251c\u2500\u2500 ScreenShareHandler (Screen captures)\n\u2514\u2500\u2500 TranscriptHandler (Conversation transcript)\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#components","title":"Components","text":""},{"location":"COMMUNICATION_MANAGER/#1-communicationmanager","title":"1. CommunicationManager","text":"<p>Purpose: Coordinates between different communication mode handlers and tracks enabled modes.</p> <p>Key Features: - Enable/disable communication modes dynamically - Track active communication modes - Provide access to individual handlers - Coordinate between handlers</p> <p>Usage Example: <pre><code>from src.communication import CommunicationManager\nfrom src.models import CommunicationMode\n\n# Initialize manager\ncomm_manager = CommunicationManager(\n    file_storage=file_storage,\n    logger=logger\n)\n\n# Enable audio mode\ncomm_manager.enable_mode(CommunicationMode.AUDIO)\n\n# Check if mode is enabled\nif comm_manager.is_mode_enabled(CommunicationMode.AUDIO):\n    audio_handler = comm_manager.get_handler(CommunicationMode.AUDIO)\n\n# Get all enabled modes\nenabled_modes = comm_manager.get_enabled_modes()\n\n# Disable mode\ncomm_manager.disable_mode(CommunicationMode.AUDIO)\n</code></pre></p>"},{"location":"COMMUNICATION_MANAGER/#2-audiohandler","title":"2. AudioHandler","text":"<p>Purpose: Handles audio recording and real-time transcription using OpenAI Whisper.</p> <p>Key Features: - Real-time audio capture via streamlit-webrtc - Audio transcription using OpenAI Whisper (&lt; 2 seconds) - WAV format audio storage - Transcript text storage - Recording state management</p> <p>Usage Example: <pre><code>from src.communication.audio_handler import AudioHandler\n\n# Initialize handler\naudio_handler = AudioHandler(\n    file_storage=file_storage,\n    whisper_client=openai_client,\n    logger=logger,\n    sample_rate=16000,\n    channels=1\n)\n\n# Start recording\naudio_handler.start_recording(session_id)\n\n# Record and save audio\naudio_path = audio_handler.record_audio(\n    session_id=session_id,\n    audio_data=audio_bytes,\n    duration_seconds=5.2\n)\n\n# Transcribe audio\ntranscript = audio_handler.transcribe_audio(\n    audio_file_path=audio_path,\n    language=\"en\"\n)\n\n# Save transcript\ntranscript_path = audio_handler.save_transcript(\n    session_id=session_id,\n    transcript_text=transcript,\n    audio_file_path=audio_path\n)\n\n# Combined operation\naudio_path, transcript = audio_handler.record_and_transcribe(\n    session_id=session_id,\n    audio_data=audio_bytes,\n    duration_seconds=5.2,\n    on_transcription_complete=lambda text: print(f\"Transcribed: {text}\")\n)\n\n# Stop recording\nmetadata = audio_handler.stop_recording(session_id)\n</code></pre></p> <p>Configuration: - <code>sample_rate</code>: Audio sample rate in Hz (default: 16000) - <code>channels</code>: Number of audio channels (default: 1 for mono) - <code>audio_format</code>: File format (default: wav)</p>"},{"location":"COMMUNICATION_MANAGER/#3-videohandler","title":"3. VideoHandler","text":"<p>Purpose: Captures and stores video streams during interview sessions.</p> <p>Key Features: - Video stream capture - H264 codec support - WebM/MP4 format storage - Recording state management - Chunk-based recording</p> <p>Usage Example: <pre><code>from src.communication.video_handler import VideoHandler\n\n# Initialize handler\nvideo_handler = VideoHandler(\n    file_storage=file_storage,\n    logger=logger,\n    fps=30,\n    resolution=\"1280x720\",\n    video_format=\"webm\"\n)\n\n# Start recording\nvideo_handler.start_recording(session_id)\n\n# Add video chunks\nvideo_handler.add_video_chunk(session_id, chunk_data)\n\n# Get recording duration\nduration = video_handler.get_recording_duration(session_id)\n\n# Save complete recording\nvideo_path = video_handler.save_recording(session_id)\n\n# Or capture directly\nvideo_path = video_handler.capture_video(\n    session_id=session_id,\n    video_data=video_bytes,\n    duration_seconds=30.5,\n    codec=\"h264\"\n)\n\n# Stop recording\nmetadata = video_handler.stop_recording(session_id)\n</code></pre></p> <p>Configuration: - <code>fps</code>: Frames per second (default: 30) - <code>resolution</code>: Video resolution as \"WIDTHxHEIGHT\" (default: 1280x720) - <code>video_format</code>: File format (default: webm)</p>"},{"location":"COMMUNICATION_MANAGER/#4-whiteboardhandler","title":"4. WhiteboardHandler","text":"<p>Purpose: Manages whiteboard canvas operations and snapshot storage.</p> <p>Key Features: - Canvas snapshot saving (PNG format) - Snapshot tracking and retrieval - Auto-save functionality - Snapshot export - Canvas clearing</p> <p>Usage Example: <pre><code>from src.communication.whiteboard_handler import WhiteboardHandler\n\n# Initialize handler\nwhiteboard_handler = WhiteboardHandler(\n    file_storage=file_storage,\n    logger=logger,\n    canvas_width=800,\n    canvas_height=600\n)\n\n# Save snapshot\nsnapshot_path = whiteboard_handler.save_whiteboard(\n    session_id=session_id,\n    canvas_data=canvas_image_bytes,\n    snapshot_number=1,\n    metadata={\"description\": \"Initial system design\"}\n)\n\n# Auto-save snapshot\nauto_path = whiteboard_handler.auto_save_snapshot(\n    session_id=session_id,\n    canvas_data=canvas_image_bytes,\n    interval_seconds=60\n)\n\n# Get all snapshots\nsnapshots = whiteboard_handler.get_snapshots(session_id)\n\n# Get latest snapshot\nlatest = whiteboard_handler.get_latest_snapshot(session_id)\n\n# Get snapshot count\ncount = whiteboard_handler.get_snapshot_count(session_id)\n\n# Export snapshots\nexported_files = whiteboard_handler.export_snapshots(\n    session_id=session_id,\n    export_dir=\"/path/to/export\"\n)\n\n# Clear canvas (logical operation)\nwhiteboard_handler.clear_canvas(session_id)\n\n# Get canvas configuration\nconfig = whiteboard_handler.get_canvas_config()\n</code></pre></p> <p>Configuration: - <code>canvas_width</code>: Canvas width in pixels (default: 800) - <code>canvas_height</code>: Canvas height in pixels (default: 600) - <code>image_format</code>: Image format (default: png)</p>"},{"location":"COMMUNICATION_MANAGER/#5-screensharehandler","title":"5. ScreenShareHandler","text":"<p>Purpose: Captures screen content at regular intervals (5-second intervals).</p> <p>Key Features: - Periodic screen capture (default: 5 seconds) - PNG format storage - Capture tracking and retrieval - Capture statistics - Export functionality</p> <p>Usage Example: <pre><code>from src.communication.screen_handler import ScreenShareHandler\n\n# Initialize handler\nscreen_handler = ScreenShareHandler(\n    file_storage=file_storage,\n    logger=logger,\n    capture_interval_seconds=5\n)\n\n# Start capture session\nscreen_handler.start_capture(session_id)\n\n# Capture screen\ncapture_path = screen_handler.capture_screen(\n    session_id=session_id,\n    screen_data=screen_image_bytes,\n    capture_number=1,\n    metadata={\"resolution\": \"1920x1080\"}\n)\n\n# Get capture count\ncount = screen_handler.get_capture_count(session_id)\n\n# Get all captures\ncaptures = screen_handler.get_captures(session_id)\n\n# Get latest capture\nlatest = screen_handler.get_latest_capture(session_id)\n\n# Get capture duration\nduration = screen_handler.get_capture_duration(session_id)\n\n# Get capture statistics\nstats = screen_handler.get_capture_stats(session_id)\n\n# Export captures\nexported_files = screen_handler.export_captures(\n    session_id=session_id,\n    export_dir=\"/path/to/export\"\n)\n\n# Stop capture\nmetadata = screen_handler.stop_capture(session_id)\n</code></pre></p> <p>Configuration: - <code>capture_interval_seconds</code>: Interval between captures (default: 5) - <code>image_format</code>: Image format (default: png)</p> <p>Design Rationale: The 5-second capture interval balances: - Storage efficiency (vs. continuous video) - Performance (minimal CPU/memory overhead) - Usefulness (captures meaningful changes) - Review capability (sufficient granularity) - Cost (reduces AI analysis costs)</p>"},{"location":"COMMUNICATION_MANAGER/#6-transcripthandler","title":"6. TranscriptHandler","text":"<p>Purpose: Manages real-time conversation transcripts with search and export.</p> <p>Key Features: - Real-time transcript entry addition - Timestamp and speaker tracking - Search functionality - Speaker filtering - JSON and text export - Transcript statistics</p> <p>Usage Example: <pre><code>from src.communication.transcript_handler import TranscriptHandler\n\n# Initialize handler\ntranscript_handler = TranscriptHandler(\n    file_storage=file_storage,\n    logger=logger\n)\n\n# Add transcript entry\nentry = transcript_handler.add_entry(\n    session_id=session_id,\n    speaker=\"interviewer\",\n    text=\"Can you explain your approach to scaling this system?\",\n    metadata={\"source\": \"ai_interviewer\"}\n)\n\n# Get complete transcript\ntranscript = transcript_handler.get_transcript(session_id)\n\n# Get recent entries\nrecent = transcript_handler.get_recent_entries(session_id, count=5)\n\n# Search transcript\nmatches = transcript_handler.search_transcript(\n    session_id=session_id,\n    query=\"scaling\",\n    case_sensitive=False\n)\n\n# Filter by speaker\ninterviewer_entries = transcript_handler.filter_by_speaker(\n    session_id=session_id,\n    speaker=\"interviewer\"\n)\n\n# Get entry count\ncount = transcript_handler.get_entry_count(session_id)\n\n# Save transcript\njson_path = transcript_handler.save_transcript(\n    session_id=session_id,\n    format=\"json\"\n)\n\ntxt_path = transcript_handler.save_transcript(\n    session_id=session_id,\n    format=\"txt\"\n)\n\n# Export transcript\nexport_path = transcript_handler.export_transcript(\n    session_id=session_id,\n    export_path=\"/path/to/export/transcript.json\",\n    format=\"json\"\n)\n\n# Get transcript statistics\nstats = transcript_handler.get_transcript_stats(session_id)\n# Returns: entry_count, total_words, total_characters, speakers, \n#          speaker_counts, duration_seconds, start_time, end_time\n\n# Load transcript from file\nloaded_transcript = transcript_handler.load_transcript(\n    session_id=session_id,\n    file_path=\"path/to/transcript.json\"\n)\n\n# Clear transcript\ntranscript_handler.clear_transcript(session_id)\n</code></pre></p> <p>TranscriptEntry Structure: <pre><code>@dataclass\nclass TranscriptEntry:\n    timestamp: datetime\n    speaker: str  # \"interviewer\" or \"candidate\"\n    text: str\n    metadata: Dict[str, Any]\n</code></pre></p>"},{"location":"COMMUNICATION_MANAGER/#integration-with-other-components","title":"Integration with Other Components","text":""},{"location":"COMMUNICATION_MANAGER/#file-storage-integration","title":"File Storage Integration","text":"<p>All handlers integrate with the FileStorage component for persistent storage:</p> <pre><code># Initialize file storage\nfile_storage = FileStorage(base_dir=\"./data/sessions\")\n\n# Initialize handlers with file storage\naudio_handler = AudioHandler(file_storage=file_storage)\nvideo_handler = VideoHandler(file_storage=file_storage)\nwhiteboard_handler = WhiteboardHandler(file_storage=file_storage)\nscreen_handler = ScreenShareHandler(file_storage=file_storage)\ntranscript_handler = TranscriptHandler(file_storage=file_storage)\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#logging-integration","title":"Logging Integration","text":"<p>All handlers support optional logging:</p> <pre><code>from src.log_manager import LoggingManager\n\n# Initialize logger\nlogger = LoggingManager(config=logging_config)\n\n# Initialize handlers with logger\naudio_handler = AudioHandler(\n    file_storage=file_storage,\n    logger=logger\n)\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#database-integration","title":"Database Integration","text":"<p>Handlers can optionally integrate with the database for storing file references:</p> <pre><code>from src.database.data_store import PostgresDataStore\n\n# Initialize data store\ndata_store = PostgresDataStore(connection_string=db_url)\n\n# Initialize handlers with data store\naudio_handler = AudioHandler(\n    file_storage=file_storage,\n    data_store=data_store\n)\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#file-organization","title":"File Organization","text":"<p>Media files are organized by session and type:</p> <pre><code>data/sessions/\n\u2514\u2500\u2500 {session_id}/\n    \u251c\u2500\u2500 audio/\n    \u2502   \u251c\u2500\u2500 audio_20241110_143000_123456.wav\n    \u2502   \u251c\u2500\u2500 audio_20241110_143000_123456_transcript.txt\n    \u2502   \u2514\u2500\u2500 audio_20241110_143030_789012.wav\n    \u251c\u2500\u2500 video/\n    \u2502   \u2514\u2500\u2500 video_20241110_143000_456789.webm\n    \u251c\u2500\u2500 whiteboard/\n    \u2502   \u251c\u2500\u2500 whiteboard_20241110_143015_234567.png\n    \u2502   \u2514\u2500\u2500 whiteboard_20241110_143045_890123.png\n    \u251c\u2500\u2500 screen/\n    \u2502   \u251c\u2500\u2500 screen_20241110_143005_345678.png\n    \u2502   \u2514\u2500\u2500 screen_20241110_143010_901234.png\n    \u2514\u2500\u2500 transcript_20241110_143100.json\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#error-handling","title":"Error Handling","text":"<p>All handlers raise <code>CommunicationError</code> for operation failures:</p> <pre><code>from src.exceptions import CommunicationError\n\ntry:\n    audio_path = audio_handler.record_audio(session_id, audio_data)\nexcept CommunicationError as e:\n    logger.error(f\"Audio recording failed: {e}\")\n    # Handle error gracefully\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#performance-considerations","title":"Performance Considerations","text":""},{"location":"COMMUNICATION_MANAGER/#audio-transcription","title":"Audio Transcription","text":"<ul> <li>Target: &lt; 2 seconds for transcription</li> <li>Uses OpenAI Whisper API</li> <li>Asynchronous processing recommended for UI responsiveness</li> </ul>"},{"location":"COMMUNICATION_MANAGER/#video-recording","title":"Video Recording","text":"<ul> <li>Chunk-based recording for memory efficiency</li> <li>H264 codec for compression</li> <li>Consider storage limits for long sessions</li> </ul>"},{"location":"COMMUNICATION_MANAGER/#whiteboard-snapshots","title":"Whiteboard Snapshots","text":"<ul> <li>PNG format for lossless quality</li> <li>Target: &lt; 1 second for snapshot save</li> <li>Auto-save at regular intervals (60 seconds)</li> </ul>"},{"location":"COMMUNICATION_MANAGER/#screen-captures","title":"Screen Captures","text":"<ul> <li>5-second interval balances storage and usefulness</li> <li>PNG format for text readability</li> <li>Periodic cleanup recommended for old sessions</li> </ul>"},{"location":"COMMUNICATION_MANAGER/#transcript-updates","title":"Transcript Updates","text":"<ul> <li>Real-time updates (&lt; 2 seconds)</li> <li>In-memory storage during session</li> <li>Periodic saves to filesystem</li> </ul>"},{"location":"COMMUNICATION_MANAGER/#testing","title":"Testing","text":"<p>Example test structure:</p> <pre><code>def test_audio_handler_record():\n    \"\"\"Test audio recording functionality.\"\"\"\n    handler = AudioHandler(file_storage=mock_storage)\n    audio_path = handler.record_audio(\n        session_id=\"test-session\",\n        audio_data=b\"mock audio data\"\n    )\n    assert audio_path is not None\n    assert \"audio\" in audio_path\n\ndef test_transcript_search():\n    \"\"\"Test transcript search functionality.\"\"\"\n    handler = TranscriptHandler(file_storage=mock_storage)\n    handler.add_entry(\"session-1\", \"interviewer\", \"scaling systems\")\n    handler.add_entry(\"session-1\", \"candidate\", \"load balancing\")\n\n    results = handler.search_transcript(\"session-1\", \"scaling\")\n    assert len(results) == 1\n    assert results[0].speaker == \"interviewer\"\n</code></pre>"},{"location":"COMMUNICATION_MANAGER/#requirements-mapping","title":"Requirements Mapping","text":"<p>This implementation satisfies the following requirements:</p> <ul> <li>Requirement 2.1, 2.2: Communication mode selection and management</li> <li>Requirement 2.3, 2.4, 2.10: Audio capture and transcription</li> <li>Requirement 2.5: Video recording</li> <li>Requirement 2.6: Screen share capture</li> <li>Requirement 3.1, 3.2, 3.3, 3.4, 3.5: Whiteboard canvas operations</li> <li>Requirement 18.3, 18.5: Real-time transcript display and functionality</li> </ul>"},{"location":"COMMUNICATION_MANAGER/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements for future iterations:</p> <ol> <li>Audio: Support for multiple audio formats (MP3, OGG)</li> <li>Video: Live streaming support</li> <li>Whiteboard: Collaborative drawing features</li> <li>Screen: Adaptive capture intervals based on activity</li> <li>Transcript: Real-time translation support</li> <li>General: Cloud storage integration for media files</li> </ol>"},{"location":"DEVELOPER_SETUP_GUIDE/","title":"Developer Setup Guide - AI Mock Interview Platform","text":"<p>This guide provides comprehensive instructions for developers who want to contribute to or extend the AI Mock Interview Platform.</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Prerequisites</li> <li>Environment Setup</li> <li>Local Development</li> <li>Running Tests</li> <li>Debugging</li> <li>Development Workflows</li> <li>Code Quality</li> <li>Architecture Overview</li> <li>Contributing</li> </ul>"},{"location":"DEVELOPER_SETUP_GUIDE/#prerequisites","title":"Prerequisites","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#required-software","title":"Required Software","text":"Software Version Purpose Download Link Python 3.10+ Runtime environment python.org Docker Desktop Latest Container orchestration docker.com Git Latest Version control git-scm.com PostgreSQL Client 15+ Database management (optional) postgresql.org"},{"location":"DEVELOPER_SETUP_GUIDE/#recommended-tools","title":"Recommended Tools","text":"<ul> <li>IDE: VS Code, PyCharm, or similar</li> <li>API Testing: Postman or curl</li> <li>Database GUI: pgAdmin, DBeaver, or TablePlus</li> <li>Terminal: iTerm2 (macOS), Windows Terminal, or similar</li> </ul>"},{"location":"DEVELOPER_SETUP_GUIDE/#api-keys","title":"API Keys","text":"<p>You'll need API keys for development: - OpenAI API Key (required): platform.openai.com - Anthropic API Key (optional): console.anthropic.com</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#environment-setup","title":"Environment Setup","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd ai-mock-interview-platform\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#2-create-python-virtual-environment","title":"2. Create Python Virtual Environment","text":"<p>macOS/Linux: <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre></p> <p>Windows: <pre><code>python -m venv venv\nvenv\\Scripts\\activate\n</code></pre></p> <p>Verify activation: <pre><code>which python  # macOS/Linux\nwhere python  # Windows\n# Should point to venv/bin/python or venv\\Scripts\\python\n</code></pre></p>"},{"location":"DEVELOPER_SETUP_GUIDE/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Install production dependencies\npip install -r requirements.txt\n\n# Install development dependencies\npip install -r requirements-dev.txt\n\n# Verify installation\npip list\n</code></pre> <p>Key Dependencies: - <code>streamlit</code>: Web UI framework - <code>langchain</code>: LLM orchestration - <code>openai</code>: OpenAI API client - <code>anthropic</code>: Anthropic API client - <code>psycopg2-binary</code>: PostgreSQL adapter - <code>streamlit-webrtc</code>: Audio/video capture - <code>streamlit-drawable-canvas</code>: Whiteboard component - <code>pytest</code>: Testing framework - <code>black</code>: Code formatter - <code>ruff</code>: Linter - <code>mypy</code>: Type checker</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#4-configure-environment-variables","title":"4. Configure Environment Variables","text":"<p>Create a <code>.env</code> file in the project root:</p> <pre><code>cp .env.template .env\n</code></pre> <p>Edit <code>.env</code> with your configuration:</p> <pre><code># Database Configuration\nDB_PASSWORD=dev_password_123\nDATABASE_URL=postgresql://interview_user:dev_password_123@localhost:5432/interview_platform\n\n# AI Provider API Keys\nOPENAI_API_KEY=sk-proj-your-key-here\nANTHROPIC_API_KEY=sk-ant-your-key-here\n\n# Application Configuration\nLOG_LEVEL=DEBUG  # Use DEBUG for development\nDATA_DIR=./data\nENVIRONMENT=development\n\n# Optional: Token Budget\nMAX_TOKENS_PER_SESSION=50000\nTOKEN_BUDGET_WARNING_THRESHOLD=0.8\n\n# Optional: Feature Flags\nENABLE_VIDEO_RECORDING=true\nENABLE_SCREEN_SHARE=true\nENABLE_AUDIO_TRANSCRIPTION=true\n</code></pre> <p>Environment Variable Reference:</p> Variable Required Default Description <code>DB_PASSWORD</code> Yes - PostgreSQL password <code>DATABASE_URL</code> Yes - Full database connection string <code>OPENAI_API_KEY</code> Yes - OpenAI API key for GPT-4 <code>ANTHROPIC_API_KEY</code> No - Anthropic API key for Claude <code>LOG_LEVEL</code> No INFO Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL) <code>DATA_DIR</code> No ./data Directory for media file storage <code>ENVIRONMENT</code> No production Environment name (development, staging, production) <code>MAX_TOKENS_PER_SESSION</code> No 50000 Maximum tokens per interview session <code>TOKEN_BUDGET_WARNING_THRESHOLD</code> No 0.8 Warn when 80% of token budget used"},{"location":"DEVELOPER_SETUP_GUIDE/#5-start-docker-services","title":"5. Start Docker Services","text":"<pre><code># Start PostgreSQL and other services\ndocker-compose up -d\n\n# Verify services are running\ndocker-compose ps\n\n# Check logs\ndocker-compose logs -f postgres\n</code></pre> <p>Expected output: <pre><code>NAME                          STATUS              PORTS\ninterview_platform_db         Up 30 seconds       0.0.0.0:5432-&gt;5432/tcp\n</code></pre></p>"},{"location":"DEVELOPER_SETUP_GUIDE/#6-initialize-database","title":"6. Initialize Database","text":"<p>The database schema is automatically initialized when PostgreSQL starts for the first time using <code>init.sql</code>. To manually reinitialize:</p> <pre><code># Connect to database\ndocker exec -it interview_platform_db psql -U interview_user -d interview_platform\n\n# Verify tables exist\n\\dt\n\n# Expected tables:\n# - resumes\n# - sessions\n# - conversations\n# - evaluations\n# - media_files\n# - token_usage\n# - audit_logs\n\n# Exit psql\n\\q\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#7-verify-setup","title":"7. Verify Setup","text":"<p>Run the validation script to ensure everything is configured correctly:</p> <pre><code>python validate_setup.py\n</code></pre> <p>This checks: - Python version - Required packages installed - Environment variables set - Docker services running - Database connectivity - API keys valid</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#local-development","title":"Local Development","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#running-the-application","title":"Running the Application","text":"<p>Option 1: Using Streamlit directly (recommended for development)</p> <pre><code># Activate virtual environment\nsource venv/bin/activate  # macOS/Linux\nvenv\\Scripts\\activate     # Windows\n\n# Run Streamlit app\nstreamlit run src/main.py\n\n# App will open at http://localhost:8501\n</code></pre> <p>Option 2: Using Docker Compose</p> <pre><code># Build and start all services\ndocker-compose up --build\n\n# Run in detached mode\ndocker-compose up -d --build\n\n# View logs\ndocker-compose logs -f app\n</code></pre> <p>Option 3: Using startup script</p> <pre><code># Make script executable (first time only)\nchmod +x startup.sh\n\n# Run startup script\n./startup.sh\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#hot-reloading","title":"Hot Reloading","text":"<p>Streamlit automatically reloads when you save changes to Python files. You'll see:</p> <pre><code>Source file changed: src/main.py\nRerunning...\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#project-structure","title":"Project Structure","text":"<pre><code>ai-mock-interview-platform/\n\u251c\u2500\u2500 src/                          # Application source code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py                   # Streamlit entry point\n\u2502   \u251c\u2500\u2500 app_factory.py            # Dependency injection setup\n\u2502   \u251c\u2500\u2500 config.py                 # Configuration management\n\u2502   \u251c\u2500\u2500 models.py                 # Data models and types\n\u2502   \u251c\u2500\u2500 exceptions.py             # Custom exception classes\n\u2502   \u251c\u2500\u2500 ai/                       # AI components\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 ai_interviewer.py    # LLM-powered interviewer\n\u2502   \u2502   \u2514\u2500\u2500 token_tracker.py     # Token usage tracking\n\u2502   \u251c\u2500\u2500 communication/            # Communication handlers\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 communication_manager.py\n\u2502   \u2502   \u251c\u2500\u2500 audio_handler.py\n\u2502   \u2502   \u251c\u2500\u2500 video_handler.py\n\u2502   \u2502   \u251c\u2500\u2500 whiteboard_handler.py\n\u2502   \u2502   \u251c\u2500\u2500 screen_handler.py\n\u2502   \u2502   \u2514\u2500\u2500 transcript_handler.py\n\u2502   \u251c\u2500\u2500 database/                 # Data persistence\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 data_store.py        # PostgreSQL implementation\n\u2502   \u251c\u2500\u2500 evaluation/               # Evaluation system\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 evaluation_manager.py\n\u2502   \u251c\u2500\u2500 log_manager/              # Logging system\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 logging_manager.py\n\u2502   \u251c\u2500\u2500 resume/                   # Resume processing\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 resume_manager.py\n\u2502   \u251c\u2500\u2500 session/                  # Session management\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 session_manager.py\n\u2502   \u251c\u2500\u2500 storage/                  # File storage\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 file_storage.py\n\u2502   \u2514\u2500\u2500 ui/                       # UI components\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 pages/\n\u2502           \u251c\u2500\u2500 setup.py          # Resume upload &amp; config\n\u2502           \u251c\u2500\u2500 interview.py      # Main interview interface\n\u2502           \u251c\u2500\u2500 evaluation.py     # Evaluation display\n\u2502           \u2514\u2500\u2500 history.py        # Session history\n\u251c\u2500\u2500 tests/                        # Test files\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_ai_interviewer.py\n\u2502   \u251c\u2500\u2500 test_communication_handlers.py\n\u2502   \u251c\u2500\u2500 test_communication_manager.py\n\u2502   \u251c\u2500\u2500 test_evaluation_manager.py\n\u2502   \u251c\u2500\u2500 test_file_storage.py\n\u2502   \u251c\u2500\u2500 test_logging.py\n\u2502   \u251c\u2500\u2500 test_resume_manager.py\n\u2502   \u251c\u2500\u2500 test_session_manager.py\n\u2502   \u251c\u2500\u2500 test_token_tracker.py\n\u2502   \u2514\u2500\u2500 integration/              # Integration tests\n\u2502       \u251c\u2500\u2500 test_integration_workflow.py\n\u2502       \u251c\u2500\u2500 test_integration_multimode.py\n\u2502       \u2514\u2500\u2500 test_integration_error_recovery.py\n\u251c\u2500\u2500 docs/                         # Documentation\n\u2502   \u251c\u2500\u2500 QUICK_START_GUIDE.md\n\u2502   \u251c\u2500\u2500 DEVELOPER_SETUP_GUIDE.md\n\u2502   \u251c\u2500\u2500 ARCHITECTURE.md\n\u2502   \u251c\u2500\u2500 LOGGING.md\n\u2502   \u2514\u2500\u2500 API_REFERENCE.md\n\u251c\u2500\u2500 data/                         # Local data storage\n\u2502   \u2514\u2500\u2500 sessions/                 # Session media files\n\u251c\u2500\u2500 logs/                         # Application logs\n\u2502   \u2514\u2500\u2500 interview_platform.log\n\u251c\u2500\u2500 .streamlit/                   # Streamlit configuration\n\u2502   \u2514\u2500\u2500 config.toml\n\u251c\u2500\u2500 .github/                      # GitHub Actions workflows\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 ci.yml\n\u251c\u2500\u2500 docker-compose.yml            # Docker services\n\u251c\u2500\u2500 Dockerfile                    # Application container\n\u251c\u2500\u2500 init.sql                      # Database schema\n\u251c\u2500\u2500 requirements.txt              # Production dependencies\n\u251c\u2500\u2500 requirements-dev.txt          # Development dependencies\n\u251c\u2500\u2500 config.yaml                   # Application configuration\n\u251c\u2500\u2500 startup.sh                    # Automated setup script\n\u251c\u2500\u2500 .env.template                 # Environment template\n\u251c\u2500\u2500 .env                          # Environment variables (gitignored)\n\u251c\u2500\u2500 .gitignore                    # Git ignore rules\n\u251c\u2500\u2500 .pre-commit-config.yaml       # Pre-commit hooks\n\u251c\u2500\u2500 pytest.ini                    # Pytest configuration\n\u251c\u2500\u2500 pyproject.toml                # Python project metadata\n\u2514\u2500\u2500 README.md                     # Project overview\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#running-tests","title":"Running Tests","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#unit-tests","title":"Unit Tests","text":"<pre><code># Run all tests\npytest\n\n# Run specific test file\npytest tests/test_session_manager.py\n\n# Run specific test function\npytest tests/test_session_manager.py::test_create_session\n\n# Run with verbose output\npytest -v\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Open coverage report\nopen htmlcov/index.html  # macOS\nstart htmlcov/index.html # Windows\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#integration-tests","title":"Integration Tests","text":"<pre><code># Run integration tests only\npytest tests/integration/\n\n# Run specific integration test\npytest tests/integration/test_integration_workflow.py\n\n# Run with markers\npytest -m integration\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#test-configuration","title":"Test Configuration","text":"<p>pytest.ini: <pre><code>[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\nmarkers =\n    integration: Integration tests\n    slow: Slow-running tests\n    unit: Unit tests\naddopts = \n    --strict-markers\n    --tb=short\n    -ra\n</code></pre></p>"},{"location":"DEVELOPER_SETUP_GUIDE/#writing-tests","title":"Writing Tests","text":"<p>Example unit test:</p> <pre><code>import pytest\nfrom src.session.session_manager import SessionManager\nfrom src.models import SessionConfig, CommunicationMode\n\ndef test_create_session(mock_data_store, mock_ai_interviewer):\n    \"\"\"Test session creation with valid configuration.\"\"\"\n    # Arrange\n    session_manager = SessionManager(\n        data_store=mock_data_store,\n        ai_interviewer=mock_ai_interviewer,\n        evaluation_manager=mock_evaluation_manager,\n        communication_manager=mock_communication_manager,\n        logger=mock_logger\n    )\n    config = SessionConfig(\n        enabled_modes=[CommunicationMode.TEXT, CommunicationMode.WHITEBOARD],\n        ai_provider=\"openai\",\n        ai_model=\"gpt-4\"\n    )\n\n    # Act\n    session = session_manager.create_session(config)\n\n    # Assert\n    assert session.id is not None\n    assert session.status == SessionStatus.ACTIVE\n    assert len(session.config.enabled_modes) == 2\n    mock_data_store.save_session.assert_called_once()\n</code></pre> <p>Example integration test:</p> <pre><code>import pytest\nfrom src.app_factory import create_app\n\n@pytest.mark.integration\ndef test_complete_interview_workflow(test_database):\n    \"\"\"Test complete interview workflow from start to evaluation.\"\"\"\n    # Arrange\n    app = create_app()\n    resume_data = create_test_resume()\n\n    # Act - Create session\n    session = app.session_manager.create_session(\n        config=create_test_config(resume_data)\n    )\n\n    # Act - Start interview\n    app.session_manager.start_session(session.id)\n\n    # Act - Process responses\n    response1 = app.ai_interviewer.process_response(\n        session.id,\n        \"I would design a distributed system with...\"\n    )\n\n    # Act - End session\n    evaluation = app.session_manager.end_session(session.id)\n\n    # Assert\n    assert evaluation is not None\n    assert evaluation.overall_score &gt; 0\n    assert len(evaluation.competency_scores) &gt; 0\n    assert len(evaluation.improvement_plan.concrete_steps) &gt; 0\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#debugging","title":"Debugging","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#vs-code-configuration","title":"VS Code Configuration","text":"<p>Create <code>.vscode/launch.json</code>:</p> <pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"Python: Streamlit\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"module\": \"streamlit\",\n      \"args\": [\n        \"run\",\n        \"src/main.py\",\n        \"--server.port=8501\"\n      ],\n      \"console\": \"integratedTerminal\",\n      \"justMyCode\": false,\n      \"env\": {\n        \"PYTHONPATH\": \"${workspaceFolder}\"\n      }\n    },\n    {\n      \"name\": \"Python: Current File\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"program\": \"${file}\",\n      \"console\": \"integratedTerminal\",\n      \"justMyCode\": false\n    },\n    {\n      \"name\": \"Python: Pytest\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"module\": \"pytest\",\n      \"args\": [\n        \"-v\",\n        \"${file}\"\n      ],\n      \"console\": \"integratedTerminal\",\n      \"justMyCode\": false\n    }\n  ]\n}\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#pycharm-configuration","title":"PyCharm Configuration","text":"<ol> <li>Run Configuration for Streamlit:</li> <li>Script path: <code>&lt;path-to-venv&gt;/bin/streamlit</code></li> <li>Parameters: <code>run src/main.py --server.port=8501</code></li> <li> <p>Working directory: <code>&lt;project-root&gt;</code></p> </li> <li> <p>Run Configuration for Tests:</p> </li> <li>Target: <code>tests/</code></li> <li>Pattern: <code>test_*.py</code></li> <li>Working directory: <code>&lt;project-root&gt;</code></li> </ol>"},{"location":"DEVELOPER_SETUP_GUIDE/#debugging-tips","title":"Debugging Tips","text":"<p>1. Enable Debug Logging:</p> <pre><code># In your code\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>Or set in <code>.env</code>: <pre><code>LOG_LEVEL=DEBUG\n</code></pre></p> <p>2. Use Breakpoints:</p> <pre><code># Add breakpoint in code\nimport pdb; pdb.set_trace()\n\n# Or use IDE breakpoints (recommended)\n</code></pre> <p>3. Inspect Database:</p> <pre><code># Connect to database\ndocker exec -it interview_platform_db psql -U interview_user -d interview_platform\n\n# Query sessions\nSELECT id, status, created_at FROM sessions ORDER BY created_at DESC LIMIT 10;\n\n# Query conversations\nSELECT role, content, timestamp FROM conversations WHERE session_id = '&lt;session-id&gt;';\n\n# Query logs\nSELECT level, component, message FROM audit_logs ORDER BY timestamp DESC LIMIT 20;\n</code></pre> <p>4. Check Logs:</p> <pre><code># Application logs\ntail -f logs/interview_platform.log\n\n# Docker logs\ndocker-compose logs -f app\n\n# Database logs\ndocker-compose logs -f postgres\n</code></pre> <p>5. Debug AI API Calls:</p> <pre><code># Enable LangChain debugging\nimport langchain\nlangchain.debug = True\n\n# Or set environment variable\nexport LANGCHAIN_VERBOSE=true\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#development-workflows","title":"Development Workflows","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#feature-development","title":"Feature Development","text":"<ol> <li> <p>Create Feature Branch: <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Implement Feature:</p> </li> <li>Write code following SOLID principles</li> <li>Add type hints to all functions</li> <li>Write docstrings for public APIs</li> <li>Keep functions under 50 lines</li> <li> <p>Keep files under 300 lines</p> </li> <li> <p>Write Tests:</p> </li> <li>Unit tests for business logic</li> <li>Integration tests for workflows</li> <li> <p>Aim for 80%+ coverage</p> </li> <li> <p>Run Quality Checks: <pre><code># Format code\nblack src/ tests/\n\n# Lint code\nruff check src/ tests/ --fix\n\n# Type check\nmypy src/\n\n# Run tests\npytest --cov=src\n</code></pre></p> </li> <li> <p>Commit Changes: <pre><code>git add .\ngit commit -m \"feat: add your feature description\"\n</code></pre></p> </li> <li> <p>Push and Create PR: <pre><code>git push origin feature/your-feature-name\n# Create pull request on GitHub\n</code></pre></p> </li> </ol>"},{"location":"DEVELOPER_SETUP_GUIDE/#bug-fixing","title":"Bug Fixing","text":"<ol> <li> <p>Create Bug Fix Branch: <pre><code>git checkout -b fix/bug-description\n</code></pre></p> </li> <li> <p>Reproduce Bug:</p> </li> <li>Write a failing test that demonstrates the bug</li> <li> <p>Debug to identify root cause</p> </li> <li> <p>Fix Bug:</p> </li> <li>Implement fix</li> <li>Ensure test now passes</li> <li> <p>Verify no regressions</p> </li> <li> <p>Follow Quality Checks (same as feature development)</p> </li> </ol>"},{"location":"DEVELOPER_SETUP_GUIDE/#code-review-process","title":"Code Review Process","text":"<p>As Author: - Ensure all tests pass - Ensure code quality checks pass - Write clear PR description - Link related issues - Request review from team members</p> <p>As Reviewer: - Check code follows SOLID principles - Verify tests are comprehensive - Look for potential bugs or edge cases - Ensure documentation is updated - Approve or request changes</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#code-quality","title":"Code Quality","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install pre-commit hooks to automatically check code quality:</p> <pre><code># Install pre-commit\npip install pre-commit\n\n# Install git hooks\npre-commit install\n\n# Run manually on all files\npre-commit run --all-files\n</code></pre> <p>What gets checked: - Code formatting (black) - Import sorting (isort) - Linting (ruff) - Type checking (mypy) - Trailing whitespace - File endings - Large files - Private keys</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#manual-quality-checks","title":"Manual Quality Checks","text":"<p>Format Code: <pre><code>black src/ tests/\n</code></pre></p> <p>Lint Code: <pre><code>ruff check src/ tests/ --fix\n</code></pre></p> <p>Type Check: <pre><code>mypy src/ --strict\n</code></pre></p> <p>Sort Imports: <pre><code>isort src/ tests/ --profile black\n</code></pre></p>"},{"location":"DEVELOPER_SETUP_GUIDE/#code-style-guidelines","title":"Code Style Guidelines","text":"<p>1. Follow PEP 8: - 4 spaces for indentation - Max line length: 88 characters (Black default) - Use snake_case for functions and variables - Use PascalCase for classes - Use UPPER_CASE for constants</p> <p>2. Type Hints: <pre><code>def process_response(\n    session_id: str,\n    response: str,\n    whiteboard_image: Optional[bytes] = None\n) -&gt; InterviewResponse:\n    \"\"\"Process candidate response and generate follow-up.\"\"\"\n    pass\n</code></pre></p> <p>3. Docstrings (Google Style): <pre><code>def create_session(self, config: SessionConfig) -&gt; Session:\n    \"\"\"Create a new interview session.\n\n    Args:\n        config: Session configuration including enabled modes and AI provider.\n\n    Returns:\n        Created session with unique identifier.\n\n    Raises:\n        ConfigurationError: If configuration is invalid.\n        DataStoreError: If database operation fails.\n\n    Example:\n        &gt;&gt;&gt; config = SessionConfig(\n        ...     enabled_modes=[CommunicationMode.TEXT],\n        ...     ai_provider=\"openai\"\n        ... )\n        &gt;&gt;&gt; session = manager.create_session(config)\n        &gt;&gt;&gt; print(session.id)\n        '550e8400-e29b-41d4-a716-446655440000'\n    \"\"\"\n    pass\n</code></pre></p> <p>4. Error Handling: <pre><code>try:\n    result = self.data_store.save_session(session)\nexcept DatabaseError as e:\n    self.logger.error(\n        \"session_save_failed\",\n        session_id=session.id,\n        error=str(e)\n    )\n    raise DataStoreError(f\"Failed to save session: {e}\") from e\n</code></pre></p>"},{"location":"DEVELOPER_SETUP_GUIDE/#architecture-overview","title":"Architecture Overview","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#design-principles","title":"Design Principles","text":"<ol> <li>SOLID Principles:</li> <li>Single Responsibility: Each class has one clear purpose</li> <li>Open-Closed: Extend through inheritance, not modification</li> <li>Liskov Substitution: Interfaces are interchangeable</li> <li>Interface Segregation: Focused, minimal interfaces</li> <li> <p>Dependency Inversion: Depend on abstractions, not concretions</p> </li> <li> <p>Dependency Injection:</p> </li> <li>All dependencies injected through constructors</li> <li>Easy to mock for testing</li> <li> <p>Clear dependency graph</p> </li> <li> <p>Repository Pattern:</p> </li> <li>Abstract data access behind interfaces</li> <li>Easy to swap implementations (PostgreSQL \u2192 Cloud DB)</li> </ol>"},{"location":"DEVELOPER_SETUP_GUIDE/#key-components","title":"Key Components","text":"<p>Session Manager: - Orchestrates interview lifecycle - Coordinates between components - Manages state transitions</p> <p>Communication Manager: - Handles audio, video, whiteboard, screen share - Delegates to specific handlers - Stores media files</p> <p>AI Interviewer: - Generates interview questions - Analyzes responses - Maintains conversation context - Tracks token usage</p> <p>Evaluation Manager: - Analyzes session data - Generates feedback reports - Creates improvement plans</p> <p>Data Store: - PostgreSQL implementation - Repository pattern for abstraction - Supports future cloud migration</p> <p>For detailed architecture documentation, see ARCHITECTURE.md.</p>"},{"location":"DEVELOPER_SETUP_GUIDE/#contributing","title":"Contributing","text":""},{"location":"DEVELOPER_SETUP_GUIDE/#contribution-guidelines","title":"Contribution Guidelines","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Write/update tests</li> <li>Ensure all quality checks pass</li> <li>Submit a pull request</li> </ol>"},{"location":"DEVELOPER_SETUP_GUIDE/#commit-message-format","title":"Commit Message Format","text":"<p>Follow conventional commits:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes (formatting) - <code>refactor</code>: Code refactoring - <code>test</code>: Test changes - <code>chore</code>: Build/tooling changes</p> <p>Examples: <pre><code>feat(ai): add resume-aware problem generation\n\nImplement logic to generate interview problems based on candidate's\nexperience level and domain expertise from resume.\n\nCloses #123\n</code></pre></p> <pre><code>fix(database): handle connection timeout gracefully\n\nAdd retry logic with exponential backoff for database connection\nfailures. Prevents application crash on transient network issues.\n\nFixes #456\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#pull-request-template","title":"Pull Request Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing completed\n\n## Checklist\n- [ ] Code follows style guidelines\n- [ ] Self-review completed\n- [ ] Comments added for complex logic\n- [ ] Documentation updated\n- [ ] No new warnings generated\n- [ ] Tests pass locally\n- [ ] Dependent changes merged\n</code></pre>"},{"location":"DEVELOPER_SETUP_GUIDE/#additional-resources","title":"Additional Resources","text":"<ul> <li>Architecture Documentation</li> <li>API Reference</li> <li>Logging Guide</li> <li>Quick Start Guide</li> <li>LangChain Documentation</li> <li>Streamlit Documentation</li> <li>PostgreSQL Documentation</li> </ul>"},{"location":"DEVELOPER_SETUP_GUIDE/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: Create an issue on GitHub</li> <li>Discussions: Use GitHub Discussions</li> <li>Email: [developer-support@example.com]</li> <li>Slack: [Join our Slack channel]</li> </ul> <p>Happy coding! \ud83d\ude80</p>"},{"location":"EVALUATION_MANAGER/","title":"Evaluation Manager Documentation","text":""},{"location":"EVALUATION_MANAGER/#overview","title":"Overview","text":"<p>The <code>EvaluationManager</code> is responsible for generating comprehensive interview assessments after a session is completed. It analyzes conversation history, whiteboard snapshots, and communication mode usage to produce structured feedback with competency scores, categorized feedback, and actionable improvement plans.</p>"},{"location":"EVALUATION_MANAGER/#architecture","title":"Architecture","text":""},{"location":"EVALUATION_MANAGER/#dependencies","title":"Dependencies","text":"<ul> <li>Data Store: Retrieves session data, conversation history, and media files</li> <li>AI Interviewer: Uses LLM capabilities for analysis and evaluation</li> <li>Logger: Logs all evaluation operations</li> </ul>"},{"location":"EVALUATION_MANAGER/#key-components","title":"Key Components","text":"<ol> <li>Competency Analysis: Evaluates candidate performance across key system design competencies</li> <li>Feedback Categorization: Organizes feedback into went_well, went_okay, and needs_improvement</li> <li>Communication Mode Analysis: Assesses usage and effectiveness of audio, video, whiteboard, and screen share</li> <li>Improvement Plan Generation: Creates actionable steps with resources for improvement</li> <li>Database Persistence: Saves evaluation reports to database</li> </ol>"},{"location":"EVALUATION_MANAGER/#usage","title":"Usage","text":""},{"location":"EVALUATION_MANAGER/#basic-usage","title":"Basic Usage","text":"<pre><code>from src.evaluation.evaluation_manager import EvaluationManager\nfrom src.database.data_store import PostgresDataStore\nfrom src.ai.ai_interviewer import AIInterviewer\nfrom src.log_manager.logging_manager import LoggingManager\n\n# Initialize dependencies\ndata_store = PostgresDataStore(...)\nai_interviewer = AIInterviewer(...)\nlogger = LoggingManager(...)\n\n# Create evaluation manager\neval_manager = EvaluationManager(\n    data_store=data_store,\n    ai_interviewer=ai_interviewer,\n    logger=logger\n)\n\n# Generate evaluation for a completed session\nevaluation = eval_manager.generate_evaluation(session_id=\"session-123\")\n\n# Access evaluation components\nprint(f\"Overall Score: {evaluation.overall_score}\")\nprint(f\"Competencies: {evaluation.competency_scores}\")\nprint(f\"Went Well: {evaluation.went_well}\")\nprint(f\"Needs Improvement: {evaluation.needs_improvement}\")\nprint(f\"Improvement Plan: {evaluation.improvement_plan}\")\n</code></pre>"},{"location":"EVALUATION_MANAGER/#evaluation-process","title":"Evaluation Process","text":""},{"location":"EVALUATION_MANAGER/#1-competency-analysis","title":"1. Competency Analysis","text":"<p>The evaluation manager analyzes the conversation history to assess performance across key competencies:</p> <ul> <li>Problem Decomposition: Ability to break down complex problems</li> <li>Scalability Considerations: Understanding of scaling strategies</li> <li>Reliability &amp; Fault Tolerance: Consideration of failure scenarios</li> <li>Data Modeling: Database and data structure design</li> <li>Trade-off Analysis: Evaluation of design alternatives</li> <li>Communication Clarity: Effectiveness of explanations</li> <li>System Design Patterns: Application of design patterns</li> </ul> <p>Each competency receives: - Score: 0-100 numeric score - Confidence Level: high, medium, or low - Evidence: Specific examples from the conversation</p>"},{"location":"EVALUATION_MANAGER/#2-feedback-categorization","title":"2. Feedback Categorization","text":"<p>Feedback is organized into three categories:</p>"},{"location":"EVALUATION_MANAGER/#went-well","title":"Went Well","text":"<p>Things the candidate did well (3-5 items) - Clear descriptions - Specific examples from conversation - Positive reinforcement</p>"},{"location":"EVALUATION_MANAGER/#went-okay","title":"Went Okay","text":"<p>Things that were acceptable but could be improved (2-4 items) - Constructive observations - Areas with room for growth - Balanced feedback</p>"},{"location":"EVALUATION_MANAGER/#needs-improvement","title":"Needs Improvement","text":"<p>Things that need significant improvement (2-4 items) - Critical areas for development - Specific gaps identified - Actionable focus areas</p>"},{"location":"EVALUATION_MANAGER/#3-communication-mode-analysis","title":"3. Communication Mode Analysis","text":"<p>Analyzes usage and effectiveness of enabled communication modes:</p> <ul> <li>Audio Quality: Assessment of audio recordings</li> <li>Video Presence: Evaluation of video usage</li> <li>Whiteboard Usage: Analysis of diagram work</li> <li>Screen Share Usage: Assessment of screen sharing</li> <li>Overall Communication: Holistic communication effectiveness</li> </ul>"},{"location":"EVALUATION_MANAGER/#4-improvement-plan-generation","title":"4. Improvement Plan Generation","text":"<p>Creates a structured improvement plan with:</p> <ul> <li>Priority Areas: Top 3 lowest-scoring competencies</li> <li>Concrete Steps: Numbered action items with specific tasks</li> <li>Resources: Books, courses, and practice sites for each step</li> <li>General Resources: Additional learning materials</li> </ul>"},{"location":"EVALUATION_MANAGER/#data-models","title":"Data Models","text":""},{"location":"EVALUATION_MANAGER/#evaluationreport","title":"EvaluationReport","text":"<pre><code>@dataclass\nclass EvaluationReport:\n    session_id: str\n    overall_score: float  # 0-100\n    competency_scores: Dict[str, CompetencyScore]\n    went_well: List[Feedback]\n    went_okay: List[Feedback]\n    needs_improvement: List[Feedback]\n    improvement_plan: ImprovementPlan\n    communication_mode_analysis: ModeAnalysis\n    created_at: datetime\n</code></pre>"},{"location":"EVALUATION_MANAGER/#competencyscore","title":"CompetencyScore","text":"<pre><code>@dataclass\nclass CompetencyScore:\n    score: float  # 0-100\n    confidence_level: str  # \"high\", \"medium\", \"low\"\n    evidence: List[str]  # Specific examples\n</code></pre>"},{"location":"EVALUATION_MANAGER/#feedback","title":"Feedback","text":"<pre><code>@dataclass\nclass Feedback:\n    category: str  # \"went_well\", \"went_okay\", \"needs_improvement\"\n    description: str\n    evidence: List[str]  # Supporting examples\n</code></pre>"},{"location":"EVALUATION_MANAGER/#improvementplan","title":"ImprovementPlan","text":"<pre><code>@dataclass\nclass ImprovementPlan:\n    priority_areas: List[str]\n    concrete_steps: List[ActionItem]\n    resources: List[str]\n\n@dataclass\nclass ActionItem:\n    step_number: int\n    description: str\n    resources: List[str]\n</code></pre>"},{"location":"EVALUATION_MANAGER/#modeanalysis","title":"ModeAnalysis","text":"<pre><code>@dataclass\nclass ModeAnalysis:\n    audio_quality: Optional[str]\n    video_presence: Optional[str]\n    whiteboard_usage: Optional[str]\n    screen_share_usage: Optional[str]\n    overall_communication: str\n</code></pre>"},{"location":"EVALUATION_MANAGER/#implementation-details","title":"Implementation Details","text":""},{"location":"EVALUATION_MANAGER/#llm-based-analysis","title":"LLM-Based Analysis","text":"<p>The evaluation manager uses the AI interviewer's LLM capabilities to:</p> <ol> <li>Analyze Competencies: Sends conversation history to LLM with competency evaluation prompt</li> <li>Generate Feedback: Requests categorized feedback based on conversation and scores</li> <li>Create Improvement Plan: Generates actionable steps based on identified weaknesses</li> </ol> <p>All LLM calls include: - Retry logic with exponential backoff - Token usage tracking - Error handling - Logging</p>"},{"location":"EVALUATION_MANAGER/#json-parsing","title":"JSON Parsing","text":"<p>LLM responses are parsed as JSON with fallback handling:</p> <pre><code>def _parse_competency_scores(self, response_content: str, competencies: List[str]):\n    try:\n        # Extract JSON from response\n        json_match = re.search(r'\\{.*\\}', response_content, re.DOTALL)\n        data = json.loads(json_match.group())\n        # Parse competency scores...\n    except Exception as e:\n        # Return default scores if parsing fails\n        return default_scores\n</code></pre>"},{"location":"EVALUATION_MANAGER/#database-persistence","title":"Database Persistence","text":"<p>Evaluations are automatically saved to the database:</p> <pre><code># Save evaluation to database\nself.data_store.save_evaluation(evaluation)\n</code></pre> <p>The data store handles: - JSON serialization of complex objects - Upsert logic (insert or update) - Transaction management</p>"},{"location":"EVALUATION_MANAGER/#error-handling","title":"Error Handling","text":""},{"location":"EVALUATION_MANAGER/#exception-types","title":"Exception Types","text":"<ul> <li>AIProviderError: Raised when LLM analysis fails</li> <li>ValueError: Raised when session not found</li> <li>DataStoreError: Raised when database operations fail</li> </ul>"},{"location":"EVALUATION_MANAGER/#retry-logic","title":"Retry Logic","text":"<p>LLM calls use retry logic with exponential backoff: - Maximum 3 attempts - Initial delay: 1 second - Exponential backoff: 2x multiplier</p>"},{"location":"EVALUATION_MANAGER/#fallback-behavior","title":"Fallback Behavior","text":"<p>If LLM parsing fails, the evaluation manager provides default values: - Default competency scores (50.0 with low confidence) - Basic feedback items - Generic improvement plan</p>"},{"location":"EVALUATION_MANAGER/#logging","title":"Logging","text":"<p>All operations are logged with structured information:</p> <pre><code>self.logger.info(\n    component=\"EvaluationManager\",\n    operation=\"generate_evaluation\",\n    message=\"Evaluation generated successfully\",\n    session_id=session_id,\n    metadata={\n        \"overall_score\": overall_score,\n        \"competency_count\": len(competency_scores),\n    }\n)\n</code></pre> <p>Log levels used: - INFO: Successful operations, progress updates - WARNING: Parsing failures, fallback usage - ERROR: Critical failures, exceptions</p>"},{"location":"EVALUATION_MANAGER/#performance-considerations","title":"Performance Considerations","text":""},{"location":"EVALUATION_MANAGER/#token-usage","title":"Token Usage","text":"<p>Evaluation generation makes 3 LLM calls: 1. Competency analysis (~500-1000 tokens) 2. Feedback generation (~500-1000 tokens) 3. Improvement plan (~300-500 tokens)</p> <p>Total estimated cost: $0.02-0.05 per evaluation (GPT-4)</p>"},{"location":"EVALUATION_MANAGER/#processing-time","title":"Processing Time","text":"<p>Typical evaluation generation: - Competency analysis: 3-5 seconds - Feedback generation: 3-5 seconds - Improvement plan: 2-4 seconds - Total: 8-14 seconds</p>"},{"location":"EVALUATION_MANAGER/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Batch Processing: Generate evaluations asynchronously</li> <li>Caching: Cache common improvement resources</li> <li>Model Selection: Use GPT-3.5 for faster/cheaper evaluations</li> <li>Prompt Optimization: Refine prompts to reduce token usage</li> </ol>"},{"location":"EVALUATION_MANAGER/#testing","title":"Testing","text":""},{"location":"EVALUATION_MANAGER/#unit-tests","title":"Unit Tests","text":"<p>Test individual methods: - <code>_calculate_overall_score()</code> - <code>_format_conversation()</code> - <code>_parse_competency_scores()</code> - <code>_parse_feedback()</code> - <code>_parse_improvement_plan()</code> - <code>_analyze_communication_modes()</code></p>"},{"location":"EVALUATION_MANAGER/#integration-tests","title":"Integration Tests","text":"<p>Test complete evaluation flow: - Mock data store and AI interviewer - Verify evaluation structure - Check database persistence - Validate error handling</p>"},{"location":"EVALUATION_MANAGER/#example-test","title":"Example Test","text":"<pre><code>def test_generate_evaluation():\n    # Setup mocks\n    data_store = Mock()\n    ai_interviewer = Mock()\n\n    # Mock responses\n    data_store.get_session.return_value = test_session\n    data_store.get_conversation_history.return_value = test_messages\n    ai_interviewer._call_llm_with_retry.return_value = (test_response, token_usage)\n\n    # Generate evaluation\n    manager = EvaluationManager(data_store, ai_interviewer)\n    evaluation = manager.generate_evaluation(\"session-123\")\n\n    # Verify\n    assert evaluation.overall_score &gt; 0\n    assert len(evaluation.competency_scores) &gt; 0\n    data_store.save_evaluation.assert_called_once()\n</code></pre>"},{"location":"EVALUATION_MANAGER/#requirements-mapping","title":"Requirements Mapping","text":"<p>The Evaluation Manager satisfies the following requirements:</p> <ul> <li>Requirement 5.3: Triggers evaluation generation when session ends</li> <li>Requirement 6.1: Generates evaluation report for completed sessions</li> <li>Requirement 6.2: Includes competency scores and confidence levels</li> <li>Requirement 6.3: Provides confidence level assessments</li> <li>Requirement 6.4: Categorizes feedback into three sections</li> <li>Requirement 6.5: Analyzes all enabled communication modes</li> <li>Requirement 6.6: Provides specific examples from responses</li> <li>Requirement 6.7: Includes actionable recommendations</li> <li>Requirement 6.8: Creates structured improvement plan with concrete steps</li> <li>Requirement 6.9: Saves evaluation to database</li> </ul>"},{"location":"EVALUATION_MANAGER/#future-enhancements","title":"Future Enhancements","text":""},{"location":"EVALUATION_MANAGER/#potential-improvements","title":"Potential Improvements","text":"<ol> <li>Whiteboard Analysis: Integrate vision LLM for diagram analysis</li> <li>Audio Analysis: Analyze speech patterns and clarity</li> <li>Video Analysis: Assess body language and engagement</li> <li>Comparative Analysis: Compare performance across sessions</li> <li>Personalized Resources: Recommend resources based on learning style</li> <li>Progress Tracking: Track improvement over multiple sessions</li> <li>Peer Comparison: Anonymous benchmarking against other candidates</li> <li>Custom Competencies: Allow customizable competency frameworks</li> </ol>"},{"location":"EVALUATION_MANAGER/#troubleshooting","title":"Troubleshooting","text":""},{"location":"EVALUATION_MANAGER/#common-issues","title":"Common Issues","text":""},{"location":"EVALUATION_MANAGER/#issue-evaluation-generation-fails","title":"Issue: Evaluation generation fails","text":"<p>Symptoms: AIProviderError raised during evaluation</p> <p>Solutions: 1. Check AI provider API key is valid 2. Verify network connectivity 3. Check token limits not exceeded 4. Review logs for specific error</p>"},{"location":"EVALUATION_MANAGER/#issue-parsing-errors-in-llm-responses","title":"Issue: Parsing errors in LLM responses","text":"<p>Symptoms: Warning logs about parsing failures</p> <p>Solutions: 1. Review LLM response format 2. Adjust prompts for clearer JSON output 3. Increase temperature for more consistent formatting 4. Use fallback values (already implemented)</p>"},{"location":"EVALUATION_MANAGER/#issue-low-confidence-scores","title":"Issue: Low confidence scores","text":"<p>Symptoms: Many competencies marked as \"low\" confidence</p> <p>Solutions: 1. Ensure sufficient conversation history 2. Check conversation quality and depth 3. Verify candidate provided detailed responses 4. Consider longer interview sessions</p>"},{"location":"EVALUATION_MANAGER/#best-practices","title":"Best Practices","text":"<ol> <li>Generate After Session Completion: Only generate evaluations for completed sessions</li> <li>Review Conversation Quality: Ensure adequate conversation depth before evaluation</li> <li>Monitor Token Usage: Track costs for evaluation generation</li> <li>Validate Results: Spot-check evaluations for quality</li> <li>Iterate on Prompts: Continuously improve evaluation prompts</li> <li>Handle Errors Gracefully: Always provide fallback values</li> <li>Log Comprehensively: Log all operations for debugging</li> <li>Test Thoroughly: Test with various conversation scenarios</li> </ol>"},{"location":"EVALUATION_MANAGER/#conclusion","title":"Conclusion","text":"<p>The Evaluation Manager provides comprehensive, AI-powered interview assessments with structured feedback and actionable improvement plans. It integrates seamlessly with the interview platform's data store and AI interviewer components, providing valuable insights to help candidates improve their system design interview skills.</p>"},{"location":"EVALUATION_QUICK_START/","title":"Evaluation Manager Quick Start Guide","text":""},{"location":"EVALUATION_QUICK_START/#basic-usage","title":"Basic Usage","text":""},{"location":"EVALUATION_QUICK_START/#1-initialize-the-evaluation-manager","title":"1. Initialize the Evaluation Manager","text":"<pre><code>from src.evaluation.evaluation_manager import EvaluationManager\nfrom src.database.data_store import PostgresDataStore\nfrom src.ai.ai_interviewer import AIInterviewer\nfrom src.ai.token_tracker import TokenTracker\nfrom src.log_manager.logging_manager import LoggingManager\n\n# Setup dependencies\ndata_store = PostgresDataStore(\n    host=\"localhost\",\n    port=5432,\n    database=\"interview_platform\",\n    user=\"interview_user\",\n    password=\"your_password\"\n)\n\ntoken_tracker = TokenTracker(data_store=data_store)\n\nai_interviewer = AIInterviewer(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    api_key=\"your_api_key\",\n    token_tracker=token_tracker\n)\n\nlogger = LoggingManager(config=logging_config)\n\n# Create evaluation manager\neval_manager = EvaluationManager(\n    data_store=data_store,\n    ai_interviewer=ai_interviewer,\n    logger=logger\n)\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#2-generate-evaluation","title":"2. Generate Evaluation","text":"<pre><code># Generate evaluation for a completed session\nevaluation = eval_manager.generate_evaluation(session_id=\"session-123\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#3-access-evaluation-results","title":"3. Access Evaluation Results","text":"<pre><code># Overall score\nprint(f\"Overall Score: {evaluation.overall_score}/100\")\n\n# Competency scores\nfor competency, score in evaluation.competency_scores.items():\n    print(f\"{competency}: {score.score}/100 ({score.confidence_level} confidence)\")\n    print(f\"  Evidence: {', '.join(score.evidence)}\")\n\n# Feedback categories\nprint(\"\\n\u2713 Went Well:\")\nfor feedback in evaluation.went_well:\n    print(f\"  - {feedback.description}\")\n\nprint(\"\\n\u26a0 Went Okay:\")\nfor feedback in evaluation.went_okay:\n    print(f\"  - {feedback.description}\")\n\nprint(\"\\n\u2717 Needs Improvement:\")\nfor feedback in evaluation.needs_improvement:\n    print(f\"  - {feedback.description}\")\n\n# Improvement plan\nprint(\"\\nImprovement Plan:\")\nprint(f\"Priority Areas: {', '.join(evaluation.improvement_plan.priority_areas)}\")\nfor step in evaluation.improvement_plan.concrete_steps:\n    print(f\"{step.step_number}. {step.description}\")\n    print(f\"   Resources: {', '.join(step.resources)}\")\n\n# Communication mode analysis\nprint(\"\\nCommunication Analysis:\")\nprint(f\"Audio: {evaluation.communication_mode_analysis.audio_quality}\")\nprint(f\"Video: {evaluation.communication_mode_analysis.video_presence}\")\nprint(f\"Whiteboard: {evaluation.communication_mode_analysis.whiteboard_usage}\")\nprint(f\"Overall: {evaluation.communication_mode_analysis.overall_communication}\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#integration-with-session-manager","title":"Integration with Session Manager","text":"<pre><code>class SessionManager:\n    def end_session(self, session_id: str) -&gt; EvaluationReport:\n        \"\"\"End session and generate evaluation.\"\"\"\n        # Update session status\n        session = self.data_store.get_session(session_id)\n        session.status = SessionStatus.COMPLETED\n        session.ended_at = datetime.now()\n        self.data_store.save_session(session)\n\n        # Generate evaluation\n        evaluation = self.eval_manager.generate_evaluation(session_id)\n\n        return evaluation\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#retrieving-saved-evaluations","title":"Retrieving Saved Evaluations","text":"<pre><code># Retrieve evaluation from database\nevaluation = data_store.get_evaluation(session_id=\"session-123\")\n\nif evaluation:\n    print(f\"Evaluation created at: {evaluation.created_at}\")\n    print(f\"Overall score: {evaluation.overall_score}\")\nelse:\n    print(\"No evaluation found for this session\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#error-handling","title":"Error Handling","text":"<pre><code>from src.exceptions import AIProviderError\n\ntry:\n    evaluation = eval_manager.generate_evaluation(session_id)\nexcept AIProviderError as e:\n    print(f\"Evaluation generation failed: {e}\")\n    # Handle error (retry, notify user, etc.)\nexcept ValueError as e:\n    print(f\"Session not found: {e}\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#customizing-evaluation","title":"Customizing Evaluation","text":""},{"location":"EVALUATION_QUICK_START/#using-different-ai-models","title":"Using Different AI Models","text":"<pre><code># Use GPT-3.5 for faster/cheaper evaluations\nai_interviewer = AIInterviewer(\n    provider=\"openai\",\n    model=\"gpt-3.5-turbo\",\n    api_key=\"your_api_key\",\n    token_tracker=token_tracker,\n    temperature=0.7  # Adjust for consistency\n)\n\n# Use Claude for alternative perspective\nai_interviewer = AIInterviewer(\n    provider=\"anthropic\",\n    model=\"claude-3-sonnet-20240229\",\n    api_key=\"your_api_key\",\n    token_tracker=token_tracker\n)\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#monitoring-and-logging","title":"Monitoring and Logging","text":"<pre><code># Check logs for evaluation operations\nlogs = data_store.get_audit_logs(\n    component=\"EvaluationManager\",\n    session_id=session_id\n)\n\nfor log in logs:\n    print(f\"[{log.level}] {log.operation}: {log.message}\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#performance-tips","title":"Performance Tips","text":""},{"location":"EVALUATION_QUICK_START/#1-async-evaluation-generation","title":"1. Async Evaluation Generation","text":"<pre><code>import asyncio\n\nasync def generate_evaluation_async(session_id: str):\n    \"\"\"Generate evaluation asynchronously.\"\"\"\n    loop = asyncio.get_event_loop()\n    evaluation = await loop.run_in_executor(\n        None, \n        eval_manager.generate_evaluation, \n        session_id\n    )\n    return evaluation\n\n# Use in async context\nevaluation = await generate_evaluation_async(\"session-123\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#2-batch-processing","title":"2. Batch Processing","text":"<pre><code>def generate_evaluations_batch(session_ids: List[str]):\n    \"\"\"Generate evaluations for multiple sessions.\"\"\"\n    evaluations = []\n    for session_id in session_ids:\n        try:\n            evaluation = eval_manager.generate_evaluation(session_id)\n            evaluations.append(evaluation)\n        except Exception as e:\n            print(f\"Failed to generate evaluation for {session_id}: {e}\")\n    return evaluations\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#3-token-usage-monitoring","title":"3. Token Usage Monitoring","text":"<pre><code># Check token usage for evaluation\ntoken_usage = data_store.get_token_usage(session_id)\nevaluation_tokens = [\n    t for t in token_usage \n    if t.operation in [\"analyze_competencies\", \"generate_feedback\", \"generate_improvement_plan\"]\n]\n\ntotal_cost = sum(t.estimated_cost for t in evaluation_tokens)\nprint(f\"Evaluation cost: ${total_cost:.4f}\")\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#common-patterns","title":"Common Patterns","text":""},{"location":"EVALUATION_QUICK_START/#pattern-1-evaluation-with-notification","title":"Pattern 1: Evaluation with Notification","text":"<pre><code>def generate_and_notify(session_id: str, user_email: str):\n    \"\"\"Generate evaluation and send notification.\"\"\"\n    evaluation = eval_manager.generate_evaluation(session_id)\n\n    # Send email notification\n    send_email(\n        to=user_email,\n        subject=\"Your Interview Evaluation is Ready\",\n        body=f\"Overall Score: {evaluation.overall_score}/100\"\n    )\n\n    return evaluation\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#pattern-2-evaluation-with-comparison","title":"Pattern 2: Evaluation with Comparison","text":"<pre><code>def generate_with_comparison(session_id: str, user_id: str):\n    \"\"\"Generate evaluation and compare with previous sessions.\"\"\"\n    evaluation = eval_manager.generate_evaluation(session_id)\n\n    # Get previous sessions\n    previous_sessions = data_store.list_sessions(user_id=user_id)\n    previous_scores = [\n        data_store.get_evaluation(s.id).overall_score \n        for s in previous_sessions[1:]  # Skip current session\n        if data_store.get_evaluation(s.id)\n    ]\n\n    if previous_scores:\n        avg_previous = sum(previous_scores) / len(previous_scores)\n        improvement = evaluation.overall_score - avg_previous\n        print(f\"Improvement: {improvement:+.1f} points\")\n\n    return evaluation\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#pattern-3-evaluation-with-export","title":"Pattern 3: Evaluation with Export","text":"<pre><code>import json\n\ndef generate_and_export(session_id: str, output_file: str):\n    \"\"\"Generate evaluation and export to JSON.\"\"\"\n    evaluation = eval_manager.generate_evaluation(session_id)\n\n    # Convert to dict for JSON serialization\n    eval_dict = {\n        \"session_id\": evaluation.session_id,\n        \"overall_score\": evaluation.overall_score,\n        \"competency_scores\": {\n            name: {\n                \"score\": score.score,\n                \"confidence\": score.confidence_level,\n                \"evidence\": score.evidence\n            }\n            for name, score in evaluation.competency_scores.items()\n        },\n        \"went_well\": [\n            {\"description\": f.description, \"evidence\": f.evidence}\n            for f in evaluation.went_well\n        ],\n        \"needs_improvement\": [\n            {\"description\": f.description, \"evidence\": f.evidence}\n            for f in evaluation.needs_improvement\n        ],\n        \"improvement_plan\": {\n            \"priority_areas\": evaluation.improvement_plan.priority_areas,\n            \"steps\": [\n                {\n                    \"number\": step.step_number,\n                    \"description\": step.description,\n                    \"resources\": step.resources\n                }\n                for step in evaluation.improvement_plan.concrete_steps\n            ]\n        }\n    }\n\n    with open(output_file, 'w') as f:\n        json.dump(eval_dict, f, indent=2)\n\n    return evaluation\n</code></pre>"},{"location":"EVALUATION_QUICK_START/#troubleshooting","title":"Troubleshooting","text":""},{"location":"EVALUATION_QUICK_START/#issue-evaluation-takes-too-long","title":"Issue: Evaluation takes too long","text":"<p>Solution: Use GPT-3.5 instead of GPT-4 <pre><code>ai_interviewer = AIInterviewer(\n    provider=\"openai\",\n    model=\"gpt-3.5-turbo\",  # Faster than GPT-4\n    api_key=\"your_api_key\",\n    token_tracker=token_tracker\n)\n</code></pre></p>"},{"location":"EVALUATION_QUICK_START/#issue-parsing-errors-in-llm-responses","title":"Issue: Parsing errors in LLM responses","text":"<p>Solution: Check logs and adjust temperature <pre><code>ai_interviewer = AIInterviewer(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    api_key=\"your_api_key\",\n    token_tracker=token_tracker,\n    temperature=0.3  # Lower temperature for more consistent JSON\n)\n</code></pre></p>"},{"location":"EVALUATION_QUICK_START/#issue-low-confidence-scores","title":"Issue: Low confidence scores","text":"<p>Solution: Ensure adequate conversation depth <pre><code># Check conversation length\nconversation = data_store.get_conversation_history(session_id)\nif len(conversation) &lt; 10:\n    print(\"Warning: Short conversation may result in low confidence scores\")\n</code></pre></p>"},{"location":"EVALUATION_QUICK_START/#best-practices","title":"Best Practices","text":"<ol> <li>Always check session status before generating evaluation</li> <li>Handle errors gracefully with try-except blocks</li> <li>Monitor token usage to control costs</li> <li>Log all operations for debugging</li> <li>Validate session data before evaluation</li> <li>Use async processing for better performance</li> <li>Cache common resources to reduce redundancy</li> <li>Test with various scenarios to ensure quality</li> </ol>"},{"location":"EVALUATION_QUICK_START/#next-steps","title":"Next Steps","text":"<ul> <li>Integrate with Session Manager (Task 10)</li> <li>Display evaluations in Streamlit UI (Task 13)</li> <li>Add comprehensive tests (Task 20)</li> <li>Implement progress tracking across sessions</li> <li>Add custom competency frameworks</li> <li>Integrate whiteboard vision analysis</li> </ul> <p>For detailed documentation, see EVALUATION_MANAGER.md</p>"},{"location":"INTERVIEW_UI/","title":"Interview UI Implementation","text":""},{"location":"INTERVIEW_UI/#overview","title":"Overview","text":"<p>The interview interface provides a comprehensive 3-panel layout optimized for system design interviews. The interface enables real-time interaction between the candidate and AI interviewer while supporting multiple communication modes.</p>"},{"location":"INTERVIEW_UI/#architecture","title":"Architecture","text":""},{"location":"INTERVIEW_UI/#layout-structure","title":"Layout Structure","text":"<p>The interview interface uses a fixed 3-panel layout with the following proportions:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Header (Session Info)                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502              \u2502                          \u2502                      \u2502\n\u2502   AI Chat    \u2502    Whiteboard Canvas     \u2502    Transcript       \u2502\n\u2502   (30%)      \u2502       (45%)              \u2502     (25%)           \u2502\n\u2502              \u2502                          \u2502                      \u2502\n\u2502  - Questions \u2502  - Drawing tools         \u2502  - Real-time text   \u2502\n\u2502  - Responses \u2502  - System diagrams       \u2502  - Conversation     \u2502\n\u2502  - Follow-ups\u2502  - Save snapshots        \u2502  - Searchable       \u2502\n\u2502              \u2502  - Clear canvas          \u2502  - Timestamps       \u2502\n\u2502              \u2502                          \u2502                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                     Recording Controls                           \u2502\n\u2502  [\u25cf] Audio  [\u25cf] Video  [\ud83d\udcf7] Whiteboard  [\ud83d\udda5\ufe0f] Screen  [End]     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"INTERVIEW_UI/#panel-specifications","title":"Panel Specifications","text":""},{"location":"INTERVIEW_UI/#left-panel-ai-chat-interface-30-width","title":"Left Panel - AI Chat Interface (30% width)","text":"<ul> <li>Purpose: Display conversation between AI interviewer and candidate</li> <li>Features:</li> <li>Scrollable conversation history with fixed height (500px)</li> <li>Distinct styling for interviewer (\ud83e\udd16) and candidate (\ud83d\udc64) messages</li> <li>Timestamps for each message</li> <li>Text input box for candidate responses</li> <li>Auto-scroll to latest message</li> <li>Real-time AI response processing</li> </ul>"},{"location":"INTERVIEW_UI/#center-panel-whiteboard-canvas-45-width","title":"Center Panel - Whiteboard Canvas (45% width)","text":"<ul> <li>Purpose: Enable visual system design diagrams</li> <li>Features:</li> <li>Drawing tools (freedraw, line, rect, circle, transform)</li> <li>Color picker for different components</li> <li>Stroke width adjustment</li> <li>Save snapshot functionality</li> <li>Clear canvas functionality</li> <li>Full-screen mode option</li> <li>Integration with AI for whiteboard analysis</li> </ul>"},{"location":"INTERVIEW_UI/#right-panel-transcript-display-25-width","title":"Right Panel - Transcript Display (25% width)","text":"<ul> <li>Purpose: Show real-time conversation transcript</li> <li>Features:</li> <li>Scrollable transcript with fixed height (500px)</li> <li>Speaker labels (Interviewer/Candidate)</li> <li>Timestamps for each entry</li> <li>Search functionality</li> <li>Export transcript button</li> <li>Auto-update as conversation progresses</li> </ul>"},{"location":"INTERVIEW_UI/#bottom-bar-recording-controls-full-width","title":"Bottom Bar - Recording Controls (Full width)","text":"<ul> <li>Purpose: Control communication modes and session</li> <li>Features:</li> <li>Audio recording toggle with visual indicator</li> <li>Video recording toggle with visual indicator</li> <li>Whiteboard snapshot counter</li> <li>Screen share toggle with visual indicator</li> <li>End interview button with confirmation</li> <li>Visual indicators for active modes:<ul> <li>Audio: \ud83d\udd34 Recording / \u26aa Inactive / \u26ab Disabled</li> <li>Video: \ud83d\udd34 Recording / \u26aa Inactive / \u26ab Disabled</li> <li>Whiteboard: \ud83d\udcf7 Snapshot count</li> <li>Screen: \ud83d\udfe2 Active / \u26aa Inactive / \u26ab Disabled</li> </ul> </li> </ul>"},{"location":"INTERVIEW_UI/#implementation-details","title":"Implementation Details","text":""},{"location":"INTERVIEW_UI/#file-structure","title":"File Structure","text":"<pre><code>src/ui/pages/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 setup.py          # Resume upload and configuration\n\u2514\u2500\u2500 interview.py      # Interview interface (NEW)\n</code></pre>"},{"location":"INTERVIEW_UI/#key-functions","title":"Key Functions","text":""},{"location":"INTERVIEW_UI/#render_interview_page","title":"<code>render_interview_page()</code>","text":"<p>Main entry point for the interview interface. Handles: - Session validation - Interview initialization - Layout rendering - Component coordination</p>"},{"location":"INTERVIEW_UI/#render_header","title":"<code>render_header()</code>","text":"<p>Displays session information: - Session timer (MM:SS format) - Session ID (truncated) - Token usage counter</p>"},{"location":"INTERVIEW_UI/#render_ai_chat_panel","title":"<code>render_ai_chat_panel()</code>","text":"<p>Manages the AI chat interface: - Displays conversation history - Handles user input - Processes AI responses - Updates transcript - Tracks token usage</p>"},{"location":"INTERVIEW_UI/#render_whiteboard_panel","title":"<code>render_whiteboard_panel()</code>","text":"<p>Manages the whiteboard canvas: - Drawing tool selection - Color and width controls - Canvas rendering (placeholder for streamlit-drawable-canvas) - Snapshot saving - Canvas clearing</p>"},{"location":"INTERVIEW_UI/#render_transcript_panel","title":"<code>render_transcript_panel()</code>","text":"<p>Manages the transcript display: - Real-time transcript updates - Search functionality - Export functionality - Speaker identification</p>"},{"location":"INTERVIEW_UI/#render_recording_controls","title":"<code>render_recording_controls()</code>","text":"<p>Manages communication mode controls: - Audio/video toggles - Whiteboard snapshot tracking - Screen share toggle - End interview button with confirmation</p>"},{"location":"INTERVIEW_UI/#session-state-management","title":"Session State Management","text":"<p>The interview interface uses Streamlit session state to maintain:</p> <pre><code>st.session_state.interview_started          # Boolean: Interview active\nst.session_state.interview_start_time       # datetime: Session start\nst.session_state.conversation_history       # List[dict]: Chat messages\nst.session_state.transcript_entries         # List[dict]: Transcript entries\nst.session_state.whiteboard_snapshots       # List[dict]: Saved snapshots\nst.session_state.tokens_used                # int: Total tokens consumed\nst.session_state.audio_active               # Boolean: Audio recording state\nst.session_state.video_active               # Boolean: Video recording state\nst.session_state.screen_active              # Boolean: Screen share state\n</code></pre>"},{"location":"INTERVIEW_UI/#integration-points","title":"Integration Points","text":""},{"location":"INTERVIEW_UI/#session-manager","title":"Session Manager","text":"<ul> <li><code>start_session(session_id)</code>: Initialize interview session</li> <li><code>end_session(session_id)</code>: Complete session and generate evaluation</li> </ul>"},{"location":"INTERVIEW_UI/#ai-interviewer","title":"AI Interviewer","text":"<ul> <li><code>start_interview(session_id)</code>: Get initial question</li> <li><code>process_response(session_id, response, whiteboard_image)</code>: Process candidate input</li> </ul>"},{"location":"INTERVIEW_UI/#communication-manager","title":"Communication Manager","text":"<ul> <li><code>save_whiteboard(session_id, canvas_data)</code>: Save whiteboard snapshot</li> <li>Communication mode status tracking</li> </ul>"},{"location":"INTERVIEW_UI/#requirements-coverage","title":"Requirements Coverage","text":""},{"location":"INTERVIEW_UI/#requirement-181","title":"Requirement 18.1","text":"<p>\u2705 AI chat interface in left panel (30% width) - Implemented with <code>st.columns([3, 4.5, 2.5])</code> - Left column (3/10 = 30%) contains AI chat</p>"},{"location":"INTERVIEW_UI/#requirement-182","title":"Requirement 18.2","text":"<p>\u2705 Whiteboard canvas in center panel (45% width) - Implemented with <code>st.columns([3, 4.5, 2.5])</code> - Center column (4.5/10 = 45%) contains whiteboard</p>"},{"location":"INTERVIEW_UI/#requirement-183","title":"Requirement 18.3","text":"<p>\u2705 Transcript display in right panel (25% width) - Implemented with <code>st.columns([3, 4.5, 2.5])</code> - Right column (2.5/10 = 25%) contains transcript</p>"},{"location":"INTERVIEW_UI/#requirement-184","title":"Requirement 18.4","text":"<p>\u2705 Recording controls in bottom bar - Implemented with <code>render_recording_controls()</code> - Spans full width below panels</p>"},{"location":"INTERVIEW_UI/#requirement-186","title":"Requirement 18.6","text":"<p>\u2705 Consistent layout throughout session - Fixed column proportions - No dynamic resizing - Persistent layout structure</p>"},{"location":"INTERVIEW_UI/#usage","title":"Usage","text":""},{"location":"INTERVIEW_UI/#starting-an-interview","title":"Starting an Interview","text":"<ol> <li>Complete setup page (resume upload, AI configuration, communication modes)</li> <li>Click \"Start Interview\" button</li> <li>System navigates to interview interface</li> <li>Session automatically starts and AI asks initial question</li> </ol>"},{"location":"INTERVIEW_UI/#during-interview","title":"During Interview","text":"<ol> <li>Chat: Type responses in the text input box</li> <li>Whiteboard: Use drawing tools to create diagrams</li> <li>Snapshots: Click \"Save Snapshot\" to capture whiteboard state</li> <li>Transcript: View real-time conversation transcript</li> <li>Search: Use search box to find specific transcript content</li> <li>Controls: Toggle audio/video/screen modes as needed</li> </ol>"},{"location":"INTERVIEW_UI/#ending-interview","title":"Ending Interview","text":"<ol> <li>Click \"End Interview\" button</li> <li>Confirm by clicking again</li> <li>System generates evaluation report</li> <li>Navigates to evaluation page</li> </ol>"},{"location":"INTERVIEW_UI/#future-enhancements","title":"Future Enhancements","text":""},{"location":"INTERVIEW_UI/#planned-for-task-122-ai-chat-panel","title":"Planned for Task 12.2 (AI Chat Panel)","text":"<ul> <li>Enhanced message formatting</li> <li>Typing indicators</li> <li>Message reactions</li> <li>Code snippet support</li> </ul>"},{"location":"INTERVIEW_UI/#planned-for-task-123-whiteboard-panel","title":"Planned for Task 12.3 (Whiteboard Panel)","text":"<ul> <li>Full streamlit-drawable-canvas integration</li> <li>Undo/redo functionality</li> <li>Shape library</li> <li>Template diagrams</li> <li>Real-time collaboration (future)</li> </ul>"},{"location":"INTERVIEW_UI/#planned-for-task-124-transcript-panel","title":"Planned for Task 12.4 (Transcript Panel)","text":"<ul> <li>Advanced search with filters</li> <li>Highlight search results</li> <li>Export formats (PDF, JSON)</li> <li>Timestamp navigation</li> </ul>"},{"location":"INTERVIEW_UI/#planned-for-task-125-recording-controls","title":"Planned for Task 12.5 (Recording Controls)","text":"<ul> <li>Real-time audio/video streaming</li> <li>Waveform visualization</li> <li>Recording quality indicators</li> <li>Bandwidth monitoring</li> </ul>"},{"location":"INTERVIEW_UI/#testing","title":"Testing","text":""},{"location":"INTERVIEW_UI/#validation-script","title":"Validation Script","text":"<p>Run <code>validate_interview_ui.py</code> to verify implementation:</p> <pre><code>python validate_interview_ui.py\n</code></pre> <p>The script validates: - File structure - Function existence - Layout proportions - Component integration - Requirements coverage</p>"},{"location":"INTERVIEW_UI/#manual-testing","title":"Manual Testing","text":"<ol> <li>Start application: <code>streamlit run src/main.py</code></li> <li>Complete setup page</li> <li>Navigate to interview interface</li> <li>Verify:</li> <li>3-panel layout renders correctly</li> <li>Chat input works</li> <li>Whiteboard controls are visible</li> <li>Transcript displays correctly</li> <li>Recording controls are functional</li> <li>End interview button works</li> </ol>"},{"location":"INTERVIEW_UI/#known-limitations","title":"Known Limitations","text":"<ol> <li>Whiteboard Canvas: Currently uses placeholder (text area) instead of streamlit-drawable-canvas</li> <li>Will be fully implemented in task 12.3</li> <li> <p>Snapshot functionality works with placeholder data</p> </li> <li> <p>Audio/Video: Toggle controls are present but streaming not yet implemented</p> </li> <li>Will be fully implemented in task 12.5</li> <li> <p>Visual indicators work correctly</p> </li> <li> <p>Screen Share: Toggle control present but capture not yet implemented</p> </li> <li>Will be fully implemented in task 12.5</li> </ol>"},{"location":"INTERVIEW_UI/#troubleshooting","title":"Troubleshooting","text":""},{"location":"INTERVIEW_UI/#layout-issues","title":"Layout Issues","text":"<p>Problem: Panels not displaying with correct proportions Solution: Verify <code>st.columns([3, 4.5, 2.5])</code> is used correctly</p> <p>Problem: Content overflowing panels Solution: Check container heights (500px for chat and transcript)</p>"},{"location":"INTERVIEW_UI/#session-issues","title":"Session Issues","text":"<p>Problem: \"No active session\" error Solution: Ensure session is created from setup page before navigating to interview</p> <p>Problem: Interview not starting Solution: Check session_manager and ai_interviewer are properly initialized</p>"},{"location":"INTERVIEW_UI/#integration-issues","title":"Integration Issues","text":"<p>Problem: AI responses not appearing Solution: Verify ai_interviewer.process_response() is called correctly</p> <p>Problem: Transcript not updating Solution: Check transcript_entries are being appended to session state</p>"},{"location":"INTERVIEW_UI/#references","title":"References","text":"<ul> <li>Design Document: <code>.kiro/specs/ai-mock-interview-platform/design.md</code></li> <li>Requirements: <code>.kiro/specs/ai-mock-interview-platform/requirements.md</code></li> <li>Tasks: <code>.kiro/specs/ai-mock-interview-platform/tasks.md</code></li> <li>Setup UI: <code>docs/SETUP_UI.md</code></li> </ul>"},{"location":"LOGGING/","title":"Logging System Documentation","text":""},{"location":"LOGGING/#overview","title":"Overview","text":"<p>The AI Mock Interview Platform includes a comprehensive logging system that provides multiple output handlers for debugging, monitoring, and audit trails.</p>"},{"location":"LOGGING/#features","title":"Features","text":"<ul> <li>Multiple Handlers: Console, rotating file, and database logging</li> <li>Structured JSON Format: Machine-readable logs for aggregation and analysis</li> <li>Configurable Log Levels: DEBUG, INFO, WARNING, ERROR, CRITICAL</li> <li>Context-Aware: Includes session_id and user_id when available</li> <li>Error Tracking: Full stack traces with contextual information</li> <li>API Call Logging: Request/response details with timing metrics</li> </ul>"},{"location":"LOGGING/#architecture","title":"Architecture","text":""},{"location":"LOGGING/#components","title":"Components","text":"<ol> <li>LoggingManager: Main logging interface</li> <li>DatabaseLogHandler: Custom handler for database audit logs</li> <li>JSONFormatter: Structured JSON log formatting</li> <li>RotatingFileHandler: File logging with size/time limits</li> </ol>"},{"location":"LOGGING/#log-destinations","title":"Log Destinations","text":"<ol> <li>Console: Real-time output during development</li> <li>File: Rotating log files in <code>logs/interview_platform.log</code></li> <li>Database: Structured logs in <code>audit_logs</code> table</li> </ol>"},{"location":"LOGGING/#configuration","title":"Configuration","text":"<p>Configure logging in <code>config.yaml</code>:</p> <pre><code>logging:\n  level: \"INFO\"                # DEBUG, INFO, WARNING, ERROR, CRITICAL\n  format: \"json\"               # json or text\n  console_output: true         # Enable console logging\n  file_output: true            # Enable file logging\n  database_output: true        # Enable database logging\n  max_file_size_mb: 10        # Max file size before rotation\n  backup_count: 5             # Number of backup files to keep\n</code></pre>"},{"location":"LOGGING/#usage","title":"Usage","text":""},{"location":"LOGGING/#basic-initialization","title":"Basic Initialization","text":"<pre><code>from src.config import get_config\nfrom src.log_manager import LoggingManager\n\n# Load configuration\nconfig = get_config()\n\n# Initialize logging manager\nlogger = LoggingManager(config.logging)\n</code></pre>"},{"location":"LOGGING/#logging-operations","title":"Logging Operations","text":"<pre><code># Info message\nlogger.info(\n    component=\"SessionManager\",\n    operation=\"create_session\",\n    message=\"Creating new interview session\",\n    session_id=\"session-123\",\n    metadata={\"user_id\": \"user-456\"}\n)\n\n# Debug message\nlogger.debug(\n    component=\"AIInterviewer\",\n    operation=\"generate_question\",\n    message=\"Generating interview question\",\n    session_id=\"session-123\"\n)\n\n# Warning message\nlogger.warning(\n    component=\"CommunicationManager\",\n    operation=\"enable_audio\",\n    message=\"Audio device not found, using default\",\n    session_id=\"session-123\"\n)\n\n# Error with exception\ntry:\n    # Some operation\n    pass\nexcept Exception as e:\n    logger.error(\n        component=\"DataStore\",\n        operation=\"save_session\",\n        message=\"Failed to save session\",\n        session_id=\"session-123\",\n        exc_info=e\n    )\n</code></pre>"},{"location":"LOGGING/#logging-errors-with-context","title":"Logging Errors with Context","text":"<pre><code>try:\n    # Some operation that might fail\n    result = risky_operation()\nexcept Exception as e:\n    logger.log_error(\n        component=\"FileStorage\",\n        operation=\"save_audio\",\n        error=e,\n        session_id=\"session-123\",\n        context={\n            \"file_path\": \"/path/to/file\",\n            \"file_size\": 1024000\n        }\n    )\n</code></pre>"},{"location":"LOGGING/#logging-api-calls","title":"Logging API Calls","text":"<pre><code>import time\n\nstart_time = time.time()\nresponse = api_client.call(request_data)\nduration_ms = (time.time() - start_time) * 1000\n\nlogger.log_api_call(\n    provider=\"OpenAI\",\n    endpoint=\"/v1/chat/completions\",\n    request_data={\"model\": \"gpt-4\", \"messages\": [...]},\n    response_data={\"choices\": [...]},\n    duration_ms=duration_ms,\n    session_id=\"session-123\"\n)\n</code></pre>"},{"location":"LOGGING/#integration-with-database","title":"Integration with Database","text":"<p>To enable database logging, set the data store after initialization:</p> <pre><code>from src.database.data_store import PostgresDataStore\n\n# Initialize data store with logger\ndata_store = PostgresDataStore(\n    host=\"localhost\",\n    port=5432,\n    database=\"interview_platform\",\n    user=\"interview_user\",\n    password=\"password\",\n    logger=logger\n)\n\n# Set data store for database logging\nlogger.set_data_store(data_store)\n</code></pre>"},{"location":"LOGGING/#log-format","title":"Log Format","text":""},{"location":"LOGGING/#json-format-default","title":"JSON Format (Default)","text":"<pre><code>{\n  \"timestamp\": \"2025-11-10T14:30:00.123Z\",\n  \"level\": \"INFO\",\n  \"component\": \"SessionManager\",\n  \"operation\": \"create_session\",\n  \"session_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"message\": \"Session created successfully\",\n  \"metadata\": {\n    \"user_id\": \"user-123\",\n    \"duration_minutes\": 45\n  }\n}\n</code></pre>"},{"location":"LOGGING/#error-log-with-stack-trace","title":"Error Log with Stack Trace","text":"<pre><code>{\n  \"timestamp\": \"2025-11-10T14:30:00.123Z\",\n  \"level\": \"ERROR\",\n  \"component\": \"AIInterviewer\",\n  \"operation\": \"process_response\",\n  \"session_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"message\": \"Failed to process candidate response\",\n  \"metadata\": {\n    \"response_length\": 250\n  },\n  \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"...\\\", line 42, in process_response\\n    ...\\nValueError: Invalid response format\\n\"\n}\n</code></pre>"},{"location":"LOGGING/#database-schema","title":"Database Schema","text":"<p>Logs are stored in the <code>audit_logs</code> table:</p> <pre><code>CREATE TABLE audit_logs (\n    id BIGSERIAL PRIMARY KEY,\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    level VARCHAR(20) NOT NULL,\n    component VARCHAR(100) NOT NULL,\n    operation VARCHAR(100) NOT NULL,\n    session_id UUID,\n    user_id VARCHAR(100),\n    message TEXT NOT NULL,\n    stack_trace TEXT,\n    metadata JSONB DEFAULT '{}'::jsonb\n);\n</code></pre>"},{"location":"LOGGING/#best-practices","title":"Best Practices","text":""},{"location":"LOGGING/#1-use-appropriate-log-levels","title":"1. Use Appropriate Log Levels","text":"<ul> <li>DEBUG: Detailed diagnostic information</li> <li>INFO: General informational messages</li> <li>WARNING: Warning messages for potentially harmful situations</li> <li>ERROR: Error events that might still allow the application to continue</li> <li>CRITICAL: Critical events that may cause the application to abort</li> </ul>"},{"location":"LOGGING/#2-include-context","title":"2. Include Context","text":"<p>Always include <code>session_id</code> when available:</p> <pre><code>logger.info(\n    component=\"Component\",\n    operation=\"operation\",\n    message=\"Message\",\n    session_id=session_id  # Always include when available\n)\n</code></pre>"},{"location":"LOGGING/#3-add-metadata","title":"3. Add Metadata","text":"<p>Include relevant metadata for debugging:</p> <pre><code>logger.info(\n    component=\"FileStorage\",\n    operation=\"save_file\",\n    message=\"File saved successfully\",\n    session_id=session_id,\n    metadata={\n        \"file_type\": \"audio\",\n        \"file_size_bytes\": 1024000,\n        \"duration_seconds\": 45\n    }\n)\n</code></pre>"},{"location":"LOGGING/#4-log-errors-with-full-context","title":"4. Log Errors with Full Context","text":"<pre><code>try:\n    operation()\nexcept Exception as e:\n    logger.log_error(\n        component=\"Component\",\n        operation=\"operation\",\n        error=e,\n        session_id=session_id,\n        context={\n            \"input_data\": input_data,\n            \"state\": current_state\n        }\n    )\n</code></pre>"},{"location":"LOGGING/#5-sanitize-sensitive-data","title":"5. Sanitize Sensitive Data","text":"<p>Never log sensitive information like API keys, passwords, or PII:</p> <pre><code># BAD\nlogger.info(\n    component=\"Config\",\n    operation=\"load\",\n    message=\"Configuration loaded\",\n    metadata={\"api_key\": config.api_key}  # Don't do this!\n)\n\n# GOOD\nlogger.info(\n    component=\"Config\",\n    operation=\"load\",\n    message=\"Configuration loaded\",\n    metadata={\"api_key_present\": bool(config.api_key)}\n)\n</code></pre>"},{"location":"LOGGING/#querying-logs","title":"Querying Logs","text":""},{"location":"LOGGING/#from-database","title":"From Database","text":"<pre><code>-- Get all errors for a session\nSELECT timestamp, component, operation, message, stack_trace\nFROM audit_logs\nWHERE session_id = '550e8400-e29b-41d4-a716-446655440000'\n  AND level = 'ERROR'\nORDER BY timestamp DESC;\n\n-- Get logs by component\nSELECT timestamp, level, operation, message\nFROM audit_logs\nWHERE component = 'AIInterviewer'\nORDER BY timestamp DESC\nLIMIT 100;\n\n-- Get error summary\nSELECT component, operation, COUNT(*) as error_count\nFROM audit_logs\nWHERE level = 'ERROR'\n  AND timestamp &gt; NOW() - INTERVAL '1 day'\nGROUP BY component, operation\nORDER BY error_count DESC;\n</code></pre>"},{"location":"LOGGING/#from-log-files","title":"From Log Files","text":"<pre><code># View recent logs\ntail -f logs/interview_platform.log\n\n# Search for errors\ngrep '\"level\": \"ERROR\"' logs/interview_platform.log\n\n# Search by session\ngrep '\"session_id\": \"session-123\"' logs/interview_platform.log\n\n# Pretty print JSON logs\ncat logs/interview_platform.log | jq '.'\n</code></pre>"},{"location":"LOGGING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"LOGGING/#logs-not-appearing-in-database","title":"Logs Not Appearing in Database","text":"<ol> <li> <p>Check database connection:    <pre><code>is_healthy = data_store.health_check()\n</code></pre></p> </li> <li> <p>Verify data store is set:    <pre><code>logger.set_data_store(data_store)\n</code></pre></p> </li> <li> <p>Check database_output configuration:    <pre><code>logging:\n  database_output: true\n</code></pre></p> </li> </ol>"},{"location":"LOGGING/#log-files-not-rotating","title":"Log Files Not Rotating","text":"<ol> <li> <p>Check file size configuration:    <pre><code>logging:\n  max_file_size_mb: 10\n  backup_count: 5\n</code></pre></p> </li> <li> <p>Verify logs directory permissions:    <pre><code>ls -la logs/\n</code></pre></p> </li> </ol>"},{"location":"LOGGING/#performance-issues","title":"Performance Issues","text":"<p>If logging impacts performance:</p> <ol> <li> <p>Reduce log level:    <pre><code>logging:\n  level: \"WARNING\"  # Only warnings and errors\n</code></pre></p> </li> <li> <p>Disable database logging for high-frequency operations:    <pre><code>logging:\n  database_output: false\n</code></pre></p> </li> <li> <p>Increase file rotation size:    <pre><code>logging:\n  max_file_size_mb: 50\n</code></pre></p> </li> </ol>"},{"location":"LOGGING/#examples","title":"Examples","text":"<p>See <code>test_logging.py</code> and <code>test_logging_integration.py</code> for complete examples.</p>"},{"location":"QUICK_START_GUIDE/","title":"Quick Start Guide - AI Mock Interview Platform","text":"<p>Welcome! This guide will help you set up and start using the AI Mock Interview Platform in just a few simple steps. No technical experience required!</p>"},{"location":"QUICK_START_GUIDE/#what-youll-need","title":"What You'll Need","text":"<p>Before you begin, make sure you have: - A computer running Windows, macOS, or Linux - An internet connection - An OpenAI API key (we'll show you how to get one) - About 15-20 minutes for setup</p>"},{"location":"QUICK_START_GUIDE/#step-1-install-docker-desktop","title":"Step 1: Install Docker Desktop","text":"<p>Estimated Time: 5-10 minutes</p> <p>Docker Desktop lets you run the interview platform on your computer without complicated setup.</p>"},{"location":"QUICK_START_GUIDE/#for-windows","title":"For Windows:","text":"<ol> <li>Visit https://www.docker.com/products/docker-desktop</li> <li>Click \"Download for Windows\"</li> <li>Run the installer file you downloaded</li> <li>Follow the installation wizard (keep all default settings)</li> <li>Restart your computer when prompted</li> <li>Open Docker Desktop from your Start menu</li> <li>Wait for Docker Desktop to start (you'll see a whale icon in your system tray)</li> </ol>"},{"location":"QUICK_START_GUIDE/#for-macos","title":"For macOS:","text":"<ol> <li>Visit https://www.docker.com/products/docker-desktop</li> <li>Click \"Download for Mac\" (choose Intel or Apple Silicon based on your Mac)</li> <li>Open the downloaded .dmg file</li> <li>Drag Docker to your Applications folder</li> <li>Open Docker from Applications</li> <li>Click \"Open\" when macOS asks for permission</li> <li>Wait for Docker Desktop to start (you'll see a whale icon in your menu bar)</li> </ol>"},{"location":"QUICK_START_GUIDE/#for-linux","title":"For Linux:","text":"<ol> <li>Visit https://docs.docker.com/desktop/install/linux-install/</li> <li>Follow the instructions for your Linux distribution</li> <li>Start Docker Desktop after installation</li> </ol> <p>How to verify Docker is working: - Look for the Docker whale icon in your system tray (Windows) or menu bar (macOS) - The icon should be steady, not animated - If you see the whale icon, Docker is ready!</p>"},{"location":"QUICK_START_GUIDE/#step-2-get-your-openai-api-key","title":"Step 2: Get Your OpenAI API Key","text":"<p>Estimated Time: 3-5 minutes</p> <p>The AI interviewer uses OpenAI's technology to conduct interviews. You'll need an API key to use it.</p> <ol> <li>Go to https://platform.openai.com/signup</li> <li>Create an account or sign in if you already have one</li> <li>Click on your profile icon in the top-right corner</li> <li>Select \"View API keys\" from the menu</li> <li>Click \"Create new secret key\"</li> <li>Give it a name like \"Interview Platform\"</li> <li>IMPORTANT: Copy the key that appears (it starts with \"sk-\")</li> <li>Save this key somewhere safe - you won't be able to see it again!</li> </ol> <p>Cost Information: - OpenAI charges based on usage (typically $0.50-$2.00 per interview) - You'll need to add a payment method to your OpenAI account - You can set spending limits in your OpenAI account settings</p>"},{"location":"QUICK_START_GUIDE/#step-3-download-the-interview-platform","title":"Step 3: Download the Interview Platform","text":"<p>Estimated Time: 2 minutes</p> <ol> <li>Download the platform from [GitHub Release Link]</li> <li>Extract the ZIP file to a location you'll remember (like your Documents folder)</li> <li>You should now have a folder called \"ai-mock-interview-platform\"</li> </ol>"},{"location":"QUICK_START_GUIDE/#step-4-configure-your-settings","title":"Step 4: Configure Your Settings","text":"<p>Estimated Time: 2 minutes</p> <ol> <li>Open the \"ai-mock-interview-platform\" folder</li> <li>Find the file named <code>.env.template</code></li> <li>Make a copy of this file and rename it to <code>.env</code> (remove the \".template\" part)</li> <li>Open the <code>.env</code> file with Notepad (Windows) or TextEdit (macOS)</li> <li>You'll see something like this:</li> </ol> <pre><code># Database Configuration\nDB_PASSWORD=your_secure_password_here\n\n# AI Provider API Keys\nOPENAI_API_KEY=sk-your-openai-key-here\nANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n</code></pre> <ol> <li>Replace <code>your_secure_password_here</code> with any password you want (this is just for your local database)</li> <li>Replace <code>sk-your-openai-key-here</code> with the OpenAI API key you copied in Step 2</li> <li>You can leave the <code>ANTHROPIC_API_KEY</code> line as-is (it's optional)</li> <li>Save the file and close it</li> </ol> <p>Example of what it should look like: <pre><code>DB_PASSWORD=MySecurePassword123\nOPENAI_API_KEY=sk-proj-abc123xyz789...\nANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n</code></pre></p>"},{"location":"QUICK_START_GUIDE/#step-5-start-the-platform","title":"Step 5: Start the Platform","text":"<p>Estimated Time: 2-3 minutes</p> <p>Now you're ready to start the interview platform!</p>"},{"location":"QUICK_START_GUIDE/#for-windows_1","title":"For Windows:","text":"<ol> <li>Open the \"ai-mock-interview-platform\" folder</li> <li>Double-click the file named <code>startup.sh</code></li> <li>If Windows asks \"How do you want to open this file?\", select \"Git Bash\" or \"Windows Subsystem for Linux\"</li> <li>Alternatively, open Command Prompt:</li> <li>Press Windows key + R</li> <li>Type <code>cmd</code> and press Enter</li> <li>Type <code>cd</code> followed by the path to your folder</li> <li>Type <code>startup.sh</code> and press Enter</li> </ol>"},{"location":"QUICK_START_GUIDE/#for-macoslinux","title":"For macOS/Linux:","text":"<ol> <li>Open Terminal</li> <li>Type <code>cd</code> followed by a space</li> <li>Drag the \"ai-mock-interview-platform\" folder into the Terminal window</li> <li>Press Enter</li> <li>Type <code>chmod +x startup.sh</code> and press Enter (this makes the script runnable)</li> <li>Type <code>./startup.sh</code> and press Enter</li> </ol> <p>What you'll see: <pre><code>Starting AI Mock Interview Platform...\nStarting Docker services...\nWaiting for PostgreSQL to be ready...\nPostgreSQL is ready!\nDatabase connection successful!\n\nServices started successfully!\n================================\nPostgreSQL: http://localhost:5432\nStreamlit App: http://localhost:8501\n================================\n</code></pre></p> <p>If you see this message, you're all set!</p>"},{"location":"QUICK_START_GUIDE/#step-6-open-the-interview-platform","title":"Step 6: Open the Interview Platform","text":"<p>Estimated Time: 1 minute</p> <ol> <li>Open your web browser (Chrome, Firefox, Safari, or Edge)</li> <li>Go to: <code>http://localhost:8501</code></li> <li>You should see the AI Mock Interview Platform welcome screen!</li> </ol>"},{"location":"QUICK_START_GUIDE/#using-the-platform","title":"Using the Platform","text":""},{"location":"QUICK_START_GUIDE/#starting-your-first-interview","title":"Starting Your First Interview","text":"<ol> <li>Upload Your Resume</li> <li>Click \"Browse files\" or drag your resume (PDF or text file)</li> <li>The AI will analyze your experience level and expertise</li> <li> <p>This helps generate relevant interview questions</p> </li> <li> <p>Choose Your AI Provider</p> </li> <li>Select \"OpenAI GPT-4\" (recommended for most users)</li> <li> <p>Or \"Anthropic Claude\" if you have an Anthropic API key</p> </li> <li> <p>Select Communication Modes</p> </li> <li>Audio: Speak your answers (requires microphone)</li> <li>Video: Record yourself (requires webcam)</li> <li>Whiteboard: Draw system diagrams (recommended!)</li> <li>Screen Share: Share your screen (optional)</li> <li> <p>You can enable multiple modes at once</p> </li> <li> <p>Click \"Start Interview\"</p> </li> <li>The AI interviewer will greet you and present a problem</li> <li>Take your time to think and respond</li> </ol>"},{"location":"QUICK_START_GUIDE/#during-the-interview","title":"During the Interview","text":"<ul> <li>Left Panel: Chat with the AI interviewer</li> <li>Type your responses in the text box</li> <li> <p>Or speak if you enabled audio mode</p> </li> <li> <p>Center Panel: Whiteboard for drawing</p> </li> <li>Use the drawing tools to create system diagrams</li> <li>Click \"Save Snapshot\" to save your work</li> <li> <p>Click \"Clear Canvas\" to start over</p> </li> <li> <p>Right Panel: Live transcript</p> </li> <li>See everything that's been said</li> <li>Search for specific topics</li> <li> <p>Export the transcript when done</p> </li> <li> <p>Bottom Bar: Recording controls</p> </li> <li>Toggle audio/video recording</li> <li>Take whiteboard snapshots</li> <li>End the interview when ready</li> </ul>"},{"location":"QUICK_START_GUIDE/#ending-the-interview","title":"Ending the Interview","text":"<ol> <li>Click the \"End Interview\" button at the bottom</li> <li>Confirm that you want to end the session</li> <li>Wait a moment while the AI generates your feedback</li> <li>Review your evaluation report with:</li> <li>Overall score and competency breakdown</li> <li>What went well</li> <li>What needs improvement</li> <li>Personalized improvement plan</li> </ol>"},{"location":"QUICK_START_GUIDE/#viewing-past-interviews","title":"Viewing Past Interviews","text":"<ol> <li>Click \"History\" in the navigation menu</li> <li>See all your completed interviews</li> <li>Click on any session to review:</li> <li>Full conversation transcript</li> <li>Whiteboard snapshots</li> <li>Evaluation report</li> <li>Token usage and costs</li> </ol>"},{"location":"QUICK_START_GUIDE/#stopping-the-platform","title":"Stopping the Platform","text":"<p>When you're done using the platform:</p>"},{"location":"QUICK_START_GUIDE/#for-windows_2","title":"For Windows:","text":"<ol> <li>Open Command Prompt</li> <li>Navigate to the platform folder</li> <li>Type: <code>docker-compose down</code></li> <li>Press Enter</li> </ol>"},{"location":"QUICK_START_GUIDE/#for-macoslinux_1","title":"For macOS/Linux:","text":"<ol> <li>Open Terminal</li> <li>Navigate to the platform folder</li> <li>Type: <code>docker-compose down</code></li> <li>Press Enter</li> </ol> <p>This stops all services and frees up your computer's resources.</p>"},{"location":"QUICK_START_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"QUICK_START_GUIDE/#problem-docker-is-not-running","title":"Problem: \"Docker is not running\"","text":"<p>Solution: 1. Open Docker Desktop 2. Wait for it to fully start (whale icon should be steady) 3. Try running <code>startup.sh</code> again</p>"},{"location":"QUICK_START_GUIDE/#problem-port-8501-is-already-in-use","title":"Problem: \"Port 8501 is already in use\"","text":"<p>Solution: 1. Something else is using that port 2. Close other applications that might be using it 3. Or restart your computer and try again</p>"},{"location":"QUICK_START_GUIDE/#problem-invalid-api-key","title":"Problem: \"Invalid API key\"","text":"<p>Solution: 1. Check that you copied your OpenAI API key correctly 2. Make sure there are no extra spaces in the <code>.env</code> file 3. Verify your API key is active at https://platform.openai.com/api-keys</p>"},{"location":"QUICK_START_GUIDE/#problem-cannot-connect-to-database","title":"Problem: \"Cannot connect to database\"","text":"<p>Solution: 1. Make sure Docker Desktop is running 2. Wait 30 seconds and try again (database might still be starting) 3. Run <code>docker-compose down</code> then <code>./startup.sh</code> again</p>"},{"location":"QUICK_START_GUIDE/#problem-resume-upload-failed","title":"Problem: \"Resume upload failed\"","text":"<p>Solution: 1. Make sure your resume is in PDF or TXT format 2. Check that the file size is under 10MB 3. Try converting your resume to a simpler format</p>"},{"location":"QUICK_START_GUIDE/#problem-ai-is-not-responding","title":"Problem: \"AI is not responding\"","text":"<p>Solution: 1. Check your internet connection 2. Verify your OpenAI API key is valid 3. Check if you have sufficient credits in your OpenAI account 4. Look at the error message for specific details</p>"},{"location":"QUICK_START_GUIDE/#still-having-issues","title":"Still Having Issues?","text":"<ol> <li>Check the logs:</li> <li>Open the <code>logs</code> folder in your platform directory</li> <li> <p>Look at <code>interview_platform.log</code> for error messages</p> </li> <li> <p>Restart everything:    <pre><code>docker-compose down\n./startup.sh\n</code></pre></p> </li> <li> <p>Check Docker logs:    <pre><code>docker-compose logs\n</code></pre></p> </li> </ol>"},{"location":"QUICK_START_GUIDE/#tips-for-a-great-interview-experience","title":"Tips for a Great Interview Experience","text":"<ol> <li>Prepare Your Environment</li> <li>Find a quiet space</li> <li>Test your microphone and camera before starting</li> <li> <p>Have a notepad handy for quick notes</p> </li> <li> <p>Use the Whiteboard</p> </li> <li>Draw system diagrams as you explain</li> <li>Use different colors for different components</li> <li> <p>Save snapshots at key points in your design</p> </li> <li> <p>Think Out Loud</p> </li> <li>Explain your reasoning as you work</li> <li>Discuss trade-offs and alternatives</li> <li> <p>Ask clarifying questions</p> </li> <li> <p>Take Your Time</p> </li> <li>There's no time limit (though 45-60 minutes is typical)</li> <li>Pause to think before responding</li> <li> <p>It's okay to revise your design</p> </li> <li> <p>Review Your Feedback</p> </li> <li>Read the evaluation carefully</li> <li>Focus on the improvement plan</li> <li>Practice the areas that need work</li> <li>Do another interview to track progress</li> </ol>"},{"location":"QUICK_START_GUIDE/#whats-next","title":"What's Next?","text":"<ul> <li>Practice Regularly: Try to do at least one interview per week</li> <li>Track Progress: Review your history to see improvement over time</li> <li>Focus on Weaknesses: Use the improvement plans to guide your study</li> <li>Experiment: Try different communication modes to find what works best</li> <li>Stay Updated: Check for platform updates and new features</li> </ul>"},{"location":"QUICK_START_GUIDE/#getting-help","title":"Getting Help","text":"<p>If you need assistance: - Check the troubleshooting section above - Review the logs in the <code>logs</code> folder - Consult the Developer Setup Guide for more technical details - Contact support at [support email]</p> <p>Congratulations! You're now ready to practice system design interviews with AI. Good luck! \ud83d\ude80</p>"},{"location":"RECORDING_CONTROLS/","title":"Recording Controls Documentation","text":""},{"location":"RECORDING_CONTROLS/#overview","title":"Overview","text":"<p>The recording controls provide a comprehensive bottom bar interface for managing communication modes, displaying session information, and controlling the interview session in the AI Mock Interview Platform.</p>"},{"location":"RECORDING_CONTROLS/#visual-layout","title":"Visual Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        \ud83c\udf9b\ufe0f Recording Controls                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u23f1\ufe0f Time \u2502 \ud83c\udd94 Session\u2502 \ud83e\ude99 Tokens\u2502 \ud83c\udfa4    \u2502 \ud83d\udcf9    \u2502 \ud83c\udfa8         \u2502 \ud83d\udda5\ufe0f     \u2502 \ud83d\uded1 End  \u2502\n\u2502 05:23   \u2502 a1b2c3...\u2502 1,234   \u2502 Audio \u2502 Video \u2502 Whiteboard \u2502 Screen \u2502 Interview\u2502\n\u2502         \u2502          \u2502 $0.056  \u2502       \u2502       \u2502            \u2502        \u2502         \u2502\n\u2502         \u2502          \u2502         \u2502 \ud83d\udd34    \u2502 \u26aa    \u2502 \ud83d\udcf7 3 saved \u2502 \ud83d\udfe2     \u2502         \u2502\n\u2502         \u2502          \u2502         \u2502Recording\u2502Inactive\u2502          \u2502Active  \u2502         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 Active Modes: \ud83d\udd34 Audio Recording \u00b7 \ud83d\udfe2 Screen Sharing                         \u2502\n\u2502 \ud83d\udca1 Tip: Speak clearly for accurate transcription                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"RECORDING_CONTROLS/#components","title":"Components","text":""},{"location":"RECORDING_CONTROLS/#1-session-timer-time","title":"1. Session Timer (\u23f1\ufe0f Time)","text":"<ul> <li>Purpose: Display elapsed session time</li> <li>Format: MM:SS (e.g., \"05:23\")</li> <li>Updates: Real-time, every second</li> <li>Initial State: \"00:00\"</li> </ul>"},{"location":"RECORDING_CONTROLS/#2-session-id-session","title":"2. Session ID (\ud83c\udd94 Session)","text":"<ul> <li>Purpose: Display current session identifier</li> <li>Format: First 8 characters + \"...\" (e.g., \"a1b2c3d4...\")</li> <li>Tooltip: Shows full session ID on hover</li> <li>Static: Does not change during session</li> </ul>"},{"location":"RECORDING_CONTROLS/#3-token-usage-tokens","title":"3. Token Usage (\ud83e\ude99 Tokens)","text":"<ul> <li>Purpose: Display AI API token consumption and cost</li> <li>Format: </li> <li>Main value: Token count with thousands separator (e.g., \"1,234\")</li> <li>Delta: Estimated cost in USD (e.g., \"$0.056\")</li> <li>Updates: After each AI interaction</li> <li>Calculation: Average $0.045 per 1K tokens</li> </ul>"},{"location":"RECORDING_CONTROLS/#4-audio-control-audio","title":"4. Audio Control (\ud83c\udfa4 Audio)","text":"<ul> <li>Purpose: Toggle audio recording and transcription</li> <li>States:</li> <li>\ud83d\udd34 Recording: Audio actively recording</li> <li>\u26aa Inactive: Enabled but not recording</li> <li>\u26ab Disabled: Not enabled for session</li> <li>Action: Click toggle to start/stop recording</li> <li>Integration: Uses streamlit-webrtc for real-time capture</li> </ul>"},{"location":"RECORDING_CONTROLS/#5-video-control-video","title":"5. Video Control (\ud83d\udcf9 Video)","text":"<ul> <li>Purpose: Toggle video recording</li> <li>States:</li> <li>\ud83d\udd34 Recording: Video actively recording</li> <li>\u26aa Inactive: Enabled but not recording</li> <li>\u26ab Disabled: Not enabled for session</li> <li>Action: Click toggle to start/stop recording</li> <li>Format: H264 video format</li> </ul>"},{"location":"RECORDING_CONTROLS/#6-whiteboard-status-whiteboard","title":"6. Whiteboard Status (\ud83c\udfa8 Whiteboard)","text":"<ul> <li>Purpose: Display whiteboard snapshot count</li> <li>Format: \"\ud83d\udcf7 X saved\" (e.g., \"\ud83d\udcf7 3 saved\")</li> <li>States:</li> <li>Shows count when enabled</li> <li>\u26ab Disabled: Not enabled for session</li> <li>Note: Snapshot button is in whiteboard panel</li> </ul>"},{"location":"RECORDING_CONTROLS/#7-screen-share-control-screen","title":"7. Screen Share Control (\ud83d\udda5\ufe0f Screen)","text":"<ul> <li>Purpose: Toggle screen sharing</li> <li>States:</li> <li>\ud83d\udfe2 Active: Screen sharing active</li> <li>\u26aa Inactive: Enabled but not active</li> <li>\u26ab Disabled: Not enabled for session</li> <li>Action: Click toggle to start/stop sharing</li> <li>Capture: Every 5 seconds as PNG images</li> </ul>"},{"location":"RECORDING_CONTROLS/#8-end-interview-button-end-interview","title":"8. End Interview Button (\ud83d\uded1 End Interview)","text":"<ul> <li>Purpose: End session and generate evaluation</li> <li>Type: Primary button (red)</li> <li>Confirmation: Two-click pattern</li> <li>First click: Shows \"\u26a0\ufe0f Confirm?\" warning</li> <li>Second click: Ends session</li> <li>Action: </li> <li>Stops all active recordings</li> <li>Generates evaluation</li> <li>Navigates to evaluation page</li> </ul>"},{"location":"RECORDING_CONTROLS/#active-modes-summary","title":"Active Modes Summary","text":"<p>Located below the main controls, this bar shows: - Active Modes: List of currently active communication modes - Format: \"\ud83d\udd34 Audio Recording \u00b7 \ud83d\udfe2 Screen Sharing\" - Empty State: \"None (Text-only mode)\"</p>"},{"location":"RECORDING_CONTROLS/#contextual-tips","title":"Contextual Tips","text":"<p>Dynamic tips based on current state: - Audio Active: \"\ud83d\udca1 Tip: Speak clearly for accurate transcription\" - Whiteboard Enabled: \"\ud83d\udca1 Tip: Use the whiteboard to draw your system design\" - Text Only: \"\ud83d\udca1 Tip: Type your responses in the chat panel\"</p>"},{"location":"RECORDING_CONTROLS/#visual-indicators","title":"Visual Indicators","text":""},{"location":"RECORDING_CONTROLS/#color-coding","title":"Color Coding","text":"<ul> <li>\ud83d\udd34 Red Circle: Active recording (audio, video)</li> <li>\ud83d\udfe2 Green Circle: Active sharing (screen)</li> <li>\u26aa White Circle: Inactive but enabled</li> <li>\u26ab Black Circle: Disabled for session</li> </ul>"},{"location":"RECORDING_CONTROLS/#status-text","title":"Status Text","text":"<ul> <li>Recording: Mode is actively capturing</li> <li>Active: Mode is actively sharing</li> <li>Inactive: Mode is enabled but not active</li> <li>Disabled: Mode not enabled for session</li> </ul>"},{"location":"RECORDING_CONTROLS/#user-interactions","title":"User Interactions","text":""},{"location":"RECORDING_CONTROLS/#starting-a-recording-mode","title":"Starting a Recording Mode","text":"<ol> <li>Locate the desired mode control (Audio, Video, Screen)</li> <li>Click the toggle switch</li> <li>Visual indicator changes to active state (\ud83d\udd34 or \ud83d\udfe2)</li> <li>Mode appears in \"Active Modes\" summary</li> <li>Contextual tip updates if applicable</li> </ol>"},{"location":"RECORDING_CONTROLS/#stopping-a-recording-mode","title":"Stopping a Recording Mode","text":"<ol> <li>Click the active toggle switch</li> <li>Visual indicator changes to inactive state (\u26aa)</li> <li>Mode is removed from \"Active Modes\" summary</li> <li>Recording/sharing stops immediately</li> </ol>"},{"location":"RECORDING_CONTROLS/#ending-the-interview","title":"Ending the Interview","text":"<ol> <li>Click \"\ud83d\uded1 End Interview\" button</li> <li>Warning appears: \"\u26a0\ufe0f Confirm?\"</li> <li>Click \"\ud83d\uded1 End Interview\" again to confirm</li> <li>Spinner shows: \"\ud83d\udd04 Ending interview and generating evaluation...\"</li> <li>All active modes stop automatically</li> <li>Evaluation is generated</li> <li>Navigate to evaluation page</li> </ol>"},{"location":"RECORDING_CONTROLS/#canceling-end-interview","title":"Canceling End Interview","text":"<ul> <li>Click anywhere else after first click</li> <li>Warning disappears on next rerun</li> <li>Session continues normally</li> </ul>"},{"location":"RECORDING_CONTROLS/#error-handling","title":"Error Handling","text":""},{"location":"RECORDING_CONTROLS/#mode-start-failure","title":"Mode Start Failure","text":"<ul> <li>Display: \"\u274c Failed to start [mode]: [error message]\"</li> <li>Action: Mode remains inactive</li> <li>State: Toggle returns to off position</li> <li>Logging: Error logged with context</li> </ul>"},{"location":"RECORDING_CONTROLS/#mode-stop-failure","title":"Mode Stop Failure","text":"<ul> <li>Display: \"\u274c Failed to stop [mode]: [error message]\"</li> <li>Action: Mode may remain active</li> <li>State: Toggle state may be inconsistent</li> <li>Logging: Error logged with context</li> </ul>"},{"location":"RECORDING_CONTROLS/#session-end-failure","title":"Session End Failure","text":"<ul> <li>Display: \"\u274c Failed to end interview: [error message]\"</li> <li>Action: Session continues</li> <li>State: Confirmation resets</li> <li>Logging: Error logged with full context</li> </ul>"},{"location":"RECORDING_CONTROLS/#state-management","title":"State Management","text":""},{"location":"RECORDING_CONTROLS/#session-state-variables","title":"Session State Variables","text":"<pre><code>st.session_state.audio_active = False      # Audio recording state\nst.session_state.video_active = False      # Video recording state\nst.session_state.screen_active = False     # Screen share state\nst.session_state.confirm_end = False       # End confirmation state\nst.session_state.interview_start_time      # Session start timestamp\nst.session_state.tokens_used = 0           # Total tokens consumed\nst.session_state.whiteboard_snapshots = [] # Saved snapshots\nst.session_state.enabled_modes = []        # Enabled communication modes\n</code></pre>"},{"location":"RECORDING_CONTROLS/#state-lifecycle","title":"State Lifecycle","text":"<ol> <li>Initialization: States created on first render</li> <li>Updates: Modified by user interactions</li> <li>Persistence: Maintained across reruns</li> <li>Reset: Cleared on session end</li> </ol>"},{"location":"RECORDING_CONTROLS/#integration-points","title":"Integration Points","text":""},{"location":"RECORDING_CONTROLS/#communicationmanager","title":"CommunicationManager","text":"<pre><code># Enable a communication mode\ncommunication_manager.enable_mode(CommunicationMode.AUDIO)\n\n# Disable a communication mode\ncommunication_manager.disable_mode(CommunicationMode.AUDIO)\n</code></pre>"},{"location":"RECORDING_CONTROLS/#sessionmanager","title":"SessionManager","text":"<pre><code># End session and generate evaluation\nevaluation = session_manager.end_session(session_id)\n</code></pre>"},{"location":"RECORDING_CONTROLS/#logger","title":"Logger","text":"<pre><code># Log mode changes\nlogger.info(\n    component=\"interview_ui\",\n    operation=\"enable_audio\",\n    message=f\"Audio recording started for session {session_id}\",\n    session_id=session_id\n)\n\n# Log errors\nlogger.log_error(\n    component=\"interview_ui\",\n    operation=\"end_session\",\n    message=f\"Failed to end interview session: {error}\",\n    session_id=session_id\n)\n</code></pre>"},{"location":"RECORDING_CONTROLS/#accessibility","title":"Accessibility","text":""},{"location":"RECORDING_CONTROLS/#keyboard-navigation","title":"Keyboard Navigation","text":"<ul> <li>Tab through controls in logical order</li> <li>Space/Enter to activate toggles and buttons</li> <li>Escape to cancel confirmation (future enhancement)</li> </ul>"},{"location":"RECORDING_CONTROLS/#screen-readers","title":"Screen Readers","text":"<ul> <li>All controls have descriptive labels</li> <li>State changes announced</li> <li>Error messages read aloud</li> <li>Help text available on focus</li> </ul>"},{"location":"RECORDING_CONTROLS/#visual-accessibility","title":"Visual Accessibility","text":"<ul> <li>High contrast indicators</li> <li>Color-blind friendly (uses shapes + colors)</li> <li>Clear text labels</li> <li>Adequate spacing between controls</li> </ul>"},{"location":"RECORDING_CONTROLS/#performance","title":"Performance","text":""},{"location":"RECORDING_CONTROLS/#update-frequency","title":"Update Frequency","text":"<ul> <li>Timer: Updates every render (appears real-time)</li> <li>Tokens: Updates after AI interactions</li> <li>Snapshots: Updates on save action</li> <li>Mode States: Updates on toggle action</li> </ul>"},{"location":"RECORDING_CONTROLS/#optimization","title":"Optimization","text":"<ul> <li>Minimal state updates</li> <li>Efficient rerun triggers</li> <li>Conditional logging</li> <li>Batch operations where possible</li> </ul>"},{"location":"RECORDING_CONTROLS/#best-practices","title":"Best Practices","text":""},{"location":"RECORDING_CONTROLS/#for-users","title":"For Users","text":"<ol> <li>Start modes early: Enable recording modes at session start</li> <li>Monitor tokens: Keep eye on token usage for cost control</li> <li>Save snapshots: Regularly save whiteboard progress</li> <li>Confirm carefully: Double-check before ending session</li> </ol>"},{"location":"RECORDING_CONTROLS/#for-developers","title":"For Developers","text":"<ol> <li>Error handling: Always wrap mode changes in try-except</li> <li>State management: Initialize all states before use</li> <li>Logging: Log all mode changes and errors</li> <li>User feedback: Provide clear messages for all actions</li> </ol>"},{"location":"RECORDING_CONTROLS/#troubleshooting","title":"Troubleshooting","text":""},{"location":"RECORDING_CONTROLS/#audio-not-recording","title":"Audio Not Recording","text":"<ul> <li>Check if audio mode is enabled for session</li> <li>Verify microphone permissions in browser</li> <li>Check browser console for WebRTC errors</li> <li>Ensure streamlit-webrtc is properly installed</li> </ul>"},{"location":"RECORDING_CONTROLS/#video-not-recording","title":"Video Not Recording","text":"<ul> <li>Check if video mode is enabled for session</li> <li>Verify camera permissions in browser</li> <li>Check available disk space</li> <li>Ensure video codec support</li> </ul>"},{"location":"RECORDING_CONTROLS/#screen-share-not-working","title":"Screen Share Not Working","text":"<ul> <li>Check if screen share mode is enabled</li> <li>Verify screen capture permissions</li> <li>Check browser compatibility</li> <li>Ensure sufficient system resources</li> </ul>"},{"location":"RECORDING_CONTROLS/#end-interview-hangs","title":"End Interview Hangs","text":"<ul> <li>Check network connectivity</li> <li>Verify database connection</li> <li>Check AI API availability</li> <li>Review logs for specific errors</li> </ul>"},{"location":"RECORDING_CONTROLS/#requirements-mapping","title":"Requirements Mapping","text":"Requirement Component Implementation 2.3, 2.4 Audio Toggle streamlit-webrtc integration with real-time transcription 2.5 Video Toggle Video recording with H264 format 2.6 Whiteboard Snapshot count display 2.6 Screen Share Toggle with 5-second capture interval 5.1 End Button Two-click confirmation with evaluation generation 14.7, 5.1 Token Display Usage tracking with cost estimation 18.4 Timer Real-time elapsed time in MM:SS format 18.7 Visual Indicators Color-coded status indicators for all modes"},{"location":"RECORDING_CONTROLS/#related-documentation","title":"Related Documentation","text":"<ul> <li>Interview UI Documentation</li> <li>Communication Manager Documentation</li> <li>Session Manager Documentation</li> <li>Token Tracking Documentation</li> </ul> <p>Last Updated: 2025-11-11 Version: 1.0 Status: \u2705 Complete</p>"},{"location":"RESUME_MANAGER/","title":"Resume Manager Implementation","text":""},{"location":"RESUME_MANAGER/#overview","title":"Overview","text":"<p>The Resume Manager component handles resume upload, parsing, and extraction of structured candidate information using LLM-based analysis. This enables the AI interviewer to generate resume-aware interview problems tailored to the candidate's experience level and domain expertise.</p>"},{"location":"RESUME_MANAGER/#components","title":"Components","text":""},{"location":"RESUME_MANAGER/#resumemanager-class","title":"ResumeManager Class","text":"<p>Located in <code>src/resume/resume_manager.py</code>, the ResumeManager provides:</p> <ul> <li>Resume Upload: Accepts PDF and TXT file formats</li> <li>Text Extraction: Extracts text from PDF files using PyPDF2</li> <li>LLM-based Parsing: Uses OpenAI GPT-4 or Anthropic Claude to extract structured data</li> <li>Data Persistence: Saves and retrieves resume data from PostgreSQL database</li> <li>Experience Classification: Categorizes candidates as junior, mid, senior, or staff level</li> </ul>"},{"location":"RESUME_MANAGER/#key-features","title":"Key Features","text":""},{"location":"RESUME_MANAGER/#supported-file-formats","title":"Supported File Formats","text":"<ul> <li>PDF: Extracted using PyPDF2 library</li> <li>TXT: Direct text file reading</li> </ul>"},{"location":"RESUME_MANAGER/#extracted-information","title":"Extracted Information","text":"<p>The ResumeManager extracts the following structured data:</p> <ol> <li>Basic Information</li> <li>Name</li> <li> <p>Email address</p> </li> <li> <p>Experience Details</p> </li> <li>Experience level (junior/mid/senior/staff)</li> <li>Years of professional experience</li> <li> <p>Domain expertise areas (e.g., backend, distributed-systems, cloud)</p> </li> <li> <p>Work History</p> </li> <li>Company name</li> <li>Job title</li> <li>Duration</li> <li> <p>Role description</p> </li> <li> <p>Education</p> </li> <li>Institution name</li> <li>Degree type</li> <li>Field of study</li> <li> <p>Graduation year</p> </li> <li> <p>Technical Skills</p> </li> <li>List of technical skills and technologies</li> </ol>"},{"location":"RESUME_MANAGER/#experience-level-classification","title":"Experience Level Classification","text":"<p>The system classifies candidates into four levels:</p> <ul> <li>Junior: 0-2 years of experience, entry-level roles</li> <li>Mid: 3-5 years of experience, intermediate roles</li> <li>Senior: 6-10 years of experience, senior roles</li> <li>Staff: 10+ years of experience, staff/principal/lead roles</li> </ul>"},{"location":"RESUME_MANAGER/#domain-expertise","title":"Domain Expertise","text":"<p>Common domain areas identified: - backend - frontend - full-stack - distributed-systems - cloud - devops - data-engineering - machine-learning - mobile - security</p>"},{"location":"RESUME_MANAGER/#api-reference","title":"API Reference","text":""},{"location":"RESUME_MANAGER/#resumemanager-methods","title":"ResumeManager Methods","text":""},{"location":"RESUME_MANAGER/#__init__data_store-config-loggernone","title":"<code>__init__(data_store, config, logger=None)</code>","text":"<p>Initialize ResumeManager with dependencies.</p> <p>Parameters: - <code>data_store</code>: IDataStore instance for database operations - <code>config</code>: Configuration object with AI provider settings - <code>logger</code>: Optional LoggingManager instance</p>"},{"location":"RESUME_MANAGER/#upload_resumefile_path-str-user_id-str-resumedata","title":"<code>upload_resume(file_path: str, user_id: str) -&gt; ResumeData</code>","text":"<p>Upload and parse a resume file.</p> <p>Parameters: - <code>file_path</code>: Path to resume file (PDF or TXT) - <code>user_id</code>: User identifier</p> <p>Returns: - ResumeData object with extracted information</p> <p>Raises: - <code>ValidationError</code>: If file format is invalid or file doesn't exist - <code>AIProviderError</code>: If LLM parsing fails</p>"},{"location":"RESUME_MANAGER/#parse_resumefile_path-str-resumedata","title":"<code>parse_resume(file_path: str) -&gt; ResumeData</code>","text":"<p>Parse resume file and extract structured data using LLM.</p> <p>Parameters: - <code>file_path</code>: Path to resume file</p> <p>Returns: - ResumeData object with extracted information</p>"},{"location":"RESUME_MANAGER/#get_resumeuser_id-str-optionalresumedata","title":"<code>get_resume(user_id: str) -&gt; Optional[ResumeData]</code>","text":"<p>Retrieve resume data for a user from database.</p> <p>Parameters: - <code>user_id</code>: User identifier</p> <p>Returns: - ResumeData if found, None otherwise</p>"},{"location":"RESUME_MANAGER/#save_resumeuser_id-str-resume_data-resumedata-none","title":"<code>save_resume(user_id: str, resume_data: ResumeData) -&gt; None</code>","text":"<p>Save resume data to database.</p> <p>Parameters: - <code>user_id</code>: User identifier - <code>resume_data</code>: ResumeData object to save</p>"},{"location":"RESUME_MANAGER/#extract_experience_levelresume_data-resumedata-str","title":"<code>extract_experience_level(resume_data: ResumeData) -&gt; str</code>","text":"<p>Extract experience level from resume data.</p> <p>Parameters: - <code>resume_data</code>: ResumeData object</p> <p>Returns: - Experience level string (junior/mid/senior/staff)</p>"},{"location":"RESUME_MANAGER/#extract_domain_expertiseresume_data-resumedata-liststr","title":"<code>extract_domain_expertise(resume_data: ResumeData) -&gt; List[str]</code>","text":"<p>Extract domain expertise from resume data.</p> <p>Parameters: - <code>resume_data</code>: ResumeData object</p> <p>Returns: - List of domain expertise areas</p>"},{"location":"RESUME_MANAGER/#database-schema","title":"Database Schema","text":"<p>Resume data is stored in the <code>resumes</code> table:</p> <pre><code>CREATE TABLE resumes (\n    id BIGSERIAL PRIMARY KEY,\n    user_id VARCHAR(100) UNIQUE NOT NULL,\n    name VARCHAR(200),\n    email VARCHAR(200),\n    experience_level VARCHAR(20) NOT NULL,\n    years_of_experience INTEGER NOT NULL,\n    domain_expertise JSONB NOT NULL,\n    work_experience JSONB NOT NULL,\n    education JSONB NOT NULL,\n    skills JSONB NOT NULL,\n    raw_text TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"RESUME_MANAGER/#usage-example","title":"Usage Example","text":"<pre><code>from src.resume.resume_manager import ResumeManager\nfrom src.database.data_store import PostgresDataStore\nfrom src.config import get_config\n\n# Initialize dependencies\nconfig = get_config()\ndata_store = PostgresDataStore(\n    host=config.database.host,\n    port=config.database.port,\n    database=config.database.database,\n    user=config.database.user,\n    password=config.database.password,\n)\n\n# Create ResumeManager\nresume_manager = ResumeManager(\n    data_store=data_store,\n    config=config,\n)\n\n# Upload and parse resume\nresume_data = resume_manager.upload_resume(\n    file_path=\"path/to/resume.pdf\",\n    user_id=\"user123\",\n)\n\n# Access extracted information\nprint(f\"Name: {resume_data.name}\")\nprint(f\"Experience Level: {resume_data.experience_level}\")\nprint(f\"Years of Experience: {resume_data.years_of_experience}\")\nprint(f\"Domain Expertise: {', '.join(resume_data.domain_expertise)}\")\n\n# Retrieve resume later\nsaved_resume = resume_manager.get_resume(\"user123\")\n</code></pre>"},{"location":"RESUME_MANAGER/#llm-integration","title":"LLM Integration","text":"<p>The ResumeManager uses LLM to parse resumes with the following approach:</p> <ol> <li>Text Extraction: Extract raw text from PDF or TXT file</li> <li>Prompt Construction: Build structured prompt with extraction guidelines</li> <li>LLM Call: Send prompt to OpenAI GPT-4 or Anthropic Claude</li> <li>JSON Parsing: Parse LLM response as JSON</li> <li>Data Validation: Validate and structure extracted data</li> <li>Database Storage: Save to PostgreSQL database</li> </ol>"},{"location":"RESUME_MANAGER/#llm-prompt-structure","title":"LLM Prompt Structure","text":"<p>The prompt instructs the LLM to: - Extract specific fields in JSON format - Classify experience level based on years and role seniority - Identify domain expertise using standardized naming - Structure work experience and education entries - Extract technical skills list</p>"},{"location":"RESUME_MANAGER/#error-handling","title":"Error Handling","text":"<p>The ResumeManager handles various error scenarios:</p> <ul> <li>File Not Found: Raises ValidationError if file doesn't exist</li> <li>Invalid Format: Raises ValidationError for unsupported file types</li> <li>Empty Resume: Raises ValidationError if resume text is too short</li> <li>LLM Failure: Raises AIProviderError if LLM call fails</li> <li>JSON Parse Error: Raises AIProviderError if LLM response is invalid JSON</li> <li>Database Error: Propagates DataStoreError from database operations</li> </ul>"},{"location":"RESUME_MANAGER/#testing","title":"Testing","text":"<p>Test file: <code>test_resume_manager.py</code></p> <p>Tests cover: - ResumeManager initialization - Text extraction from TXT files - Resume parsing with mocked LLM - Resume retrieval from database - Resume saving to database</p> <p>Run tests: <pre><code>python test_resume_manager.py\n</code></pre></p>"},{"location":"RESUME_MANAGER/#dependencies","title":"Dependencies","text":"<ul> <li>PyPDF2: PDF text extraction</li> <li>openai: OpenAI API client (optional)</li> <li>anthropic: Anthropic API client (optional)</li> <li>psycopg2: PostgreSQL database driver</li> </ul>"},{"location":"RESUME_MANAGER/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements: - Support for DOCX format - OCR for scanned PDFs - Resume quality scoring - Duplicate detection - Batch processing - Resume comparison - Skills gap analysis</p>"},{"location":"SESSION_MANAGER/","title":"Session Manager","text":"<p>The Session Manager orchestrates the complete interview session lifecycle, coordinating between the AI Interviewer, Evaluation Manager, Communication Manager, and Data Store.</p>"},{"location":"SESSION_MANAGER/#overview","title":"Overview","text":"<p>The <code>SessionManager</code> class is responsible for: - Creating new interview sessions with unique identifiers - Starting sessions and initializing all components - Managing session state transitions (active, paused, completed) - Ending sessions and triggering evaluation generation - Retrieving session information and history</p>"},{"location":"SESSION_MANAGER/#architecture","title":"Architecture","text":"<p>The Session Manager follows the dependency injection pattern, receiving all dependencies through its constructor:</p> <pre><code>session_manager = SessionManager(\n    data_store=data_store,\n    ai_interviewer=ai_interviewer,\n    evaluation_manager=evaluation_manager,\n    communication_manager=communication_manager,\n    logger=logger\n)\n</code></pre>"},{"location":"SESSION_MANAGER/#key-features","title":"Key Features","text":""},{"location":"SESSION_MANAGER/#1-session-creation","title":"1. Session Creation","text":"<p>Creates a new interview session with a unique UUID identifier:</p> <pre><code>config = SessionConfig(\n    enabled_modes=[CommunicationMode.TEXT, CommunicationMode.WHITEBOARD],\n    ai_provider=\"openai\",\n    ai_model=\"gpt-4\",\n    resume_data=resume_data,\n    duration_minutes=45\n)\n\nsession = session_manager.create_session(config)\n</code></pre> <p>Features: - Generates unique session ID using UUID - Extracts user_id from resume data or generates one - Stores session metadata in database - Returns Session object with all details</p>"},{"location":"SESSION_MANAGER/#2-session-start","title":"2. Session Start","text":"<p>Starts an interview session and initializes all components:</p> <pre><code>session_manager.start_session(session_id)\n</code></pre> <p>What happens: 1. Retrieves session from database 2. Initializes AI Interviewer with session context and resume data 3. Enables configured communication modes 4. Generates opening question from AI Interviewer 5. Saves opening message to conversation history 6. Sets session as active</p>"},{"location":"SESSION_MANAGER/#3-session-end","title":"3. Session End","text":"<p>Ends an interview session and generates evaluation:</p> <pre><code>evaluation = session_manager.end_session(session_id)\n</code></pre> <p>What happens: 1. Retrieves session from database 2. Marks session as completed with end timestamp 3. Clears active session 4. Disables all communication modes 5. Triggers evaluation generation 6. Returns EvaluationReport</p>"},{"location":"SESSION_MANAGER/#4-session-state-management","title":"4. Session State Management","text":"<p>The Session Manager supports three session states:</p> <ul> <li>ACTIVE: Session is currently running</li> <li>PAUSED: Session is temporarily paused</li> <li>COMPLETED: Session has ended</li> </ul> <pre><code># Pause a session\nsession_manager.pause_session(session_id)\n\n# Resume a paused session\nsession_manager.resume_session(session_id)\n</code></pre>"},{"location":"SESSION_MANAGER/#5-session-retrieval","title":"5. Session Retrieval","text":"<p>Retrieve session information:</p> <pre><code># Get specific session\nsession = session_manager.get_session(session_id)\n\n# Get active session\nactive_session = session_manager.get_active_session()\n\n# List sessions with pagination\nsessions = session_manager.list_sessions(\n    user_id=\"user_123\",\n    limit=50,\n    offset=0\n)\n</code></pre>"},{"location":"SESSION_MANAGER/#session-lifecycle","title":"Session Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Create Session \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Start Session  \u2502\n\u2502  - Initialize AI\u2502\n\u2502  - Enable modes \u2502\n\u2502  - Open question\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Active Session  \u2502\u25c4\u2500\u2500\u2510\n\u2502  - Conversation \u2502   \u2502\n\u2502  - Whiteboard   \u2502   \u2502\n\u2502  - Recording    \u2502   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n         \u2502            \u2502\n         \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  \u2502  Pause/Resume    \u2502\n         \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   End Session   \u2502\n\u2502  - Mark complete\u2502\n\u2502  - Disable modes\u2502\n\u2502  - Generate eval\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Completed    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"SESSION_MANAGER/#integration-with-other-components","title":"Integration with Other Components","text":""},{"location":"SESSION_MANAGER/#ai-interviewer-integration","title":"AI Interviewer Integration","text":"<p>The Session Manager initializes the AI Interviewer with: - Session ID for tracking - Resume data for context-aware questions - System design interview context</p> <pre><code>ai_interviewer.initialize(\n    session_id=session_id,\n    resume_data=resume_data\n)\n</code></pre>"},{"location":"SESSION_MANAGER/#communication-manager-integration","title":"Communication Manager Integration","text":"<p>The Session Manager: - Enables communication modes based on session configuration - Disables all modes when session ends - Tracks which modes are active</p> <pre><code>for mode in session.config.enabled_modes:\n    communication_manager.enable_mode(mode)\n</code></pre>"},{"location":"SESSION_MANAGER/#evaluation-manager-integration","title":"Evaluation Manager Integration","text":"<p>The Session Manager triggers evaluation generation when a session ends:</p> <pre><code>evaluation = evaluation_manager.generate_evaluation(session_id)\n</code></pre>"},{"location":"SESSION_MANAGER/#data-store-integration","title":"Data Store Integration","text":"<p>The Session Manager persists: - Session metadata (creation time, status, configuration) - Conversation messages - Session state transitions</p>"},{"location":"SESSION_MANAGER/#error-handling","title":"Error Handling","text":"<p>The Session Manager raises <code>InterviewPlatformError</code> for: - Session not found - Invalid state transitions (e.g., ending a completed session) - Component initialization failures - Database operation failures</p> <p>All errors are logged with full context for debugging.</p>"},{"location":"SESSION_MANAGER/#logging","title":"Logging","text":"<p>The Session Manager logs: - Session creation with configuration details - Session start with enabled modes - Session end with duration and score - State transitions (pause/resume) - All errors with stack traces</p> <p>Example log entry: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"INFO\",\n  \"component\": \"SessionManager\",\n  \"operation\": \"start_session\",\n  \"message\": \"Session abc-123 started successfully\",\n  \"session_id\": \"abc-123\",\n  \"metadata\": {\n    \"enabled_modes\": [\"text\", \"whiteboard\"]\n  }\n}\n</code></pre></p>"},{"location":"SESSION_MANAGER/#usage-example","title":"Usage Example","text":"<p>Complete workflow example:</p> <pre><code>from src.session.session_manager import SessionManager\nfrom src.models import SessionConfig, CommunicationMode\n\n# Create session manager (with injected dependencies)\nsession_manager = SessionManager(\n    data_store=data_store,\n    ai_interviewer=ai_interviewer,\n    evaluation_manager=evaluation_manager,\n    communication_manager=communication_manager,\n    logger=logger\n)\n\n# Create session configuration\nconfig = SessionConfig(\n    enabled_modes=[\n        CommunicationMode.TEXT,\n        CommunicationMode.WHITEBOARD,\n        CommunicationMode.AUDIO\n    ],\n    ai_provider=\"openai\",\n    ai_model=\"gpt-4\",\n    resume_data=resume_data,\n    duration_minutes=45\n)\n\n# Create new session\nsession = session_manager.create_session(config)\nprint(f\"Created session: {session.id}\")\n\n# Start the session\nsession_manager.start_session(session.id)\nprint(\"Session started - interview in progress\")\n\n# ... interview happens here ...\n\n# End the session\nevaluation = session_manager.end_session(session.id)\nprint(f\"Session ended - Overall score: {evaluation.overall_score}\")\n\n# View session history\nsessions = session_manager.list_sessions(user_id=session.user_id)\nfor s in sessions:\n    print(f\"Session {s.id}: {s.overall_score}/100\")\n</code></pre>"},{"location":"SESSION_MANAGER/#testing","title":"Testing","text":"<p>The Session Manager includes comprehensive unit tests covering: - Session creation with and without resume data - Session start with component initialization - Session end with evaluation generation - State transitions (pause/resume) - Session retrieval and listing - Error handling for invalid operations</p> <p>Run tests: <pre><code>python -m pytest test_session_manager.py -v\n</code></pre></p>"},{"location":"SESSION_MANAGER/#requirements-mapping","title":"Requirements Mapping","text":"<p>The Session Manager implementation satisfies the following requirements:</p> <ul> <li>Requirement 1.1: Provides interface to initiate new interview sessions</li> <li>Requirement 1.2: Creates unique session identifiers using UUID</li> <li>Requirement 1.3: Initializes AI Interviewer with system design context</li> <li>Requirement 1.4: Stores session metadata in database</li> <li>Requirement 5.1: Provides control to end interview sessions</li> <li>Requirement 5.2: Stops accepting inputs when session ends</li> <li>Requirement 5.3: Triggers evaluation generation on session end</li> <li>Requirement 5.4: Saves complete session recording</li> <li>Requirement 5.5: Marks session as completed in database</li> <li>Requirement 7.1: Provides interface to list completed sessions</li> <li>Requirement 7.2: Displays session metadata (date, duration, score)</li> <li>Requirement 7.5: Orders sessions by date with most recent first</li> </ul>"},{"location":"SESSION_MANAGER/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements for future versions:</p> <ol> <li>Session Templates: Pre-configured session templates for different interview types</li> <li>Session Scheduling: Schedule sessions for future times</li> <li>Session Sharing: Share session recordings with others</li> <li>Session Analytics: Aggregate analytics across multiple sessions</li> <li>Session Export: Export session data in various formats</li> <li>Session Replay: Replay sessions with timeline controls</li> </ol>"},{"location":"SETUP_UI/","title":"Setup UI Implementation","text":""},{"location":"SETUP_UI/#overview","title":"Overview","text":"<p>The Setup UI provides the interview configuration interface where users can upload their resume, configure AI providers, select communication modes, and start interview sessions.</p>"},{"location":"SETUP_UI/#components","title":"Components","text":""},{"location":"SETUP_UI/#1-resume-upload-section-render_resume_upload_section","title":"1. Resume Upload Section (<code>render_resume_upload_section</code>)","text":"<p>Features: - File uploader supporting PDF and TXT formats - Real-time resume parsing using LLM - Progress indicator during upload - Error handling with clear messages</p> <p>Resume Analysis Display: - Candidate name, experience level, and years of experience - Domain expertise displayed as styled badges - Work experience summary (first 3 entries) - Education summary (first 2 entries) - Skills list (first 10 skills)</p>"},{"location":"SETUP_UI/#2-ai-provider-configuration-render_ai_configuration_section","title":"2. AI Provider Configuration (<code>render_ai_configuration_section</code>)","text":"<p>Features: - Dropdown selection for OpenAI GPT-4 or Anthropic Claude - Automatic detection of available providers based on API keys - API credential validation with test calls - Clear error messages for missing or invalid credentials</p> <p>Supported Providers: - OpenAI GPT-4 (requires OPENAI_API_KEY) - Anthropic Claude (requires ANTHROPIC_API_KEY)</p>"},{"location":"SETUP_UI/#3-communication-mode-selection-render_communication_mode_section","title":"3. Communication Mode Selection (<code>render_communication_mode_section</code>)","text":"<p>Features: - Checkboxes for each communication mode:   - \ud83c\udfa4 Audio (recording and transcription)   - \ud83d\udcf9 Video (recording)   - \ud83c\udfa8 Whiteboard (system design diagrams) - default enabled   - \ud83d\udda5\ufe0f Screen Share (periodic captures) - Multiple modes can be enabled simultaneously - Text mode is always included - Visual confirmation of selected modes</p>"},{"location":"SETUP_UI/#4-start-interview-button-render_start_interview_button","title":"4. Start Interview Button (<code>render_start_interview_button</code>)","text":"<p>Features: - Validation of required configurations - Clear indication of missing items - Session creation with all selected configurations - Automatic navigation to interview interface - Error handling for session creation failures</p>"},{"location":"SETUP_UI/#application-factory","title":"Application Factory","text":"<p>The <code>src/app_factory.py</code> module provides dependency injection for all components:</p> <pre><code>def create_app(config_path: str = \"config.yaml\") -&gt; dict:\n    \"\"\"\n    Creates and wires up all application components.\n\n    Returns:\n        Dictionary with initialized components:\n        - config\n        - data_store\n        - file_storage\n        - logger\n        - token_tracker\n        - resume_manager\n        - communication_manager\n        - ai_interviewer\n        - evaluation_manager\n        - session_manager\n    \"\"\"\n</code></pre>"},{"location":"SETUP_UI/#main-application-integration","title":"Main Application Integration","text":"<p>The <code>src/main.py</code> has been updated to: - Initialize application components on first load - Provide sidebar navigation between pages - Route to appropriate page based on user selection - Display session information when active - Handle page transitions</p>"},{"location":"SETUP_UI/#session-state-management","title":"Session State Management","text":"<p>The following session state variables are used:</p> <ul> <li><code>app_components</code>: Dictionary of initialized components</li> <li><code>current_page</code>: Current page name (setup, interview, evaluation, history)</li> <li><code>resume_data</code>: Parsed resume data</li> <li><code>resume_uploaded</code>: Boolean flag for resume upload status</li> <li><code>ai_provider</code>: Selected AI provider name</li> <li><code>ai_model</code>: Selected AI model name</li> <li><code>enabled_modes</code>: List of enabled communication modes</li> <li><code>current_session_id</code>: Active session identifier</li> <li><code>session_created</code>: Boolean flag for session creation status</li> <li><code>user_id</code>: User identifier</li> </ul>"},{"location":"SETUP_UI/#usage","title":"Usage","text":""},{"location":"SETUP_UI/#starting-the-application","title":"Starting the Application","text":"<pre><code># Install dependencies\npip install -r requirements.txt\n\n# Set environment variables\nexport DB_PASSWORD=\"your_db_password\"\nexport OPENAI_API_KEY=\"your_openai_key\"  # or ANTHROPIC_API_KEY\n\n# Run the application\nstreamlit run src/main.py\n</code></pre>"},{"location":"SETUP_UI/#user-workflow","title":"User Workflow","text":"<ol> <li>Upload Resume (Optional)</li> <li>Click \"Choose a PDF or TXT file\"</li> <li>Wait for parsing to complete</li> <li> <p>Review extracted information</p> </li> <li> <p>Configure AI Provider</p> </li> <li>Select OpenAI GPT-4 or Anthropic Claude</li> <li> <p>Optionally validate credentials</p> </li> <li> <p>Select Communication Modes</p> </li> <li>Check desired modes (audio, video, whiteboard, screen share)</li> <li> <p>Text mode is always enabled</p> </li> <li> <p>Start Interview</p> </li> <li>Click \"Start Interview\" button</li> <li>System creates session and navigates to interview interface</li> </ol>"},{"location":"SETUP_UI/#error-handling","title":"Error Handling","text":"<p>The implementation includes comprehensive error handling:</p> <ul> <li>ValidationError: Invalid file format or empty resume</li> <li>AIProviderError: LLM parsing failures or invalid credentials</li> <li>InterviewPlatformError: Session creation failures</li> <li>Generic exceptions with user-friendly messages</li> </ul>"},{"location":"SETUP_UI/#requirements-satisfied","title":"Requirements Satisfied","text":""},{"location":"SETUP_UI/#requirement-191-resume-upload","title":"Requirement 19.1 (Resume Upload)","text":"<p>\u2705 Interface to upload resume before starting session \u2705 Extract experience level from resume \u2705 Extract domain expertise from resume</p>"},{"location":"SETUP_UI/#requirements-91-95-ai-configuration","title":"Requirements 9.1-9.5 (AI Configuration)","text":"<p>\u2705 Support for OpenAI GPT-4 \u2705 Support for Anthropic Claude \u2705 Configuration interface for API keys and model selection \u2705 Validate API credentials before starting session \u2705 Display clear error messages for invalid credentials</p>"},{"location":"SETUP_UI/#requirements-21-22-communication-modes","title":"Requirements 2.1-2.2 (Communication Modes)","text":"<p>\u2705 Provide audio, video, whiteboard, and screen share options \u2705 Allow multiple modes to be enabled simultaneously</p>"},{"location":"SETUP_UI/#requirements-11-12-session-creation","title":"Requirements 1.1-1.2 (Session Creation)","text":"<p>\u2705 Interface to initiate new interview session \u2705 Create unique session identifier \u2705 Initialize AI Interviewer with configuration</p>"},{"location":"SETUP_UI/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Resume editing capability</li> <li>Multiple resume support per user</li> <li>Advanced AI model configuration (temperature, max tokens)</li> <li>Communication mode presets</li> <li>Session templates</li> </ul>"},{"location":"TOKEN_TRACKING/","title":"Token Tracking System","text":""},{"location":"TOKEN_TRACKING/#overview","title":"Overview","text":"<p>The Token Tracking system provides comprehensive monitoring and cost estimation for AI API usage across interview sessions. It tracks token consumption, calculates costs based on provider-specific pricing, and provides detailed analytics.</p>"},{"location":"TOKEN_TRACKING/#implementation","title":"Implementation","text":""},{"location":"TOKEN_TRACKING/#tokentracker-class","title":"TokenTracker Class","text":"<p>Located in <code>src/ai/token_tracker.py</code>, the TokenTracker class provides:</p> <ul> <li>Token Usage Recording: Records input/output tokens for each AI API call</li> <li>Cost Calculation: Calculates estimated costs based on provider pricing models</li> <li>Session Aggregation: Aggregates token usage across an entire session</li> <li>Operation Breakdown: Provides usage breakdown by operation type (question_generation, response_analysis, evaluation)</li> </ul>"},{"location":"TOKEN_TRACKING/#key-features","title":"Key Features","text":"<ol> <li>Multi-Provider Support</li> <li>OpenAI (GPT-4, GPT-4 Turbo, GPT-3.5 Turbo)</li> <li>Anthropic (Claude 3 Opus, Sonnet, Haiku)</li> <li> <p>Fallback to default pricing for unknown providers</p> </li> <li> <p>Accurate Cost Estimation</p> </li> <li>Provider-specific pricing per 1M tokens</li> <li>Separate input/output token pricing</li> <li> <p>Precision to 6 decimal places</p> </li> <li> <p>Database Integration</p> </li> <li>Persists all token usage records to PostgreSQL</li> <li>Supports querying historical usage</li> <li> <p>Associates usage with sessions</p> </li> <li> <p>Operation Tracking</p> </li> <li>Categorizes usage by operation type</li> <li>Enables cost analysis by feature</li> <li>Supports usage optimization</li> </ol>"},{"location":"TOKEN_TRACKING/#usage-example","title":"Usage Example","text":"<pre><code>from src.ai.token_tracker import TokenTracker\nfrom src.database.data_store import PostgresDataStore\n\n# Initialize\ndb = PostgresDataStore(...)\ntracker = TokenTracker(data_store=db)\n\n# Record usage\nusage = tracker.record_usage(\n    session_id=\"session-123\",\n    provider=\"openai\",\n    model=\"gpt-4-turbo-preview\",\n    operation=\"question_generation\",\n    input_tokens=500,\n    output_tokens=200\n)\n\n# Get session summary\nsession_usage = tracker.get_session_usage(\"session-123\")\nprint(f\"Total cost: ${session_usage.total_cost:.6f}\")\n\n# Get breakdown by operation\nbreakdown = tracker.get_usage_breakdown(\"session-123\")\nfor operation, usage in breakdown.items():\n    print(f\"{operation}: {usage.total_tokens} tokens, ${usage.estimated_cost:.6f}\")\n</code></pre>"},{"location":"TOKEN_TRACKING/#pricing-table","title":"Pricing Table","text":"<p>Current pricing (as of 2024):</p>"},{"location":"TOKEN_TRACKING/#openai","title":"OpenAI","text":"<ul> <li>GPT-4 Turbo: $10/1M input, $30/1M output</li> <li>GPT-4: $30/1M input, $60/1M output</li> <li>GPT-3.5 Turbo: $0.50/1M input, $1.50/1M output</li> </ul>"},{"location":"TOKEN_TRACKING/#anthropic","title":"Anthropic","text":"<ul> <li>Claude 3 Opus: $15/1M input, $75/1M output</li> <li>Claude 3 Sonnet: $3/1M input, $15/1M output</li> <li>Claude 3 Haiku: $0.25/1M input, $1.25/1M output</li> </ul>"},{"location":"TOKEN_TRACKING/#database-schema","title":"Database Schema","text":"<p>Token usage is stored in the <code>token_usage</code> table:</p> <pre><code>CREATE TABLE token_usage (\n    id BIGSERIAL PRIMARY KEY,\n    session_id UUID NOT NULL,\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    operation VARCHAR(50) NOT NULL,\n    provider VARCHAR(50) NOT NULL,\n    model VARCHAR(100) NOT NULL,\n    input_tokens INTEGER NOT NULL,\n    output_tokens INTEGER NOT NULL,\n    total_tokens INTEGER NOT NULL,\n    estimated_cost DECIMAL(10,6) NOT NULL,\n    FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE\n);\n</code></pre>"},{"location":"TOKEN_TRACKING/#testing","title":"Testing","text":"<p>Unit tests are provided in <code>test_token_tracker_unit.py</code> that verify: - Cost calculation accuracy - Session aggregation - Operation breakdown - Multi-provider support - Unknown provider handling</p> <p>Run tests with: <pre><code>python test_token_tracker_unit.py\n</code></pre></p>"},{"location":"TOKEN_TRACKING/#requirements-satisfied","title":"Requirements Satisfied","text":"<p>This implementation satisfies the following requirements:</p> <ul> <li>14.1: Records input token count for each AI API call</li> <li>14.2: Records output token count for each response</li> <li>14.3: Calculates estimated cost based on provider pricing</li> <li>14.4: Stores token usage in database with session association</li> <li>14.5: Provides session usage summary</li> <li>14.6: Categorizes usage by operation type</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to the AI Mock Interview Platform will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>GitHub Pages documentation site with MkDocs Material theme</li> <li>Comprehensive API documentation</li> <li>Component-level documentation</li> <li>Feature guides and tutorials</li> </ul>"},{"location":"changelog/#100-2024-01-15","title":"[1.0.0] - 2024-01-15","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Initial release of AI Mock Interview Platform</li> <li>Multi-modal communication support (audio, video, whiteboard, screen share)</li> <li>AI-powered interviewer using OpenAI GPT-4 and Anthropic Claude</li> <li>Resume-aware problem generation</li> <li>Interactive whiteboard for system design diagrams</li> <li>Comprehensive evaluation system with detailed feedback</li> <li>Token usage tracking and budget management</li> <li>PostgreSQL-based data persistence</li> <li>Local file storage for media files</li> <li>Comprehensive logging system (console, file, database)</li> <li>Docker-based deployment with Docker Compose</li> <li>Streamlit web interface</li> <li>Session history and progress tracking</li> </ul>"},{"location":"changelog/#core-components","title":"Core Components","text":"<ul> <li>Session Manager: Interview lifecycle orchestration</li> <li>AI Interviewer: LLM-powered question generation and response analysis</li> <li>Communication Manager: Multi-modal communication handling</li> <li>Evaluation Manager: Performance analysis and feedback generation</li> <li>Resume Manager: Resume parsing and analysis</li> <li>Data Store: PostgreSQL repository implementation</li> <li>File Storage: Local filesystem media storage</li> <li>Logging Manager: Multi-destination logging system</li> </ul>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>Resume Upload: PDF and text format support</li> <li>AI Provider Selection: OpenAI GPT-4 or Anthropic Claude</li> <li>Communication Modes: Text, audio, video, whiteboard, screen share</li> <li>Real-time Interaction: Instant AI responses and live transcripts</li> <li>Whiteboard Drawing: Canvas with drawing tools and snapshot capability</li> <li>Audio Transcription: Automatic transcription using Whisper</li> <li>Token Tracking: Real-time usage monitoring and cost estimation</li> <li>Evaluation Reports: Detailed scores, strengths, and improvement plans</li> <li>Session History: View and review past interview sessions</li> <li>Progress Tracking: Track improvement across multiple sessions</li> </ul>"},{"location":"changelog/#infrastructure","title":"Infrastructure","text":"<ul> <li>Database: PostgreSQL 15 with Docker deployment</li> <li>Storage: Local filesystem with organized directory structure</li> <li>Logging: Multi-level logging with rotation and database persistence</li> <li>Configuration: YAML-based configuration with environment variables</li> <li>Deployment: Docker Compose for easy local setup</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Quick Start Guide for end users</li> <li>Developer Setup Guide for contributors</li> <li>Architecture documentation with diagrams</li> <li>Component-level API documentation</li> <li>Logging system documentation</li> <li>Code standards and contribution guidelines</li> </ul>"},{"location":"changelog/#testing","title":"Testing","text":"<ul> <li>Unit tests for all core components</li> <li>Integration tests for complete workflows</li> <li>Test coverage reporting</li> <li>Pre-commit hooks for code quality</li> </ul>"},{"location":"changelog/#development-tools","title":"Development Tools","text":"<ul> <li>Black for code formatting</li> <li>Ruff for linting</li> <li>mypy for type checking</li> <li>isort for import sorting</li> <li>pytest for testing</li> <li>Pre-commit hooks for automation</li> </ul>"},{"location":"changelog/#090-2024-01-01","title":"[0.9.0] - 2024-01-01","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Beta release for internal testing</li> <li>Core interview functionality</li> <li>Basic evaluation system</li> <li>PostgreSQL integration</li> <li>Streamlit UI prototype</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Refactored to use dependency injection</li> <li>Implemented repository pattern for data access</li> <li>Improved error handling and logging</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Database connection stability issues</li> <li>Token tracking accuracy</li> <li>Whiteboard snapshot timing</li> </ul>"},{"location":"changelog/#050-2023-12-15","title":"[0.5.0] - 2023-12-15","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Alpha release for proof-of-concept</li> <li>Basic AI interviewer functionality</li> <li>Text-based communication</li> <li>Simple evaluation scoring</li> <li>SQLite database</li> </ul>"},{"location":"changelog/#known-issues","title":"Known Issues","text":"<ul> <li>Limited to text communication only</li> <li>No resume analysis</li> <li>Basic evaluation criteria</li> <li>No token tracking</li> </ul>"},{"location":"changelog/#version-history","title":"Version History","text":"<ul> <li>1.0.0 (2024-01-15): Initial public release</li> <li>0.9.0 (2024-01-01): Beta release</li> <li>0.5.0 (2023-12-15): Alpha release</li> </ul>"},{"location":"changelog/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"changelog/#from-090-to-100","title":"From 0.9.0 to 1.0.0","text":"<ol> <li>Database Migration: Run migration scripts to update schema</li> <li>Configuration: Update <code>config.yaml</code> with new token tracking settings</li> <li>Environment Variables: Add <code>MAX_TOKENS_PER_SESSION</code> to <code>.env</code></li> <li>Dependencies: Update to latest versions with <code>pip install -r requirements.txt</code></li> </ol>"},{"location":"changelog/#from-050-to-090","title":"From 0.5.0 to 0.9.0","text":"<ol> <li>Database: Migrate from SQLite to PostgreSQL</li> <li>Configuration: Convert to YAML-based configuration</li> <li>Code: Update to use new dependency injection pattern</li> </ol>"},{"location":"changelog/#deprecation-notices","title":"Deprecation Notices","text":""},{"location":"changelog/#version-100","title":"Version 1.0.0","text":"<ul> <li>None</li> </ul>"},{"location":"changelog/#future-deprecations","title":"Future Deprecations","text":"<ul> <li>SQLite support will be removed in version 2.0.0</li> <li>Legacy evaluation format will be deprecated in version 1.5.0</li> </ul>"},{"location":"changelog/#security-updates","title":"Security Updates","text":""},{"location":"changelog/#version-100_1","title":"Version 1.0.0","text":"<ul> <li>Implemented secure API key storage</li> <li>Added input validation for all user inputs</li> <li>Sanitized file uploads</li> <li>Implemented rate limiting for API calls</li> </ul>"},{"location":"changelog/#performance-improvements","title":"Performance Improvements","text":""},{"location":"changelog/#version-100_2","title":"Version 1.0.0","text":"<ul> <li>Optimized database queries with indexes</li> <li>Implemented connection pooling</li> <li>Added caching for frequently accessed data</li> <li>Reduced AI API latency with streaming</li> </ul>"},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":""},{"location":"changelog/#version-100_3","title":"Version 1.0.0","text":"<ul> <li>None (initial release)</li> </ul>"},{"location":"changelog/#version-090","title":"Version 0.9.0","text":"<ul> <li>Changed from SQLite to PostgreSQL (requires migration)</li> <li>Updated configuration format from JSON to YAML</li> <li>Refactored API with dependency injection</li> </ul>"},{"location":"changelog/#contributors","title":"Contributors","text":"<p>Thank you to all contributors who made this release possible!</p> <ul> <li>Initial development team</li> <li>Beta testers</li> <li>Documentation contributors</li> </ul>"},{"location":"changelog/#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>Documentation</li> <li>Issue Tracker</li> <li>Discussions</li> </ul> <p>For detailed implementation notes, see Implementation Notes.</p>"},{"location":"code-standards/","title":"Code Standards","text":"<p>This document outlines the coding standards and best practices for the AI Mock Interview Platform.</p>"},{"location":"code-standards/#python-style-guide","title":"Python Style Guide","text":""},{"location":"code-standards/#pep-8-compliance","title":"PEP 8 Compliance","text":"<p>Follow PEP 8 with these specifics:</p> <ul> <li>Indentation: 4 spaces (no tabs)</li> <li>Line Length: 88 characters (Black default)</li> <li>Blank Lines: 2 between top-level definitions, 1 between methods</li> <li>Imports: Grouped and sorted (stdlib, third-party, local)</li> </ul>"},{"location":"code-standards/#naming-conventions","title":"Naming Conventions","text":"<pre><code># Variables and functions: snake_case\nuser_name = \"John\"\ndef calculate_score():\n    pass\n\n# Classes: PascalCase\nclass SessionManager:\n    pass\n\n# Constants: UPPER_CASE\nMAX_TOKENS = 50000\nDEFAULT_PROVIDER = \"openai\"\n\n# Private members: _leading_underscore\ndef _internal_helper():\n    pass\n</code></pre>"},{"location":"code-standards/#type-hints","title":"Type Hints","text":""},{"location":"code-standards/#always-use-type-hints","title":"Always Use Type Hints","text":"<pre><code>from typing import Optional, List, Dict\n\ndef process_response(\n    session_id: str,\n    response: str,\n    whiteboard_image: Optional[bytes] = None\n) -&gt; InterviewResponse:\n    pass\n</code></pre>"},{"location":"code-standards/#complex-types","title":"Complex Types","text":"<pre><code>from typing import Union, Callable, TypeVar\n\nT = TypeVar('T')\n\ndef get_or_default(\n    value: Optional[T],\n    default: T\n) -&gt; T:\n    return value if value is not None else default\n</code></pre>"},{"location":"code-standards/#docstrings","title":"Docstrings","text":""},{"location":"code-standards/#google-style","title":"Google Style","text":"<pre><code>def create_session(self, config: SessionConfig) -&gt; Session:\n    \"\"\"Create a new interview session.\n\n    This method creates a new session with the provided configuration,\n    initializes all required components, and persists the session to\n    the database.\n\n    Args:\n        config: Session configuration including enabled communication\n            modes, AI provider selection, and token budget settings.\n\n    Returns:\n        A Session object with a unique identifier and CREATED status.\n\n    Raises:\n        ConfigurationError: If the configuration is invalid or incomplete.\n        DataStoreError: If the database operation fails.\n\n    Example:\n        &gt;&gt;&gt; config = SessionConfig(\n        ...     enabled_modes=[CommunicationMode.TEXT],\n        ...     ai_provider=\"openai\"\n        ... )\n        &gt;&gt;&gt; session = manager.create_session(config)\n        &gt;&gt;&gt; print(session.id)\n        '550e8400-e29b-41d4-a716-446655440000'\n    \"\"\"\n    pass\n</code></pre>"},{"location":"code-standards/#error-handling","title":"Error Handling","text":""},{"location":"code-standards/#use-specific-exceptions","title":"Use Specific Exceptions","text":"<pre><code># Good\ntry:\n    session = self.data_store.get_session(session_id)\nexcept SessionNotFoundError:\n    raise\nexcept DatabaseError as e:\n    raise DataStoreError(f\"Failed to retrieve session: {e}\") from e\n\n# Bad\ntry:\n    session = self.data_store.get_session(session_id)\nexcept Exception:\n    pass\n</code></pre>"},{"location":"code-standards/#always-log-errors","title":"Always Log Errors","text":"<pre><code>try:\n    result = risky_operation()\nexcept OperationError as e:\n    self.logger.error(\n        \"operation_failed\",\n        operation=\"risky_operation\",\n        error=str(e),\n        session_id=session_id\n    )\n    raise\n</code></pre>"},{"location":"code-standards/#solid-principles","title":"SOLID Principles","text":""},{"location":"code-standards/#single-responsibility","title":"Single Responsibility","text":"<p>Each class should have one clear purpose:</p> <pre><code># Good: Focused responsibility\nclass SessionManager:\n    \"\"\"Manages interview session lifecycle.\"\"\"\n    pass\n\nclass DataStore:\n    \"\"\"Handles data persistence.\"\"\"\n    pass\n\n# Bad: Multiple responsibilities\nclass SessionManagerAndDataStore:\n    \"\"\"Manages sessions AND handles persistence.\"\"\"\n    pass\n</code></pre>"},{"location":"code-standards/#dependency-injection","title":"Dependency Injection","text":"<p>Always inject dependencies:</p> <pre><code># Good\nclass SessionManager:\n    def __init__(\n        self,\n        data_store: DataStore,\n        ai_interviewer: AIInterviewer\n    ):\n        self.data_store = data_store\n        self.ai_interviewer = ai_interviewer\n\n# Bad\nclass SessionManager:\n    def __init__(self):\n        self.data_store = PostgresDataStore()  # Hard-coded dependency\n</code></pre>"},{"location":"code-standards/#code-organization","title":"Code Organization","text":""},{"location":"code-standards/#file-structure","title":"File Structure","text":"<pre><code># 1. Module docstring\n\"\"\"Session management module.\n\nThis module provides the SessionManager class for orchestrating\ninterview sessions.\n\"\"\"\n\n# 2. Imports (grouped and sorted)\nimport logging\nfrom typing import Optional\n\nfrom langchain import LLMChain\n\nfrom src.models import Session\nfrom src.database import DataStore\n\n# 3. Constants\nMAX_SESSION_DURATION = 7200  # 2 hours\n\n# 4. Classes and functions\nclass SessionManager:\n    pass\n</code></pre>"},{"location":"code-standards/#keep-functions-small","title":"Keep Functions Small","text":"<pre><code># Good: Small, focused function\ndef validate_config(config: SessionConfig) -&gt; None:\n    \"\"\"Validate session configuration.\"\"\"\n    if not config.enabled_modes:\n        raise ConfigurationError(\"At least one mode must be enabled\")\n    if not config.ai_provider:\n        raise ConfigurationError(\"AI provider must be specified\")\n\n# Bad: Large, complex function\ndef create_and_start_session_with_validation_and_logging(config):\n    # 100+ lines of mixed concerns\n    pass\n</code></pre>"},{"location":"code-standards/#testing-standards","title":"Testing Standards","text":""},{"location":"code-standards/#test-structure","title":"Test Structure","text":"<pre><code>def test_create_session_with_valid_config():\n    \"\"\"Test session creation with valid configuration.\"\"\"\n    # Arrange\n    mock_data_store = Mock(spec=DataStore)\n    session_manager = SessionManager(data_store=mock_data_store)\n    config = SessionConfig(enabled_modes=[CommunicationMode.TEXT])\n\n    # Act\n    session = session_manager.create_session(config)\n\n    # Assert\n    assert session.id is not None\n    assert session.status == SessionStatus.CREATED\n    mock_data_store.save_session.assert_called_once()\n</code></pre>"},{"location":"code-standards/#test-naming","title":"Test Naming","text":"<pre><code># Good: Descriptive test names\ndef test_create_session_with_invalid_config_raises_error():\n    pass\n\ndef test_end_session_generates_evaluation():\n    pass\n\n# Bad: Vague test names\ndef test_session():\n    pass\n\ndef test_1():\n    pass\n</code></pre>"},{"location":"code-standards/#performance-guidelines","title":"Performance Guidelines","text":""},{"location":"code-standards/#use-appropriate-data-structures","title":"Use Appropriate Data Structures","text":"<pre><code># Good: O(1) lookup\nuser_sessions = {user_id: session for user_id, session in sessions}\nsession = user_sessions.get(user_id)\n\n# Bad: O(n) lookup\nsession = next(s for s in sessions if s.user_id == user_id)\n</code></pre>"},{"location":"code-standards/#avoid-premature-optimization","title":"Avoid Premature Optimization","text":"<pre><code># Good: Clear and correct\ndef calculate_score(scores: List[float]) -&gt; float:\n    return sum(scores) / len(scores)\n\n# Bad: Premature optimization\ndef calculate_score(scores: List[float]) -&gt; float:\n    # Complex optimization that's hard to read\n    pass\n</code></pre>"},{"location":"code-standards/#security-guidelines","title":"Security Guidelines","text":""},{"location":"code-standards/#never-log-sensitive-data","title":"Never Log Sensitive Data","text":"<pre><code># Good\nself.logger.info(\"User authenticated\", user_id=user.id)\n\n# Bad\nself.logger.info(\"User authenticated\", password=user.password)\n</code></pre>"},{"location":"code-standards/#validate-input","title":"Validate Input","text":"<pre><code>def process_response(self, response: str) -&gt; None:\n    \"\"\"Process user response.\"\"\"\n    if not response or len(response) &gt; 10000:\n        raise ValueError(\"Invalid response length\")\n\n    # Process response\n    pass\n</code></pre>"},{"location":"code-standards/#documentation-standards","title":"Documentation Standards","text":""},{"location":"code-standards/#readme-files","title":"README Files","text":"<p>Every module should have a README explaining: - Purpose - Key components - Usage examples - Dependencies</p>"},{"location":"code-standards/#code-comments","title":"Code Comments","text":"<pre><code># Good: Explain WHY, not WHAT\n# Use exponential backoff to handle transient network errors\nretry_delay = 2 ** attempt\n\n# Bad: Explain obvious code\n# Increment counter by 1\ncounter += 1\n</code></pre>"},{"location":"code-standards/#git-commit-standards","title":"Git Commit Standards","text":""},{"location":"code-standards/#commit-message-format","title":"Commit Message Format","text":"<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre>"},{"location":"code-standards/#types","title":"Types","text":"<ul> <li><code>feat</code>: New feature</li> <li><code>fix</code>: Bug fix</li> <li><code>docs</code>: Documentation</li> <li><code>style</code>: Formatting</li> <li><code>refactor</code>: Code restructuring</li> <li><code>test</code>: Tests</li> <li><code>chore</code>: Maintenance</li> </ul>"},{"location":"code-standards/#examples","title":"Examples","text":"<pre><code>feat(ai): add Claude 3 support\n\nImplement Anthropic Claude 3 provider with streaming support.\nAdd configuration options for model selection.\n\nCloses #123\n</code></pre>"},{"location":"code-standards/#tools-and-automation","title":"Tools and Automation","text":""},{"location":"code-standards/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Required checks: - Black (formatting) - Ruff (linting) - mypy (type checking) - isort (import sorting)</p>"},{"location":"code-standards/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>All PRs must pass: - Unit tests - Integration tests - Code coverage (80%+) - Type checking - Linting</p>"},{"location":"code-standards/#related-documents","title":"Related Documents","text":"<ul> <li>Contributing Guide</li> <li>Developer Setup</li> <li>Architecture</li> </ul>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing to the AI Mock Interview Platform! This guide will help you get started.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository</li> <li>Clone your fork locally</li> <li>Follow the Developer Setup Guide</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Submit a pull request</li> </ol>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#1-create-a-feature-branch","title":"1. Create a Feature Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n</code></pre> <p>Use descriptive branch names: - <code>feature/add-coding-interviews</code> - <code>fix/audio-recording-bug</code> - <code>docs/update-api-reference</code></p>"},{"location":"contributing/#2-make-your-changes","title":"2. Make Your Changes","text":"<p>Follow our coding standards: - Write clean, readable code - Add type hints to all functions - Write docstrings for public APIs - Keep functions under 50 lines - Keep files under 300 lines</p>"},{"location":"contributing/#3-write-tests","title":"3. Write Tests","text":"<ul> <li>Unit tests for business logic</li> <li>Integration tests for workflows</li> <li>Aim for 80%+ coverage</li> </ul> <pre><code># Run tests\npytest\n\n# Run with coverage\npytest --cov=src --cov-report=html\n</code></pre>"},{"location":"contributing/#4-run-quality-checks","title":"4. Run Quality Checks","text":"<pre><code># Format code\nblack src/ tests/\n\n# Lint code\nruff check src/ tests/ --fix\n\n# Type check\nmypy src/\n\n# Run all checks\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/#5-commit-your-changes","title":"5. Commit Your Changes","text":"<p>Follow conventional commits format:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes - <code>refactor</code>: Code refactoring - <code>test</code>: Test changes - <code>chore</code>: Build/tooling changes</p> <p>Example: <pre><code>feat(ai): add resume-aware problem generation\n\nImplement logic to generate interview problems based on candidate's\nexperience level and domain expertise from resume.\n\nCloses #123\n</code></pre></p>"},{"location":"contributing/#6-push-and-create-pr","title":"6. Push and Create PR","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request on GitHub.</p>"},{"location":"contributing/#code-standards","title":"Code Standards","text":""},{"location":"contributing/#python-style","title":"Python Style","text":"<p>Follow PEP 8 with these specifics:</p> <ul> <li>4 spaces for indentation</li> <li>Max line length: 88 characters (Black default)</li> <li>Use snake_case for functions and variables</li> <li>Use PascalCase for classes</li> <li>Use UPPER_CASE for constants</li> </ul>"},{"location":"contributing/#type-hints","title":"Type Hints","text":"<p>Always use type hints:</p> <pre><code>def process_response(\n    session_id: str,\n    response: str,\n    whiteboard_image: Optional[bytes] = None\n) -&gt; InterviewResponse:\n    \"\"\"Process candidate response.\"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings:</p> <pre><code>def create_session(self, config: SessionConfig) -&gt; Session:\n    \"\"\"Create a new interview session.\n\n    Args:\n        config: Session configuration including enabled modes and AI provider.\n\n    Returns:\n        Created session with unique identifier.\n\n    Raises:\n        ConfigurationError: If configuration is invalid.\n        DataStoreError: If database operation fails.\n\n    Example:\n        &gt;&gt;&gt; config = SessionConfig(enabled_modes=[CommunicationMode.TEXT])\n        &gt;&gt;&gt; session = manager.create_session(config)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#error-handling","title":"Error Handling","text":"<p>Always handle errors gracefully:</p> <pre><code>try:\n    result = self.data_store.save_session(session)\nexcept DatabaseError as e:\n    self.logger.error(\n        \"session_save_failed\",\n        session_id=session.id,\n        error=str(e)\n    )\n    raise DataStoreError(f\"Failed to save session: {e}\") from e\n</code></pre>"},{"location":"contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"contributing/#unit-tests","title":"Unit Tests","text":"<p>Test individual components in isolation:</p> <pre><code>def test_create_session(mock_data_store):\n    # Arrange\n    session_manager = SessionManager(data_store=mock_data_store)\n    config = SessionConfig(enabled_modes=[CommunicationMode.TEXT])\n\n    # Act\n    session = session_manager.create_session(config)\n\n    # Assert\n    assert session.id is not None\n    mock_data_store.save_session.assert_called_once()\n</code></pre>"},{"location":"contributing/#integration-tests","title":"Integration Tests","text":"<p>Test complete workflows:</p> <pre><code>@pytest.mark.integration\ndef test_complete_interview_workflow(test_database):\n    # Test full interview from start to evaluation\n    pass\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"contributing/#pr-checklist","title":"PR Checklist","text":"<ul> <li>[ ] Code follows style guidelines</li> <li>[ ] Self-review completed</li> <li>[ ] Comments added for complex logic</li> <li>[ ] Documentation updated</li> <li>[ ] Tests added/updated</li> <li>[ ] All tests pass</li> <li>[ ] No new warnings</li> <li>[ ] Dependent changes merged</li> </ul>"},{"location":"contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing completed\n\n## Screenshots (if applicable)\nAdd screenshots here\n</code></pre>"},{"location":"contributing/#review-process","title":"Review Process","text":"<ol> <li>Automated checks run (CI/CD)</li> <li>Code review by maintainers</li> <li>Address feedback</li> <li>Approval and merge</li> </ol>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":""},{"location":"contributing/#be-respectful","title":"Be Respectful","text":"<ul> <li>Be kind and courteous</li> <li>Respect different viewpoints</li> <li>Accept constructive criticism</li> <li>Focus on what's best for the project</li> </ul>"},{"location":"contributing/#be-collaborative","title":"Be Collaborative","text":"<ul> <li>Help others learn</li> <li>Share knowledge</li> <li>Ask questions</li> <li>Provide feedback</li> </ul>"},{"location":"contributing/#be-professional","title":"Be Professional","text":"<ul> <li>Keep discussions on-topic</li> <li>Avoid personal attacks</li> <li>Use inclusive language</li> <li>Follow the code of conduct</li> </ul>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Questions: Open a GitHub Discussion</li> <li>Bugs: Create an issue with reproduction steps</li> <li>Features: Open an issue to discuss before implementing</li> <li>Security: Email security@example.com</li> </ul>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors will be: - Listed in CONTRIBUTORS.md - Mentioned in release notes - Credited in documentation</p> <p>Thank you for contributing! \ud83c\udf89</p>"},{"location":"developer-setup/","title":"Developer Setup Guide","text":"<p>This guide provides comprehensive instructions for developers who want to contribute to or extend the AI Mock Interview Platform.</p>"},{"location":"developer-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"developer-setup/#required-software","title":"Required Software","text":"Software Version Purpose Download Link Python 3.10+ Runtime environment python.org Docker Desktop Latest Container orchestration docker.com Git Latest Version control git-scm.com PostgreSQL Client 15+ Database management (optional) postgresql.org"},{"location":"developer-setup/#api-keys","title":"API Keys","text":"<p>You'll need API keys for development:</p> <ul> <li>OpenAI API Key (required): platform.openai.com</li> <li>Anthropic API Key (optional): console.anthropic.com</li> </ul>"},{"location":"developer-setup/#environment-setup","title":"Environment Setup","text":""},{"location":"developer-setup/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd ai-mock-interview-platform\n</code></pre>"},{"location":"developer-setup/#2-create-python-virtual-environment","title":"2. Create Python Virtual Environment","text":"<p>macOS/Linux: <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre></p> <p>Windows: <pre><code>python -m venv venv\nvenv\\Scripts\\activate\n</code></pre></p>"},{"location":"developer-setup/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Install production dependencies\npip install -r requirements.txt\n\n# Install development dependencies\npip install -r requirements-dev.txt\n</code></pre>"},{"location":"developer-setup/#4-configure-environment-variables","title":"4. Configure Environment Variables","text":"<p>Create a <code>.env</code> file:</p> <pre><code>cp .env.template .env\n</code></pre> <p>Edit <code>.env</code> with your configuration:</p> <pre><code># Database Configuration\nDB_PASSWORD=dev_password_123\nDATABASE_URL=postgresql://interview_user:dev_password_123@localhost:5432/interview_platform\n\n# AI Provider API Keys\nOPENAI_API_KEY=sk-proj-your-key-here\nANTHROPIC_API_KEY=sk-ant-your-key-here\n\n# Application Configuration\nLOG_LEVEL=DEBUG\nDATA_DIR=./data\nENVIRONMENT=development\n</code></pre>"},{"location":"developer-setup/#5-start-docker-services","title":"5. Start Docker Services","text":"<pre><code># Start PostgreSQL and other services\ndocker-compose up -d\n\n# Verify services are running\ndocker-compose ps\n</code></pre>"},{"location":"developer-setup/#6-verify-setup","title":"6. Verify Setup","text":"<p>Run the validation script:</p> <pre><code>python validate_setup.py\n</code></pre>"},{"location":"developer-setup/#local-development","title":"Local Development","text":""},{"location":"developer-setup/#running-the-application","title":"Running the Application","text":"<p>Using Streamlit directly (recommended):</p> <pre><code>source venv/bin/activate  # macOS/Linux\nvenv\\Scripts\\activate     # Windows\n\nstreamlit run src/main.py\n</code></pre> <p>Using Docker Compose:</p> <pre><code>docker-compose up --build\n</code></pre>"},{"location":"developer-setup/#hot-reloading","title":"Hot Reloading","text":"<p>Streamlit automatically reloads when you save changes to Python files.</p>"},{"location":"developer-setup/#running-tests","title":"Running Tests","text":""},{"location":"developer-setup/#unit-tests","title":"Unit Tests","text":"<pre><code># Run all tests\npytest\n\n# Run specific test file\npytest tests/test_session_manager.py\n\n# Run with coverage\npytest --cov=src --cov-report=html\n</code></pre>"},{"location":"developer-setup/#integration-tests","title":"Integration Tests","text":"<pre><code># Run integration tests only\npytest tests/integration/\n\n# Run with markers\npytest -m integration\n</code></pre>"},{"location":"developer-setup/#code-quality","title":"Code Quality","text":""},{"location":"developer-setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install pre-commit\npip install pre-commit\n\n# Install git hooks\npre-commit install\n\n# Run manually\npre-commit run --all-files\n</code></pre>"},{"location":"developer-setup/#manual-quality-checks","title":"Manual Quality Checks","text":"<pre><code># Format code\nblack src/ tests/\n\n# Lint code\nruff check src/ tests/ --fix\n\n# Type check\nmypy src/ --strict\n\n# Sort imports\nisort src/ tests/ --profile black\n</code></pre>"},{"location":"developer-setup/#debugging","title":"Debugging","text":""},{"location":"developer-setup/#vs-code-configuration","title":"VS Code Configuration","text":"<p>Create <code>.vscode/launch.json</code>:</p> <pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"Python: Streamlit\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"module\": \"streamlit\",\n      \"args\": [\"run\", \"src/main.py\"],\n      \"console\": \"integratedTerminal\"\n    }\n  ]\n}\n</code></pre>"},{"location":"developer-setup/#debugging-tips","title":"Debugging Tips","text":"<ol> <li>Enable debug logging in <code>.env</code>: <code>LOG_LEVEL=DEBUG</code></li> <li>Use IDE breakpoints</li> <li>Check logs: <code>tail -f logs/interview_platform.log</code></li> <li>Inspect database: <code>docker exec -it interview_platform_db psql -U interview_user -d interview_platform</code></li> </ol>"},{"location":"developer-setup/#contributing","title":"Contributing","text":""},{"location":"developer-setup/#contribution-guidelines","title":"Contribution Guidelines","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Write/update tests</li> <li>Ensure all quality checks pass</li> <li>Submit a pull request</li> </ol>"},{"location":"developer-setup/#commit-message-format","title":"Commit Message Format","text":"<p>Follow conventional commits:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: feat, fix, docs, style, refactor, test, chore</p> <p>Example: <pre><code>feat(ai): add resume-aware problem generation\n\nImplement logic to generate interview problems based on candidate's\nexperience level and domain expertise from resume.\n\nCloses #123\n</code></pre></p>"},{"location":"developer-setup/#additional-resources","title":"Additional Resources","text":"<ul> <li>Architecture Documentation</li> <li>API Reference</li> <li>Quick Start Guide</li> <li>LangChain Documentation</li> <li>Streamlit Documentation</li> </ul> <p>Happy coding! \ud83d\ude80</p>"},{"location":"implementation-notes/","title":"Implementation Notes","text":"<p>This document provides detailed notes on key implementation decisions, technical challenges, and solutions in the AI Mock Interview Platform.</p>"},{"location":"implementation-notes/#architecture-decisions","title":"Architecture Decisions","text":""},{"location":"implementation-notes/#1-dependency-injection-pattern","title":"1. Dependency Injection Pattern","text":"<p>Decision: Use constructor-based dependency injection throughout the application.</p> <p>Rationale: - Enables easy testing with mock objects - Makes dependencies explicit and clear - Allows swapping implementations without code changes - No framework overhead (pure Python)</p> <p>Implementation: <pre><code>class SessionManager:\n    def __init__(\n        self,\n        data_store: DataStore,\n        ai_interviewer: AIInterviewer,\n        evaluation_manager: EvaluationManager,\n        communication_manager: CommunicationManager,\n        logger: LoggingManager\n    ):\n        self.data_store = data_store\n        self.ai_interviewer = ai_interviewer\n        # ...\n</code></pre></p> <p>Challenges: - Verbose constructors with many dependencies - Requires factory function for initialization - Need to maintain dependency graph manually</p> <p>Solutions: - Created <code>app_factory.py</code> to centralize dependency creation - Documented dependency graph in architecture docs - Used type hints to make dependencies clear</p>"},{"location":"implementation-notes/#2-repository-pattern-for-data-access","title":"2. Repository Pattern for Data Access","text":"<p>Decision: Abstract all data access behind repository interfaces.</p> <p>Rationale: - Enables future migration to cloud databases - Makes testing easier with in-memory implementations - Separates business logic from data access - Follows SOLID principles</p> <p>Implementation: <pre><code>class DataStore(ABC):\n    @abstractmethod\n    def save_session(self, session: Session) -&gt; None:\n        pass\n\n    @abstractmethod\n    def get_session(self, session_id: str) -&gt; Optional[Session]:\n        pass\n\nclass PostgresDataStore(DataStore):\n    def save_session(self, session: Session) -&gt; None:\n        # PostgreSQL implementation\n        pass\n</code></pre></p> <p>Challenges: - Additional abstraction layer adds complexity - Need to maintain interface and implementation - Query optimization can be harder with abstraction</p> <p>Solutions: - Kept interface focused and minimal - Documented expected behavior clearly - Allowed implementation-specific optimizations</p>"},{"location":"implementation-notes/#3-langchain-for-llm-orchestration","title":"3. LangChain for LLM Orchestration","text":"<p>Decision: Use LangChain framework for AI provider integration.</p> <p>Rationale: - Multi-provider support (OpenAI, Anthropic) - Built-in conversation memory - Prompt template management - Token tracking included - Active development and community</p> <p>Implementation: <pre><code>from langchain.chat_models import ChatOpenAI\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import ConversationChain\n\nclass AIInterviewer:\n    def __init__(self, provider: str, api_key: str):\n        self.llm = ChatOpenAI(\n            model=\"gpt-4\",\n            api_key=api_key,\n            temperature=0.7\n        )\n        self.memory = ConversationBufferMemory()\n        self.chain = ConversationChain(\n            llm=self.llm,\n            memory=self.memory\n        )\n</code></pre></p> <p>Challenges: - Learning curve for LangChain concepts - Version updates can introduce breaking changes - Some features are still experimental</p> <p>Solutions: - Pinned LangChain version in requirements - Created wrapper classes to isolate LangChain usage - Documented LangChain-specific patterns</p>"},{"location":"implementation-notes/#4-streamlit-for-ui","title":"4. Streamlit for UI","text":"<p>Decision: Use Streamlit for the web interface.</p> <p>Rationale: - Rapid development with pure Python - Built-in interactive components - WebRTC support for audio/video - Canvas support for whiteboard - Perfect for proof-of-concept</p> <p>Implementation: <pre><code>import streamlit as st\nfrom streamlit_webrtc import webrtc_streamer\nfrom streamlit_drawable_canvas import st_canvas\n\n# Simple UI with Streamlit\nst.title(\"AI Mock Interview Platform\")\nuploaded_file = st.file_uploader(\"Upload Resume\")\nif st.button(\"Start Interview\"):\n    start_interview()\n</code></pre></p> <p>Challenges: - State management can be tricky - Limited customization compared to React/Vue - Not ideal for production-scale applications - Page reloads on every interaction</p> <p>Solutions: - Used <code>st.session_state</code> for state management - Created reusable UI components - Documented Streamlit-specific patterns - Planned migration path to React for production</p>"},{"location":"implementation-notes/#5-local-file-storage","title":"5. Local File Storage","text":"<p>Decision: Store media files on local filesystem.</p> <p>Rationale: - Simple implementation for proof-of-concept - No cloud storage costs - Fast local access - Complete data privacy</p> <p>Implementation: <pre><code>class FileStorage:\n    def save_file(\n        self,\n        session_id: str,\n        file_type: str,\n        data: bytes\n    ) -&gt; str:\n        path = f\"data/sessions/{session_id}/{file_type}/\"\n        os.makedirs(path, exist_ok=True)\n        filename = f\"{uuid.uuid4()}.{extension}\"\n        filepath = os.path.join(path, filename)\n        with open(filepath, 'wb') as f:\n            f.write(data)\n        return filepath\n</code></pre></p> <p>Challenges: - Not scalable to multiple users - No backup or redundancy - Requires migration for cloud deployment</p> <p>Solutions: - Designed interface to support future S3 migration - Documented migration path in architecture docs - Kept file paths relative for portability</p>"},{"location":"implementation-notes/#technical-challenges-and-solutions","title":"Technical Challenges and Solutions","text":""},{"location":"implementation-notes/#1-token-budget-management","title":"1. Token Budget Management","text":"<p>Challenge: Need to track token usage in real-time and prevent budget overruns.</p> <p>Solution: - Created <code>TokenTracker</code> component - Integrated with LangChain callbacks - Added budget warnings at 80% threshold - Displayed real-time usage in UI</p> <p>Implementation: <pre><code>class TokenTracker:\n    def track_usage(\n        self,\n        session_id: str,\n        input_tokens: int,\n        output_tokens: int,\n        provider: str,\n        model: str\n    ) -&gt; TokenUsage:\n        usage = TokenUsage(\n            session_id=session_id,\n            input_tokens=input_tokens,\n            output_tokens=output_tokens,\n            total_tokens=input_tokens + output_tokens,\n            cost=self.calculate_cost(input_tokens, output_tokens, provider, model)\n        )\n        self.data_store.save_token_usage(usage)\n        return usage\n</code></pre></p>"},{"location":"implementation-notes/#2-whiteboard-context-integration","title":"2. Whiteboard Context Integration","text":"<p>Challenge: Include whiteboard snapshots in AI context without exceeding token limits.</p> <p>Solution: - Compress images before sending to AI - Use vision-capable models (GPT-4V) - Only include recent snapshots - Implement snapshot summarization</p> <p>Implementation: <pre><code>def process_response_with_whiteboard(\n    self,\n    response: str,\n    whiteboard_image: Optional[bytes]\n) -&gt; InterviewResponse:\n    if whiteboard_image:\n        # Compress image\n        compressed = self.compress_image(whiteboard_image)\n        # Convert to base64\n        image_b64 = base64.b64encode(compressed).decode()\n        # Include in prompt\n        prompt = f\"{response}\\n[Whiteboard: {image_b64}]\"\n    else:\n        prompt = response\n\n    return self.chain.run(prompt)\n</code></pre></p>"},{"location":"implementation-notes/#3-audio-transcription-accuracy","title":"3. Audio Transcription Accuracy","text":"<p>Challenge: Ensure accurate transcription of technical terms and system design concepts.</p> <p>Solution: - Use OpenAI Whisper for transcription - Implement custom vocabulary for technical terms - Allow manual correction of transcripts - Store both audio and transcript</p> <p>Implementation: <pre><code>def transcribe_audio(self, audio_data: bytes) -&gt; str:\n    # Use Whisper API\n    transcript = openai.Audio.transcribe(\n        model=\"whisper-1\",\n        file=audio_data,\n        language=\"en\",\n        prompt=\"System design interview discussing databases, caching, load balancing\"\n    )\n    return transcript.text\n</code></pre></p>"},{"location":"implementation-notes/#4-database-connection-pooling","title":"4. Database Connection Pooling","text":"<p>Challenge: Manage database connections efficiently to avoid exhaustion.</p> <p>Solution: - Implemented connection pooling with psycopg2 - Set appropriate pool size and timeout - Added connection health checks - Implemented retry logic with exponential backoff</p> <p>Implementation: <pre><code>from psycopg2 import pool\n\nclass PostgresDataStore:\n    def __init__(self, config: DatabaseConfig):\n        self.connection_pool = pool.ThreadedConnectionPool(\n            minconn=1,\n            maxconn=10,\n            host=config.host,\n            port=config.port,\n            database=config.database,\n            user=config.user,\n            password=config.password\n        )\n\n    def get_connection(self):\n        return self.connection_pool.getconn()\n\n    def return_connection(self, conn):\n        self.connection_pool.putconn(conn)\n</code></pre></p>"},{"location":"implementation-notes/#5-evaluation-consistency","title":"5. Evaluation Consistency","text":"<p>Challenge: Generate consistent, fair evaluations across different sessions.</p> <p>Solution: - Created structured evaluation prompts - Used temperature=0 for deterministic output - Implemented rubric-based scoring - Added human review capability</p> <p>Implementation: <pre><code>EVALUATION_PROMPT = \"\"\"\nEvaluate the interview based on these criteria:\n\n1. Problem Understanding (0-10)\n   - Did they ask clarifying questions?\n   - Did they identify requirements?\n   - Did they understand constraints?\n\n2. System Design Approach (0-10)\n   - Did they create a high-level architecture?\n   - Did they break down components?\n   - Did they design data flow?\n\n[... more criteria ...]\n\nProvide scores and detailed feedback.\n\"\"\"\n</code></pre></p>"},{"location":"implementation-notes/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"implementation-notes/#1-database-query-optimization","title":"1. Database Query Optimization","text":"<p>Optimizations: - Added indexes on frequently queried columns - Used connection pooling - Implemented query result caching - Optimized JOIN operations</p> <p>Example: <pre><code>-- Added indexes\nCREATE INDEX idx_sessions_user_id ON sessions(user_id);\nCREATE INDEX idx_conversations_session_id ON conversations(session_id);\nCREATE INDEX idx_media_files_session_id ON media_files(session_id);\n\n-- Optimized query\nSELECT s.*, COUNT(c.id) as message_count\nFROM sessions s\nLEFT JOIN conversations c ON s.id = c.session_id\nWHERE s.user_id = %s\nGROUP BY s.id\nORDER BY s.created_at DESC\nLIMIT 10;\n</code></pre></p>"},{"location":"implementation-notes/#2-ai-response-streaming","title":"2. AI Response Streaming","text":"<p>Optimization: Stream AI responses instead of waiting for complete response.</p> <p>Implementation: <pre><code>def stream_response(self, prompt: str):\n    for chunk in self.llm.stream(prompt):\n        yield chunk.content\n</code></pre></p> <p>Benefits: - Faster perceived performance - Better user experience - Can display partial responses</p>"},{"location":"implementation-notes/#3-file-upload-optimization","title":"3. File Upload Optimization","text":"<p>Optimizations: - Chunked file uploads for large files - Client-side file validation - Async file processing - Progress indicators</p>"},{"location":"implementation-notes/#security-considerations","title":"Security Considerations","text":""},{"location":"implementation-notes/#1-api-key-management","title":"1. API Key Management","text":"<p>Implementation: - Store API keys in environment variables - Never log API keys - Use separate keys for dev/prod - Implement key rotation</p>"},{"location":"implementation-notes/#2-input-validation","title":"2. Input Validation","text":"<p>Implementation: - Validate all user inputs - Sanitize file uploads - Limit file sizes - Check file types</p> <p>Example: <pre><code>def validate_resume_upload(file: UploadedFile) -&gt; None:\n    # Check file size\n    if file.size &gt; 10 * 1024 * 1024:  # 10MB\n        raise ValueError(\"File too large\")\n\n    # Check file type\n    if file.type not in [\"application/pdf\", \"text/plain\"]:\n        raise ValueError(\"Invalid file type\")\n\n    # Scan for malicious content\n    if contains_malicious_content(file):\n        raise ValueError(\"File contains malicious content\")\n</code></pre></p>"},{"location":"implementation-notes/#3-sql-injection-prevention","title":"3. SQL Injection Prevention","text":"<p>Implementation: - Use parameterized queries - Never concatenate SQL strings - Use ORM where appropriate</p> <p>Example: <pre><code># Good: Parameterized query\ncursor.execute(\n    \"SELECT * FROM sessions WHERE id = %s\",\n    (session_id,)\n)\n\n# Bad: String concatenation\ncursor.execute(\n    f\"SELECT * FROM sessions WHERE id = '{session_id}'\"\n)\n</code></pre></p>"},{"location":"implementation-notes/#testing-strategies","title":"Testing Strategies","text":""},{"location":"implementation-notes/#1-unit-testing","title":"1. Unit Testing","text":"<p>Approach: - Test each component in isolation - Use mocks for dependencies - Aim for 80%+ coverage</p> <p>Example: <pre><code>def test_create_session():\n    # Arrange\n    mock_data_store = Mock(spec=DataStore)\n    session_manager = SessionManager(data_store=mock_data_store)\n\n    # Act\n    session = session_manager.create_session(config)\n\n    # Assert\n    assert session.id is not None\n    mock_data_store.save_session.assert_called_once()\n</code></pre></p>"},{"location":"implementation-notes/#2-integration-testing","title":"2. Integration Testing","text":"<p>Approach: - Test complete workflows - Use test database - Clean up after tests</p> <p>Example: <pre><code>@pytest.mark.integration\ndef test_complete_interview_workflow(test_database):\n    # Create session\n    session = create_test_session()\n\n    # Start interview\n    start_session(session.id)\n\n    # Process responses\n    process_response(session.id, \"response\")\n\n    # End session\n    evaluation = end_session(session.id)\n\n    # Verify\n    assert evaluation.overall_score &gt; 0\n</code></pre></p>"},{"location":"implementation-notes/#3-end-to-end-testing","title":"3. End-to-End Testing","text":"<p>Approach: - Test through UI - Use Selenium or Playwright - Test critical user flows</p>"},{"location":"implementation-notes/#future-improvements","title":"Future Improvements","text":""},{"location":"implementation-notes/#1-cloud-migration","title":"1. Cloud Migration","text":"<p>Plan: - Migrate PostgreSQL to AWS RDS - Migrate file storage to S3 - Add Redis for caching - Implement CDN for media delivery</p>"},{"location":"implementation-notes/#2-multi-user-support","title":"2. Multi-User Support","text":"<p>Plan: - Add authentication system - Implement user management - Add role-based access control - Support team accounts</p>"},{"location":"implementation-notes/#3-advanced-features","title":"3. Advanced Features","text":"<p>Plan: - Multiple interview types (coding, behavioral) - Real-time collaboration - Analytics dashboard - Mobile app support</p>"},{"location":"implementation-notes/#4-performance-enhancements","title":"4. Performance Enhancements","text":"<p>Plan: - Implement async/await throughout - Add background job processing - Optimize database queries further - Implement advanced caching</p>"},{"location":"implementation-notes/#lessons-learned","title":"Lessons Learned","text":""},{"location":"implementation-notes/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with the simplest solution that works, then optimize based on real needs.</p>"},{"location":"implementation-notes/#2-test-early","title":"2. Test Early","text":"<p>Write tests from the beginning. It's much harder to add tests later.</p>"},{"location":"implementation-notes/#3-document-decisions","title":"3. Document Decisions","text":"<p>Document why decisions were made, not just what was implemented.</p>"},{"location":"implementation-notes/#4-plan-for-change","title":"4. Plan for Change","text":"<p>Design for extensibility. Requirements will change.</p>"},{"location":"implementation-notes/#5-user-feedback","title":"5. User Feedback","text":"<p>Get user feedback early and often. Build what users actually need.</p>"},{"location":"implementation-notes/#references","title":"References","text":"<ul> <li>Architecture Documentation</li> <li>API Reference</li> <li>Developer Setup</li> <li>Contributing Guide</li> </ul> <p>Last updated: 2024-01-15</p>"},{"location":"quick-start/","title":"Quick Start Guide","text":"<p>Welcome! This guide will help you set up and start using the AI Mock Interview Platform in just a few simple steps. No technical experience required!</p>"},{"location":"quick-start/#what-youll-need","title":"What You'll Need","text":"<p>Before you begin, make sure you have:</p> <ul> <li>A computer running Windows, macOS, or Linux</li> <li>An internet connection</li> <li>An OpenAI API key (we'll show you how to get one)</li> <li>About 15-20 minutes for setup</li> </ul>"},{"location":"quick-start/#step-1-install-docker-desktop","title":"Step 1: Install Docker Desktop","text":"<p>Estimated Time: 5-10 minutes</p> <p>Docker Desktop lets you run the interview platform on your computer without complicated setup.</p>"},{"location":"quick-start/#for-windows","title":"For Windows","text":"<ol> <li>Visit https://www.docker.com/products/docker-desktop</li> <li>Click \"Download for Windows\"</li> <li>Run the installer file you downloaded</li> <li>Follow the installation wizard (keep all default settings)</li> <li>Restart your computer when prompted</li> <li>Open Docker Desktop from your Start menu</li> <li>Wait for Docker Desktop to start (you'll see a whale icon in your system tray)</li> </ol>"},{"location":"quick-start/#for-macos","title":"For macOS","text":"<ol> <li>Visit https://www.docker.com/products/docker-desktop</li> <li>Click \"Download for Mac\" (choose Intel or Apple Silicon based on your Mac)</li> <li>Open the downloaded .dmg file</li> <li>Drag Docker to your Applications folder</li> <li>Open Docker from Applications</li> <li>Click \"Open\" when macOS asks for permission</li> <li>Wait for Docker Desktop to start (you'll see a whale icon in your menu bar)</li> </ol>"},{"location":"quick-start/#for-linux","title":"For Linux","text":"<ol> <li>Visit https://docs.docker.com/desktop/install/linux-install/</li> <li>Follow the instructions for your Linux distribution</li> <li>Start Docker Desktop after installation</li> </ol> <p>How to verify Docker is working:</p> <ul> <li>Look for the Docker whale icon in your system tray (Windows) or menu bar (macOS)</li> <li>The icon should be steady, not animated</li> <li>If you see the whale icon, Docker is ready!</li> </ul>"},{"location":"quick-start/#step-2-get-your-openai-api-key","title":"Step 2: Get Your OpenAI API Key","text":"<p>Estimated Time: 3-5 minutes</p> <p>The AI interviewer uses OpenAI's technology to conduct interviews. You'll need an API key to use it.</p> <ol> <li>Go to https://platform.openai.com/signup</li> <li>Create an account or sign in if you already have one</li> <li>Click on your profile icon in the top-right corner</li> <li>Select \"View API keys\" from the menu</li> <li>Click \"Create new secret key\"</li> <li>Give it a name like \"Interview Platform\"</li> <li>IMPORTANT: Copy the key that appears (it starts with \"sk-\")</li> <li>Save this key somewhere safe - you won't be able to see it again!</li> </ol> <p>Cost Information:</p> <ul> <li>OpenAI charges based on usage (typically $0.50-$2.00 per interview)</li> <li>You'll need to add a payment method to your OpenAI account</li> <li>You can set spending limits in your OpenAI account settings</li> </ul>"},{"location":"quick-start/#step-3-download-the-interview-platform","title":"Step 3: Download the Interview Platform","text":"<p>Estimated Time: 2 minutes</p> <ol> <li>Download the platform from [GitHub Release Link]</li> <li>Extract the ZIP file to a location you'll remember (like your Documents folder)</li> <li>You should now have a folder called \"ai-mock-interview-platform\"</li> </ol>"},{"location":"quick-start/#step-4-configure-your-settings","title":"Step 4: Configure Your Settings","text":"<p>Estimated Time: 2 minutes</p> <ol> <li>Open the \"ai-mock-interview-platform\" folder</li> <li>Find the file named <code>.env.template</code></li> <li>Make a copy of this file and rename it to <code>.env</code> (remove the \".template\" part)</li> <li>Open the <code>.env</code> file with Notepad (Windows) or TextEdit (macOS)</li> <li>Replace the placeholder values with your actual configuration</li> </ol> <p>Example: <pre><code>DB_PASSWORD=MySecurePassword123\nOPENAI_API_KEY=sk-proj-abc123xyz789...\n</code></pre></p>"},{"location":"quick-start/#step-5-start-the-platform","title":"Step 5: Start the Platform","text":"<p>Estimated Time: 2-3 minutes</p>"},{"location":"quick-start/#for-windows_1","title":"For Windows","text":"<p>Open Command Prompt in the platform folder and run: <pre><code>startup.sh\n</code></pre></p>"},{"location":"quick-start/#for-macoslinux","title":"For macOS/Linux","text":"<p>Open Terminal, navigate to the platform folder, and run: <pre><code>chmod +x startup.sh\n./startup.sh\n</code></pre></p>"},{"location":"quick-start/#step-6-open-the-interview-platform","title":"Step 6: Open the Interview Platform","text":"<ol> <li>Open your web browser (Chrome, Firefox, Safari, or Edge)</li> <li>Go to: <code>http://localhost:8501</code></li> <li>You should see the AI Mock Interview Platform welcome screen!</li> </ol>"},{"location":"quick-start/#using-the-platform","title":"Using the Platform","text":""},{"location":"quick-start/#starting-your-first-interview","title":"Starting Your First Interview","text":"<ol> <li>Upload Your Resume - The AI will analyze your experience level</li> <li>Choose Your AI Provider - Select OpenAI GPT-4 (recommended)</li> <li>Select Communication Modes - Enable audio, video, whiteboard as needed</li> <li>Click \"Start Interview\" - The AI interviewer will present a problem</li> </ol>"},{"location":"quick-start/#during-the-interview","title":"During the Interview","text":"<ul> <li>Left Panel: Chat with the AI interviewer</li> <li>Center Panel: Whiteboard for drawing system diagrams</li> <li>Right Panel: Live transcript</li> <li>Bottom Bar: Recording controls</li> </ul>"},{"location":"quick-start/#ending-the-interview","title":"Ending the Interview","text":"<ol> <li>Click the \"End Interview\" button</li> <li>Wait for the AI to generate your feedback</li> <li>Review your evaluation report</li> </ol>"},{"location":"quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"quick-start/#docker-is-not-running","title":"Docker is not running","text":"<p>Solution: Open Docker Desktop and wait for it to fully start</p>"},{"location":"quick-start/#port-8501-is-already-in-use","title":"Port 8501 is already in use","text":"<p>Solution: Close other applications using that port or restart your computer</p>"},{"location":"quick-start/#invalid-api-key","title":"Invalid API key","text":"<p>Solution: Verify your OpenAI API key is correct in the <code>.env</code> file</p>"},{"location":"quick-start/#cannot-connect-to-database","title":"Cannot connect to database","text":"<p>Solution: Wait 30 seconds for the database to start, or run <code>docker-compose down</code> then <code>./startup.sh</code> again</p>"},{"location":"quick-start/#whats-next","title":"What's Next?","text":"<ul> <li>Practice regularly (at least one interview per week)</li> <li>Track your progress in the History section</li> <li>Focus on areas identified in your improvement plans</li> <li>Experiment with different communication modes</li> </ul> <p>For more detailed information, see the Developer Setup Guide.</p> <p>Congratulations! You're now ready to practice system design interviews with AI. Good luck! \ud83d\ude80</p>"},{"location":"api/","title":"API Reference","text":"<p>This section provides detailed API documentation for all major components of the AI Mock Interview Platform.</p>"},{"location":"api/#core-components","title":"Core Components","text":""},{"location":"api/#session-manager","title":"Session Manager","text":"<p>The central orchestrator for interview sessions.</p> <p>View Session Manager API \u2192</p>"},{"location":"api/#ai-interviewer","title":"AI Interviewer","text":"<p>LLM-powered interview question generation and response analysis.</p> <p>View AI Interviewer API \u2192</p>"},{"location":"api/#communication-manager","title":"Communication Manager","text":"<p>Multi-modal communication handling (audio, video, whiteboard, screen share).</p> <p>View Communication Manager API \u2192</p>"},{"location":"api/#evaluation-manager","title":"Evaluation Manager","text":"<p>Interview performance analysis and feedback generation.</p> <p>View Evaluation Manager API \u2192</p>"},{"location":"api/#resume-manager","title":"Resume Manager","text":"<p>Resume parsing and analysis for personalized interviews.</p> <p>View Resume Manager API \u2192</p>"},{"location":"api/#infrastructure-components","title":"Infrastructure Components","text":""},{"location":"api/#data-store","title":"Data Store","text":"<p>PostgreSQL-based data persistence layer.</p> <p>View Data Store API \u2192</p>"},{"location":"api/#file-storage","title":"File Storage","text":"<p>Local filesystem storage for media files.</p> <p>View File Storage API \u2192</p>"},{"location":"api/#logging-manager","title":"Logging Manager","text":"<p>Comprehensive logging system with multiple outputs.</p> <p>View Logging Manager API \u2192</p>"},{"location":"api/#data-models","title":"Data Models","text":""},{"location":"api/#session","title":"Session","text":"<pre><code>@dataclass\nclass Session:\n    id: str\n    user_id: str\n    status: SessionStatus\n    config: SessionConfig\n    created_at: datetime\n    started_at: Optional[datetime]\n    ended_at: Optional[datetime]\n</code></pre>"},{"location":"api/#sessionconfig","title":"SessionConfig","text":"<pre><code>@dataclass\nclass SessionConfig:\n    enabled_modes: List[CommunicationMode]\n    ai_provider: str\n    ai_model: str\n    max_tokens: int\n    token_warning_threshold: float\n</code></pre>"},{"location":"api/#evaluation","title":"Evaluation","text":"<pre><code>@dataclass\nclass Evaluation:\n    session_id: str\n    overall_score: float\n    competency_scores: Dict[str, float]\n    strengths: List[str]\n    areas_for_improvement: List[str]\n    improvement_plan: ImprovementPlan\n    detailed_feedback: str\n    created_at: datetime\n</code></pre>"},{"location":"api/#enumerations","title":"Enumerations","text":""},{"location":"api/#sessionstatus","title":"SessionStatus","text":"<pre><code>class SessionStatus(Enum):\n    CREATED = \"created\"\n    ACTIVE = \"active\"\n    PAUSED = \"paused\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n</code></pre>"},{"location":"api/#communicationmode","title":"CommunicationMode","text":"<pre><code>class CommunicationMode(Enum):\n    TEXT = \"text\"\n    AUDIO = \"audio\"\n    VIDEO = \"video\"\n    WHITEBOARD = \"whiteboard\"\n    SCREEN_SHARE = \"screen_share\"\n</code></pre>"},{"location":"api/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>InterviewPlatformError\n\u251c\u2500\u2500 ConfigurationError\n\u251c\u2500\u2500 SessionError\n\u2502   \u251c\u2500\u2500 SessionNotFoundError\n\u2502   \u251c\u2500\u2500 InvalidStateError\n\u2502   \u2514\u2500\u2500 SessionExpiredError\n\u251c\u2500\u2500 DataStoreError\n\u2502   \u251c\u2500\u2500 DatabaseError\n\u2502   \u2514\u2500\u2500 ConnectionError\n\u251c\u2500\u2500 AIProviderError\n\u2502   \u251c\u2500\u2500 TokenLimitError\n\u2502   \u2514\u2500\u2500 APIError\n\u2514\u2500\u2500 CommunicationError\n    \u251c\u2500\u2500 AudioError\n    \u251c\u2500\u2500 VideoError\n    \u2514\u2500\u2500 WhiteboardError\n</code></pre>"},{"location":"api/#usage-examples","title":"Usage Examples","text":""},{"location":"api/#creating-a-session","title":"Creating a Session","text":"<pre><code>from src.session import SessionManager\nfrom src.models import SessionConfig, CommunicationMode\n\n# Create session manager\nsession_manager = SessionManager(\n    data_store=data_store,\n    ai_interviewer=ai_interviewer,\n    evaluation_manager=evaluation_manager,\n    communication_manager=communication_manager,\n    logger=logger\n)\n\n# Configure session\nconfig = SessionConfig(\n    enabled_modes=[CommunicationMode.TEXT, CommunicationMode.WHITEBOARD],\n    ai_provider=\"openai\",\n    ai_model=\"gpt-4\",\n    max_tokens=50000,\n    token_warning_threshold=0.8\n)\n\n# Create session\nsession = session_manager.create_session(config)\nprint(f\"Session created: {session.id}\")\n</code></pre>"},{"location":"api/#processing-responses","title":"Processing Responses","text":"<pre><code>from src.ai import AIInterviewer\n\n# Initialize AI interviewer\nai_interviewer = AIInterviewer(\n    provider=openai_provider,\n    token_tracker=token_tracker,\n    logger=logger\n)\n\n# Process response\nresponse = ai_interviewer.process_response(\n    session_id=session.id,\n    response=\"I would design a distributed system with...\",\n    whiteboard_image=snapshot_bytes\n)\n\nprint(f\"AI: {response.message}\")\nprint(f\"Tokens used: {response.tokens_used}\")\n</code></pre>"},{"location":"api/#generating-evaluation","title":"Generating Evaluation","text":"<pre><code>from src.evaluation import EvaluationManager\n\n# Initialize evaluation manager\nevaluation_manager = EvaluationManager(\n    data_store=data_store,\n    logger=logger\n)\n\n# Generate evaluation\nevaluation = evaluation_manager.evaluate_session(session.id)\n\nprint(f\"Overall Score: {evaluation.overall_score}/10\")\nfor competency, score in evaluation.competency_scores.items():\n    print(f\"{competency}: {score}/10\")\n</code></pre>"},{"location":"api/#type-definitions","title":"Type Definitions","text":"<p>For complete type definitions, see the models module.</p>"},{"location":"api/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>Developer Setup</li> <li>Contributing Guide</li> </ul>"},{"location":"components/ai-interviewer/","title":"AI Interviewer","text":"<p>The AI Interviewer component generates interview questions and analyzes candidate responses using Large Language Models (LLMs).</p>"},{"location":"components/ai-interviewer/#overview","title":"Overview","text":"<p>Powered by OpenAI GPT-4 or Anthropic Claude, the AI Interviewer:</p> <ul> <li>Generates initial interview problems based on resume</li> <li>Analyzes candidate responses</li> <li>Generates contextual follow-up questions</li> <li>Maintains conversation history</li> <li>Tracks token usage</li> </ul>"},{"location":"components/ai-interviewer/#key-features","title":"Key Features","text":""},{"location":"components/ai-interviewer/#resume-aware-problem-generation","title":"Resume-Aware Problem Generation","text":"<p>The AI analyzes the candidate's resume to generate appropriate problems:</p> <pre><code>def generate_initial_problem(self, resume_data: ResumeData) -&gt; str:\n    \"\"\"Generate interview problem based on resume.\n\n    Considers:\n    - Experience level (junior, mid, senior, staff)\n    - Domain expertise (e.g., e-commerce, fintech, social media)\n    - Technical skills\n    - Past projects\n    \"\"\"\n</code></pre>"},{"location":"components/ai-interviewer/#context-aware-response-analysis","title":"Context-Aware Response Analysis","text":"<p>The AI maintains full conversation context including:</p> <ul> <li>Previous questions and answers</li> <li>Whiteboard snapshots</li> <li>Clarifying questions asked</li> <li>Discussion depth</li> </ul>"},{"location":"components/ai-interviewer/#multi-provider-support","title":"Multi-Provider Support","text":"<p>Supports multiple LLM providers through LangChain:</p> <ul> <li>OpenAI GPT-4 (default)</li> <li>Anthropic Claude</li> <li>Easy to add new providers</li> </ul>"},{"location":"components/ai-interviewer/#usage-example","title":"Usage Example","text":"<pre><code># Initialize AI Interviewer\nai_interviewer = AIInterviewer(\n    provider=OpenAIProvider(api_key=config.openai_api_key),\n    token_tracker=TokenTracker(),\n    logger=logging_manager\n)\n\n# Generate initial problem\nproblem = ai_interviewer.generate_initial_problem(resume_data)\n\n# Process candidate response\nresponse = ai_interviewer.process_response(\n    session_id=session.id,\n    response=\"I would design a distributed system with...\",\n    whiteboard_image=snapshot_bytes\n)\n</code></pre>"},{"location":"components/ai-interviewer/#token-tracking","title":"Token Tracking","text":"<p>The AI Interviewer tracks token usage for cost monitoring:</p> <ul> <li>Input tokens</li> <li>Output tokens</li> <li>Total cost</li> <li>Budget warnings</li> </ul> <p>See Token Tracking for details.</p>"},{"location":"components/ai-interviewer/#related-components","title":"Related Components","text":"<ul> <li>Session Manager</li> <li>Evaluation Manager</li> <li>Token Tracking</li> </ul>"},{"location":"components/communication-manager/","title":"Communication Manager","text":"<p>The Communication Manager handles multi-modal communication during interviews, including audio, video, whiteboard, and screen sharing.</p>"},{"location":"components/communication-manager/#overview","title":"Overview","text":"<p>The Communication Manager:</p> <ul> <li>Enables/disables communication modes</li> <li>Coordinates mode-specific handlers</li> <li>Stores media files</li> <li>Manages transcription</li> </ul>"},{"location":"components/communication-manager/#supported-modes","title":"Supported Modes","text":""},{"location":"components/communication-manager/#audio","title":"Audio","text":"<ul> <li>Records audio using WebRTC</li> <li>Transcribes with OpenAI Whisper</li> <li>Stores audio files locally</li> </ul>"},{"location":"components/communication-manager/#video","title":"Video","text":"<ul> <li>Records video streams</li> <li>Stores video files locally</li> <li>Optional: Extract frames for analysis</li> </ul>"},{"location":"components/communication-manager/#whiteboard","title":"Whiteboard","text":"<ul> <li>Captures canvas snapshots</li> <li>Stores images with timestamps</li> <li>Includes in AI context</li> </ul>"},{"location":"components/communication-manager/#screen-share","title":"Screen Share","text":"<ul> <li>Captures screen recordings</li> <li>Stores screen captures</li> <li>Optional: OCR for text extraction</li> </ul>"},{"location":"components/communication-manager/#architecture","title":"Architecture","text":"<pre><code>class CommunicationManager:\n    def __init__(\n        self,\n        file_storage: FileStorage,\n        data_store: DataStore,\n        logger: LoggingManager\n    ):\n        self.audio_handler = AudioHandler(file_storage, logger)\n        self.video_handler = VideoHandler(file_storage, logger)\n        self.whiteboard_handler = WhiteboardHandler(file_storage, logger)\n        self.screen_handler = ScreenHandler(file_storage, logger)\n</code></pre>"},{"location":"components/communication-manager/#usage-example","title":"Usage Example","text":"<pre><code># Enable modes\ncommunication_manager.enable_mode(session_id, CommunicationMode.AUDIO)\ncommunication_manager.enable_mode(session_id, CommunicationMode.WHITEBOARD)\n\n# Save audio\naudio_path = communication_manager.save_audio(session_id, audio_bytes)\n\n# Save whiteboard snapshot\nsnapshot_path = communication_manager.save_whiteboard_snapshot(\n    session_id,\n    canvas_image_bytes\n)\n\n# Get transcript\ntranscript = communication_manager.get_transcript(session_id)\n</code></pre>"},{"location":"components/communication-manager/#file-storage","title":"File Storage","text":"<p>Media files are organized by session:</p> <pre><code>data/sessions/{session_id}/\n\u251c\u2500\u2500 audio/\n\u2502   \u251c\u2500\u2500 recording_001.wav\n\u2502   \u2514\u2500\u2500 recording_002.wav\n\u251c\u2500\u2500 video/\n\u2502   \u2514\u2500\u2500 interview.mp4\n\u251c\u2500\u2500 whiteboard/\n\u2502   \u251c\u2500\u2500 snapshot_001.png\n\u2502   \u2514\u2500\u2500 snapshot_002.png\n\u2514\u2500\u2500 screen/\n    \u2514\u2500\u2500 capture_001.png\n</code></pre>"},{"location":"components/communication-manager/#related-components","title":"Related Components","text":"<ul> <li>Session Manager</li> <li>File Storage</li> </ul>"},{"location":"components/evaluation-manager/","title":"Evaluation Manager","text":"<p>The Evaluation Manager analyzes interview performance and generates comprehensive feedback reports.</p>"},{"location":"components/evaluation-manager/#overview","title":"Overview","text":"<p>The Evaluation Manager:</p> <ul> <li>Analyzes conversation quality</li> <li>Evaluates system design approach</li> <li>Generates competency scores</li> <li>Creates personalized improvement plans</li> </ul>"},{"location":"components/evaluation-manager/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"components/evaluation-manager/#problem-understanding-0-10","title":"Problem Understanding (0-10)","text":"<ul> <li>Clarifying questions asked</li> <li>Requirements gathering</li> <li>Constraint identification</li> </ul>"},{"location":"components/evaluation-manager/#system-design-approach-0-10","title":"System Design Approach (0-10)","text":"<ul> <li>High-level architecture</li> <li>Component breakdown</li> <li>Data flow design</li> </ul>"},{"location":"components/evaluation-manager/#communication-clarity-0-10","title":"Communication Clarity (0-10)","text":"<ul> <li>Explanation quality</li> <li>Thought process articulation</li> <li>Whiteboard usage</li> </ul>"},{"location":"components/evaluation-manager/#technical-depth-0-10","title":"Technical Depth (0-10)","text":"<ul> <li>Technology choices</li> <li>Implementation details</li> <li>Edge case handling</li> </ul>"},{"location":"components/evaluation-manager/#trade-off-analysis-0-10","title":"Trade-off Analysis (0-10)","text":"<ul> <li>Alternative approaches considered</li> <li>Pros/cons discussed</li> <li>Justification quality</li> </ul>"},{"location":"components/evaluation-manager/#scalability-considerations-0-10","title":"Scalability Considerations (0-10)","text":"<ul> <li>Performance optimization</li> <li>Bottleneck identification</li> <li>Scaling strategies</li> </ul>"},{"location":"components/evaluation-manager/#evaluation-report","title":"Evaluation Report","text":"<pre><code>@dataclass\nclass Evaluation:\n    session_id: str\n    overall_score: float\n    competency_scores: Dict[str, float]\n    strengths: List[str]\n    areas_for_improvement: List[str]\n    improvement_plan: ImprovementPlan\n    detailed_feedback: str\n    created_at: datetime\n</code></pre>"},{"location":"components/evaluation-manager/#improvement-plan","title":"Improvement Plan","text":"<p>The improvement plan includes:</p> <ul> <li>Specific areas to focus on</li> <li>Concrete action steps</li> <li>Recommended resources</li> <li>Practice problems</li> </ul>"},{"location":"components/evaluation-manager/#usage-example","title":"Usage Example","text":"<pre><code># Generate evaluation\nevaluation = evaluation_manager.evaluate_session(session_id)\n\n# Access scores\nprint(f\"Overall: {evaluation.overall_score}/10\")\nfor competency, score in evaluation.competency_scores.items():\n    print(f\"{competency}: {score}/10\")\n\n# View improvement plan\nfor step in evaluation.improvement_plan.concrete_steps:\n    print(f\"- {step}\")\n</code></pre>"},{"location":"components/evaluation-manager/#related-components","title":"Related Components","text":"<ul> <li>Session Manager</li> <li>AI Interviewer</li> </ul>"},{"location":"components/resume-manager/","title":"Resume Manager","text":"<p>The Resume Manager handles resume upload, parsing, and analysis to generate personalized interview problems.</p>"},{"location":"components/resume-manager/#overview","title":"Overview","text":"<p>The Resume Manager:</p> <ul> <li>Accepts PDF and text resumes</li> <li>Extracts key information</li> <li>Analyzes experience level</li> <li>Identifies domain expertise</li> <li>Stores resume data</li> </ul>"},{"location":"components/resume-manager/#resume-analysis","title":"Resume Analysis","text":""},{"location":"components/resume-manager/#experience-level-detection","title":"Experience Level Detection","text":"<ul> <li>Junior (0-2 years)</li> <li>Mid-level (2-5 years)</li> <li>Senior (5-10 years)</li> <li>Staff+ (10+ years)</li> </ul>"},{"location":"components/resume-manager/#domain-expertise-extraction","title":"Domain Expertise Extraction","text":"<ul> <li>E-commerce</li> <li>Fintech</li> <li>Social media</li> <li>Healthcare</li> <li>Gaming</li> <li>Enterprise software</li> </ul>"},{"location":"components/resume-manager/#skills-identification","title":"Skills Identification","text":"<ul> <li>Programming languages</li> <li>Frameworks and tools</li> <li>Cloud platforms</li> <li>Databases</li> <li>System design patterns</li> </ul>"},{"location":"components/resume-manager/#usage-example","title":"Usage Example","text":"<pre><code># Upload and parse resume\nresume_data = resume_manager.parse_resume(\n    file_content=pdf_bytes,\n    file_type=\"pdf\"\n)\n\n# Access parsed data\nprint(f\"Experience: {resume_data.experience_level}\")\nprint(f\"Domains: {resume_data.domains}\")\nprint(f\"Skills: {resume_data.skills}\")\n</code></pre>"},{"location":"components/resume-manager/#related-components","title":"Related Components","text":"<ul> <li>Session Manager</li> <li>AI Interviewer</li> </ul>"},{"location":"components/session-manager/","title":"Session Manager","text":"<p>The Session Manager is the central orchestrator of the AI Mock Interview Platform, coordinating the interview lifecycle and managing interactions between all major components.</p>"},{"location":"components/session-manager/#overview","title":"Overview","text":"<p>The Session Manager handles:</p> <ul> <li>Creating and configuring interview sessions</li> <li>Starting and ending sessions</li> <li>Managing session state transitions</li> <li>Coordinating between AI Interviewer, Communication Manager, and Evaluation Manager</li> <li>Persisting session data</li> </ul>"},{"location":"components/session-manager/#architecture","title":"Architecture","text":"<pre><code>class SessionManager:\n    def __init__(\n        self,\n        data_store: DataStore,\n        ai_interviewer: AIInterviewer,\n        evaluation_manager: EvaluationManager,\n        communication_manager: CommunicationManager,\n        logger: LoggingManager\n    ):\n        self.data_store = data_store\n        self.ai_interviewer = ai_interviewer\n        self.evaluation_manager = evaluation_manager\n        self.communication_manager = communication_manager\n        self.logger = logger\n</code></pre>"},{"location":"components/session-manager/#key-methods","title":"Key Methods","text":""},{"location":"components/session-manager/#create_session","title":"create_session","text":"<p>Creates a new interview session with the specified configuration.</p> <pre><code>def create_session(self, config: SessionConfig) -&gt; Session:\n    \"\"\"Create a new interview session.\n\n    Args:\n        config: Session configuration including enabled modes and AI provider\n\n    Returns:\n        Created session with unique identifier\n\n    Raises:\n        ConfigurationError: If configuration is invalid\n        DataStoreError: If database operation fails\n    \"\"\"\n</code></pre>"},{"location":"components/session-manager/#start_session","title":"start_session","text":"<p>Starts an interview session and enables communication modes.</p> <pre><code>def start_session(self, session_id: str) -&gt; None:\n    \"\"\"Start an interview session.\n\n    Args:\n        session_id: Unique session identifier\n\n    Raises:\n        SessionNotFoundError: If session doesn't exist\n        InvalidStateError: If session is not in CREATED state\n    \"\"\"\n</code></pre>"},{"location":"components/session-manager/#end_session","title":"end_session","text":"<p>Ends an interview session and generates evaluation.</p> <pre><code>def end_session(self, session_id: str) -&gt; Evaluation:\n    \"\"\"End session and generate evaluation.\n\n    Args:\n        session_id: Unique session identifier\n\n    Returns:\n        Evaluation report with scores and feedback\n\n    Raises:\n        SessionNotFoundError: If session doesn't exist\n        InvalidStateError: If session is not in ACTIVE state\n    \"\"\"\n</code></pre>"},{"location":"components/session-manager/#state-machine","title":"State Machine","text":"<p>Sessions progress through the following states:</p> <pre><code>[CREATED] \u2192 start_session() \u2192 [ACTIVE]\n[ACTIVE] \u2192 end_session() \u2192 [COMPLETED]\n[ACTIVE] \u2192 pause_session() \u2192 [PAUSED]\n[PAUSED] \u2192 resume_session() \u2192 [ACTIVE]\n</code></pre>"},{"location":"components/session-manager/#usage-example","title":"Usage Example","text":"<pre><code># Create session manager with dependencies\nsession_manager = SessionManager(\n    data_store=postgres_data_store,\n    ai_interviewer=ai_interviewer,\n    evaluation_manager=evaluation_manager,\n    communication_manager=communication_manager,\n    logger=logging_manager\n)\n\n# Create new session\nconfig = SessionConfig(\n    enabled_modes=[CommunicationMode.TEXT, CommunicationMode.WHITEBOARD],\n    ai_provider=\"openai\",\n    ai_model=\"gpt-4\"\n)\nsession = session_manager.create_session(config)\n\n# Start session\nsession_manager.start_session(session.id)\n\n# ... interview interaction ...\n\n# End session and get evaluation\nevaluation = session_manager.end_session(session.id)\n</code></pre>"},{"location":"components/session-manager/#error-handling","title":"Error Handling","text":"<p>The Session Manager handles various error scenarios:</p> <ul> <li>Configuration errors: Invalid session configuration</li> <li>State errors: Invalid state transitions</li> <li>Database errors: Data persistence failures</li> <li>Component errors: Failures in dependent components</li> </ul> <p>All errors are logged with full context for debugging.</p>"},{"location":"components/session-manager/#testing","title":"Testing","text":"<p>The Session Manager is designed for testability with dependency injection:</p> <pre><code>def test_create_session():\n    # Arrange\n    mock_data_store = Mock(spec=DataStore)\n    mock_ai_interviewer = Mock(spec=AIInterviewer)\n    session_manager = SessionManager(\n        data_store=mock_data_store,\n        ai_interviewer=mock_ai_interviewer,\n        # ... other mocks\n    )\n\n    # Act\n    session = session_manager.create_session(config)\n\n    # Assert\n    assert session.id is not None\n    mock_data_store.save_session.assert_called_once()\n</code></pre>"},{"location":"components/session-manager/#related-components","title":"Related Components","text":"<ul> <li>AI Interviewer</li> <li>Communication Manager</li> <li>Evaluation Manager</li> </ul>"},{"location":"features/evaluation-quick-start/","title":"Evaluation Quick Start","text":"<p>Get started with the evaluation system to understand your interview performance.</p>"},{"location":"features/evaluation-quick-start/#understanding-your-evaluation","title":"Understanding Your Evaluation","text":"<p>After completing an interview, you'll receive a comprehensive evaluation report with:</p>"},{"location":"features/evaluation-quick-start/#overall-score","title":"Overall Score","text":"<p>A score from 0-10 representing your overall performance.</p> <ul> <li>0-4: Needs significant improvement</li> <li>5-6: Below average, focus on fundamentals</li> <li>7-8: Good performance, minor improvements needed</li> <li>9-10: Excellent performance</li> </ul>"},{"location":"features/evaluation-quick-start/#competency-scores","title":"Competency Scores","text":"<p>Individual scores for each evaluation criterion:</p> <ul> <li>Problem Understanding</li> <li>System Design Approach</li> <li>Communication Clarity</li> <li>Technical Depth</li> <li>Trade-off Analysis</li> <li>Scalability Considerations</li> </ul>"},{"location":"features/evaluation-quick-start/#strengths","title":"Strengths","text":"<p>What you did well during the interview:</p> <ul> <li>\"Asked excellent clarifying questions about scale\"</li> <li>\"Clearly explained trade-offs between SQL and NoSQL\"</li> <li>\"Effectively used whiteboard to illustrate architecture\"</li> </ul>"},{"location":"features/evaluation-quick-start/#areas-for-improvement","title":"Areas for Improvement","text":"<p>What needs work:</p> <ul> <li>\"Consider discussing data consistency models\"</li> <li>\"Explore caching strategies in more depth\"</li> <li>\"Address monitoring and observability\"</li> </ul>"},{"location":"features/evaluation-quick-start/#improvement-plan","title":"Improvement Plan","text":"<p>Concrete steps to improve:</p> <ol> <li>Study CAP theorem and consistency models</li> <li>Practice designing caching layers</li> <li>Learn about distributed tracing tools</li> <li>Review 3 system design case studies</li> </ol>"},{"location":"features/evaluation-quick-start/#using-your-evaluation","title":"Using Your Evaluation","text":""},{"location":"features/evaluation-quick-start/#1-review-immediately","title":"1. Review Immediately","text":"<p>Read your evaluation right after the interview while it's fresh.</p>"},{"location":"features/evaluation-quick-start/#2-focus-on-patterns","title":"2. Focus on Patterns","text":"<p>After multiple interviews, look for recurring themes in areas for improvement.</p>"},{"location":"features/evaluation-quick-start/#3-follow-the-plan","title":"3. Follow the Plan","text":"<p>Work through the improvement plan steps before your next interview.</p>"},{"location":"features/evaluation-quick-start/#4-track-progress","title":"4. Track Progress","text":"<p>Compare scores across interviews to see improvement over time.</p>"},{"location":"features/evaluation-quick-start/#evaluation-metrics","title":"Evaluation Metrics","text":""},{"location":"features/evaluation-quick-start/#problem-understanding-0-10","title":"Problem Understanding (0-10)","text":"<p>Measures how well you: - Asked clarifying questions - Identified requirements - Understood constraints</p>"},{"location":"features/evaluation-quick-start/#system-design-approach-0-10","title":"System Design Approach (0-10)","text":"<p>Measures your: - High-level architecture - Component breakdown - Data flow design</p>"},{"location":"features/evaluation-quick-start/#communication-clarity-0-10","title":"Communication Clarity (0-10)","text":"<p>Measures your ability to: - Explain clearly - Articulate thought process - Use visual aids effectively</p>"},{"location":"features/evaluation-quick-start/#technical-depth-0-10","title":"Technical Depth (0-10)","text":"<p>Measures your: - Technology choices - Implementation details - Edge case handling</p>"},{"location":"features/evaluation-quick-start/#trade-off-analysis-0-10","title":"Trade-off Analysis (0-10)","text":"<p>Measures your: - Alternative approaches - Pros/cons discussion - Decision justification</p>"},{"location":"features/evaluation-quick-start/#scalability-considerations-0-10","title":"Scalability Considerations (0-10)","text":"<p>Measures your: - Performance optimization - Bottleneck identification - Scaling strategies</p>"},{"location":"features/evaluation-quick-start/#tips-for-better-scores","title":"Tips for Better Scores","text":""},{"location":"features/evaluation-quick-start/#ask-questions","title":"Ask Questions","text":"<p>Always start by asking clarifying questions about: - Scale (users, requests, data) - Latency requirements - Consistency requirements - Budget constraints</p>"},{"location":"features/evaluation-quick-start/#think-out-loud","title":"Think Out Loud","text":"<p>Explain your reasoning as you design: - \"I'm choosing PostgreSQL because...\" - \"This could be a bottleneck, so...\" - \"An alternative would be...\"</p>"},{"location":"features/evaluation-quick-start/#use-the-whiteboard","title":"Use the Whiteboard","text":"<p>Draw diagrams to illustrate: - System architecture - Data flow - Component interactions</p>"},{"location":"features/evaluation-quick-start/#discuss-trade-offs","title":"Discuss Trade-offs","text":"<p>For every decision, mention: - Why you chose this approach - What alternatives exist - Pros and cons of each</p>"},{"location":"features/evaluation-quick-start/#consider-scale","title":"Consider Scale","text":"<p>Always address: - How the system handles growth - Where bottlenecks might occur - How to scale each component</p>"},{"location":"features/evaluation-quick-start/#related-pages","title":"Related Pages","text":"<ul> <li>Evaluation Manager</li> <li>Interview UI</li> </ul>"},{"location":"features/logging/","title":"Logging System","text":"<p>The platform includes a comprehensive logging system for debugging, monitoring, and audit trails.</p>"},{"location":"features/logging/#overview","title":"Overview","text":"<p>The logging system provides:</p> <ul> <li>Multiple output destinations (console, file, database)</li> <li>Structured JSON format</li> <li>Context-aware logging</li> <li>Error tracking with stack traces</li> </ul>"},{"location":"features/logging/#log-levels","title":"Log Levels","text":"<ul> <li>DEBUG: Detailed diagnostic information</li> <li>INFO: General informational messages</li> <li>WARNING: Warning messages for potential issues</li> <li>ERROR: Error messages for failures</li> <li>CRITICAL: Critical errors requiring immediate attention</li> </ul>"},{"location":"features/logging/#log-destinations","title":"Log Destinations","text":""},{"location":"features/logging/#console-logging","title":"Console Logging","text":"<p>Human-readable format for development:</p> <pre><code>2024-01-15 10:30:45 [INFO] session_manager: Session created (session_id=abc123)\n</code></pre>"},{"location":"features/logging/#file-logging","title":"File Logging","text":"<p>Rotating file logs in <code>logs/interview_platform.log</code>:</p> <ul> <li>Max size: 10MB per file</li> <li>Keeps 5 backup files</li> <li>JSON format for parsing</li> </ul>"},{"location":"features/logging/#database-logging","title":"Database Logging","text":"<p>Stored in <code>audit_logs</code> table for querying:</p> <pre><code>SELECT * FROM audit_logs \nWHERE session_id = 'abc123' \nORDER BY timestamp DESC;\n</code></pre>"},{"location":"features/logging/#structured-logging","title":"Structured Logging","text":"<p>All logs include:</p> <ul> <li>Timestamp</li> <li>Level</li> <li>Component</li> <li>Operation</li> <li>Message</li> <li>Session ID (when available)</li> <li>User ID (when available)</li> <li>Metadata (custom fields)</li> </ul> <p>Example JSON log:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"component\": \"session_manager\",\n  \"operation\": \"create_session\",\n  \"message\": \"Session created successfully\",\n  \"session_id\": \"abc123\",\n  \"metadata\": {\n    \"enabled_modes\": [\"text\", \"whiteboard\"],\n    \"ai_provider\": \"openai\"\n  }\n}\n</code></pre>"},{"location":"features/logging/#usage","title":"Usage","text":"<pre><code># Log operation\nlogger.log_operation(\n    level=\"INFO\",\n    component=\"session_manager\",\n    operation=\"create_session\",\n    message=\"Session created successfully\",\n    session_id=session.id,\n    metadata={\"enabled_modes\": config.enabled_modes}\n)\n\n# Log error\ntry:\n    result = risky_operation()\nexcept Exception as e:\n    logger.log_error(\n        component=\"session_manager\",\n        operation=\"create_session\",\n        error=e,\n        session_id=session.id\n    )\n</code></pre>"},{"location":"features/logging/#configuration","title":"Configuration","text":"<p>Configure logging in <code>config.yaml</code>:</p> <pre><code>logging:\n  level: INFO\n  console:\n    enabled: true\n    format: human\n  file:\n    enabled: true\n    path: logs/interview_platform.log\n    max_bytes: 10485760  # 10MB\n    backup_count: 5\n  database:\n    enabled: true\n    table: audit_logs\n</code></pre>"},{"location":"features/logging/#querying-logs","title":"Querying Logs","text":""},{"location":"features/logging/#from-database","title":"From Database","text":"<pre><code>-- Recent errors\nSELECT * FROM audit_logs \nWHERE level = 'ERROR' \nORDER BY timestamp DESC \nLIMIT 10;\n\n-- Session activity\nSELECT * FROM audit_logs \nWHERE session_id = 'abc123' \nORDER BY timestamp;\n\n-- Component errors\nSELECT component, COUNT(*) as error_count\nFROM audit_logs \nWHERE level = 'ERROR' \nGROUP BY component;\n</code></pre>"},{"location":"features/logging/#from-files","title":"From Files","text":"<pre><code># View recent logs\ntail -f logs/interview_platform.log\n\n# Search for errors\ngrep \"ERROR\" logs/interview_platform.log\n\n# Parse JSON logs\ncat logs/interview_platform.log | jq '.level == \"ERROR\"'\n</code></pre>"},{"location":"features/logging/#related-features","title":"Related Features","text":"<ul> <li>Token Tracking</li> <li>Architecture</li> </ul>"},{"location":"features/token-tracking/","title":"Token Tracking","text":"<p>The Token Tracking feature monitors AI API usage to help manage costs and prevent budget overruns.</p>"},{"location":"features/token-tracking/#overview","title":"Overview","text":"<p>Token tracking provides:</p> <ul> <li>Real-time token usage monitoring</li> <li>Cost estimation</li> <li>Budget warnings</li> <li>Historical usage data</li> </ul>"},{"location":"features/token-tracking/#how-it-works","title":"How It Works","text":""},{"location":"features/token-tracking/#token-counting","title":"Token Counting","text":"<p>The system tracks:</p> <ul> <li>Input tokens: Prompt and context sent to AI</li> <li>Output tokens: AI-generated responses</li> <li>Total tokens: Sum of input and output</li> </ul>"},{"location":"features/token-tracking/#cost-calculation","title":"Cost Calculation","text":"<p>Costs are calculated based on provider pricing:</p> <p>OpenAI GPT-4: - Input: $0.03 per 1K tokens - Output: $0.06 per 1K tokens</p> <p>Anthropic Claude: - Input: $0.015 per 1K tokens - Output: $0.075 per 1K tokens</p>"},{"location":"features/token-tracking/#budget-management","title":"Budget Management","text":"<p>Set a token budget per session:</p> <pre><code>config = SessionConfig(\n    max_tokens=50000,  # 50K token budget\n    token_warning_threshold=0.8  # Warn at 80%\n)\n</code></pre>"},{"location":"features/token-tracking/#ui-indicators","title":"UI Indicators","text":""},{"location":"features/token-tracking/#progress-bar","title":"Progress Bar","text":"<p>Visual indicator showing: - Green: &lt; 70% used - Yellow: 70-90% used - Red: &gt; 90% used</p>"},{"location":"features/token-tracking/#token-counter","title":"Token Counter","text":"<p>Displays: <code>12,450 / 50,000 tokens ($0.85)</code></p>"},{"location":"features/token-tracking/#warnings","title":"Warnings","text":"<ul> <li>80% threshold: \"Approaching token budget limit\"</li> <li>100% threshold: \"Token budget exceeded\"</li> </ul>"},{"location":"features/token-tracking/#historical-data","title":"Historical Data","text":"<p>View token usage across sessions:</p> <ul> <li>Total tokens used</li> <li>Total cost</li> <li>Average per session</li> <li>Trends over time</li> </ul>"},{"location":"features/token-tracking/#configuration","title":"Configuration","text":"<p>Set default budgets in <code>config.yaml</code>:</p> <pre><code>token_tracking:\n  default_budget: 50000\n  warning_threshold: 0.8\n  track_by_component: true\n</code></pre>"},{"location":"features/token-tracking/#api-reference","title":"API Reference","text":"<pre><code>class TokenTracker:\n    def track_usage(\n        self,\n        session_id: str,\n        input_tokens: int,\n        output_tokens: int,\n        provider: str,\n        model: str\n    ) -&gt; TokenUsage\n\n    def get_session_usage(self, session_id: str) -&gt; TokenUsage\n\n    def check_budget(self, session_id: str) -&gt; BudgetStatus\n</code></pre>"},{"location":"features/token-tracking/#related-features","title":"Related Features","text":"<ul> <li>AI Interviewer</li> <li>Logging</li> </ul>"},{"location":"ui/interview-ui/","title":"Interview UI","text":"<p>The Interview UI is the main interface during an active interview session.</p>"},{"location":"ui/interview-ui/#layout","title":"Layout","text":""},{"location":"ui/interview-ui/#three-panel-design","title":"Three-Panel Design","text":"<p>Left Panel: Chat Interface - AI interviewer messages - Candidate text responses - Message history - Input box for typing</p> <p>Center Panel: Whiteboard - Drawing canvas - Tools: pen, eraser, shapes, text - Color picker - Save snapshot button - Clear canvas button</p> <p>Right Panel: Transcript - Live conversation transcript - Timestamps - Search functionality - Export button</p>"},{"location":"ui/interview-ui/#bottom-bar-recording-controls","title":"Bottom Bar: Recording Controls","text":"<ul> <li>Audio recording toggle</li> <li>Video recording toggle</li> <li>Whiteboard snapshot button</li> <li>Token usage indicator</li> <li>End interview button</li> </ul>"},{"location":"ui/interview-ui/#features","title":"Features","text":""},{"location":"ui/interview-ui/#real-time-interaction","title":"Real-time Interaction","text":"<ul> <li>Instant AI responses</li> <li>Live transcript updates</li> <li>Whiteboard auto-save</li> </ul>"},{"location":"ui/interview-ui/#multi-modal-input","title":"Multi-modal Input","text":"<ul> <li>Type responses</li> <li>Speak responses (if audio enabled)</li> <li>Draw diagrams (whiteboard)</li> <li>Share screen (if enabled)</li> </ul>"},{"location":"ui/interview-ui/#context-awareness","title":"Context Awareness","text":"<ul> <li>AI sees whiteboard snapshots</li> <li>AI considers conversation history</li> <li>AI adapts to candidate's level</li> </ul>"},{"location":"ui/interview-ui/#user-flow","title":"User Flow","text":"<ol> <li>Read initial problem</li> <li>Ask clarifying questions</li> <li>Design solution on whiteboard</li> <li>Explain approach to AI</li> <li>Answer follow-up questions</li> <li>Iterate on design</li> <li>End interview</li> </ol>"},{"location":"ui/interview-ui/#related-pages","title":"Related Pages","text":"<ul> <li>Setup UI</li> <li>Recording Controls</li> </ul>"},{"location":"ui/recording-controls/","title":"Recording Controls","text":"<p>The Recording Controls provide easy access to media recording features during interviews.</p>"},{"location":"ui/recording-controls/#controls","title":"Controls","text":""},{"location":"ui/recording-controls/#audio-recording","title":"Audio Recording","text":"<ul> <li>Toggle Button: Start/stop audio recording</li> <li>Indicator: Red dot when recording</li> <li>Status: Shows recording duration</li> </ul>"},{"location":"ui/recording-controls/#video-recording","title":"Video Recording","text":"<ul> <li>Toggle Button: Start/stop video recording</li> <li>Indicator: Red dot when recording</li> <li>Preview: Small camera preview</li> </ul>"},{"location":"ui/recording-controls/#whiteboard-snapshot","title":"Whiteboard Snapshot","text":"<ul> <li>Snapshot Button: Capture current whiteboard state</li> <li>Counter: Shows number of snapshots taken</li> <li>Thumbnail: Preview of last snapshot</li> </ul>"},{"location":"ui/recording-controls/#token-usage","title":"Token Usage","text":"<ul> <li>Progress Bar: Visual token budget indicator</li> <li>Counter: Tokens used / budget</li> <li>Warning: Alert at 80% usage</li> </ul>"},{"location":"ui/recording-controls/#end-interview","title":"End Interview","text":"<ul> <li>End Button: Terminate interview session</li> <li>Confirmation: Prevents accidental ending</li> <li>Status: Shows session duration</li> </ul>"},{"location":"ui/recording-controls/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<ul> <li><code>Ctrl+R</code>: Toggle audio recording</li> <li><code>Ctrl+S</code>: Save whiteboard snapshot</li> <li><code>Ctrl+E</code>: End interview (with confirmation)</li> </ul>"},{"location":"ui/recording-controls/#related-pages","title":"Related Pages","text":"<ul> <li>Interview UI</li> <li>Communication Manager</li> </ul>"},{"location":"ui/setup-ui/","title":"Setup UI","text":"<p>The Setup UI is the initial screen where users configure their interview session.</p>"},{"location":"ui/setup-ui/#features","title":"Features","text":""},{"location":"ui/setup-ui/#resume-upload","title":"Resume Upload","text":"<ul> <li>Drag-and-drop or file browser</li> <li>Supports PDF and TXT formats</li> <li>Max file size: 10MB</li> <li>Automatic parsing and analysis</li> </ul>"},{"location":"ui/setup-ui/#ai-provider-selection","title":"AI Provider Selection","text":"<ul> <li>OpenAI GPT-4 (recommended)</li> <li>Anthropic Claude</li> <li>Model selection (GPT-4, GPT-4-turbo, Claude-3-opus, etc.)</li> </ul>"},{"location":"ui/setup-ui/#communication-mode-selection","title":"Communication Mode Selection","text":"<ul> <li>Audio: Enable microphone recording</li> <li>Video: Enable camera recording</li> <li>Whiteboard: Enable drawing canvas</li> <li>Screen Share: Enable screen capture</li> </ul> <p>Multiple modes can be enabled simultaneously.</p>"},{"location":"ui/setup-ui/#session-configuration","title":"Session Configuration","text":"<ul> <li>Interview duration (optional)</li> <li>Token budget limit</li> <li>Difficulty preference</li> </ul>"},{"location":"ui/setup-ui/#user-flow","title":"User Flow","text":"<ol> <li>Upload resume</li> <li>Wait for analysis</li> <li>Select AI provider</li> <li>Choose communication modes</li> <li>Click \"Start Interview\"</li> </ol>"},{"location":"ui/setup-ui/#screenshots","title":"Screenshots","text":"<p>[Add screenshots here]</p>"},{"location":"ui/setup-ui/#related-pages","title":"Related Pages","text":"<ul> <li>Interview UI</li> <li>Quick Start Guide</li> </ul>"}]}